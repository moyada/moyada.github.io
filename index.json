[{"authors":null,"categories":null,"content":"","date":1585417455,"expirydate":-62135596800,"kind":"section","lang":"zh","lastmod":1585417455,"objectID":"3a71e2d65a6b876f7027ee955e76a5e8","permalink":"https://moyada.github.io/projects/","publishdate":"2020-03-29T01:44:15+08:00","relpermalink":"/projects/","section":"projects","summary":"Learn how to use Academic's docs layout for publishing online courses, software documentation, and tutorials.","tags":null,"title":"介绍","type":"docs"},{"authors":null,"categories":null,"content":"目标 该程序意在通过模拟请求来检测微服务的可用性，在请求完成后对结果进性分析生成报表，反馈出请求异常及接口耗时等情况。\n通过分析源码熟悉 SpringCloud、Dubbo、SofaRPC 等框架调 逻辑，并将其封装成调用模块，将调用结果异步进行存储。 设计的参数表达式功能，通过表达式动态 成 同请求参数，并使用线程池模拟并发调。提供监听注解的 Spring 装配模块，自定义 Processor 对目标方法注 参数收集逻辑。\n","date":1586041200,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1586041200,"objectID":"aea6001599513eadc82626d7b103b0bf","permalink":"https://moyada.github.io/projects/project1/","publishdate":"2020-04-05T00:00:00+01:00","relpermalink":"/projects/project1/","section":"projects","summary":"目标 该程序意在通过模拟请求来检测微服务的可用性，在请求完成后","tags":null,"title":"微服务测试工具","type":"docs"},{"authors":null,"categories":null,"content":"项目通过分析和平台视频接口，获取原视频下载地址\n","date":1557010800,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557010800,"objectID":"66027ab6a2867c337fd2d63854ef7f33","permalink":"https://moyada.github.io/projects/project2/","publishdate":"2019-05-05T00:00:00+01:00","relpermalink":"/projects/project2/","section":"projects","summary":"项目通过分析和平台视频接口，获取原视频下载地址","tags":null,"title":"去水印程序","type":"docs"},{"authors":[],"categories":["Java"],"content":"简介 在 Java 中有两种获取时间的方式，分别是在 java.lang.System 中的 public static native long currentTimeMillis() 和 public static native long nanoTime()。\n  currentTimeMillis() 是返回当前的时间戳，这个时间戳的增长幅度可能由于不同的操作系统而变化。\n  nanoTime() 返回系统当前的纳秒时间，这个时间与系统的时钟并没有关系，是由系统的计时器计算返回。\n  但是由于这两个方法都是 native 修饰的，为了研究其底层逻辑，那就需要进入 openJdk 中一探究竟。\n实现 在 System.c 的 Java_java_lang_System_registerNatives 方法中发现，currentTimeMillis 注册的函数为 JVM_CurrentTimeMillis，nanoTime 注册的函数为 JVM_NanoTime。\n接着跟踪进入 jvm.cpp，得知这个函数是根据不同的操作系统底层选择调用的实现，这里使用 os_linux.cpp 中的实现作为研究。\ncurrentTimeMillis javaTimeMillis 的实现是直接调用操作系统的 gettimeofday 函数实现的。这个函数的作用是获取当前的墙上时钟时间，并保存在参数 timeval。\njlong os::javaTimeMillis() { timeval time; int status = gettimeofday(\u0026amp;time, NULL); assert(status != -1, \u0026quot;linux error\u0026quot;); return jlong(time.tv_sec) * 1000 + jlong(time.tv_usec / 1000); }   http://man7.org/linux/man-pages/man2/gettimeofday.2.html\n nanoTime 而 javaTimeNanos 是根据操作系统是否支持 clock_gettime 函数选择调用 clock_gettime，否则调用 gettimeofday。openJdk 这里调用 clock_gettime 时传递的参数为 CLOCK_MONOTONIC，他的功能是获取从系统启动时单调变化的时间。\njlong os::javaTimeNanos() { if (os::supports_monotonic_clock()) { struct timespec tp; int status = os::Posix::clock_gettime(CLOCK_MONOTONIC, \u0026amp;tp); assert(status == 0, \u0026quot;gettime error\u0026quot;); jlong result = jlong(tp.tv_sec) * (1000 * 1000 * 1000) + jlong(tp.tv_nsec); return result; } else { timeval time; int status = gettimeofday(\u0026amp;time, NULL); assert(status != -1, \u0026quot;linux error\u0026quot;); jlong usecs = jlong(time.tv_sec) * (1000 * 1000) + jlong(time.tv_usec); return 1000 * usecs; } }   http://man7.org/linux/man-pages/man2/clock_gettime.2.htmlxs\n 应用 在实际应用中，currentTimeMillis() 会比 nanoTime() 有更好的作用，例如 new Data() 的底层就是调用了 currentTimeMillis 作为时间参数，而 nanoTime 由于底层是依赖于计数器，更多的应用则是计算耗时。\n在 雪花算法中，时间戳是保证全局编号递增的关键，然而现实场景下是有可能出现时钟回拨现象，那么单调递增的 nanoTime 是否更适合呢？\n其实这个问题的解法有很多种，选择适用的即可。\n  最原始的方式，记录上一次的时间戳，但新产生的时间戳先于这个时间戳时，那就进行 sleep 重新获取时间戳\n  使用 nanoTime，由于 nanoTime 是单调递增的，所以也不会出现时钟回拨的现场。但是 nanoTime 有可能会产生溢出，导致返回负值。\n  使用 currentTimeMillis，并且调用 adjtime 增量调整时间同步策略。\n   http://man7.org/linux/man-pages/man3/adjtime.3.html\n 这里讲讲第三种，adjtime() 是Unix提供的函数，她的作用是设置系统时间变化的增量。如果出现了时钟回拨，那系统将会使用一个缓慢的速率，慢慢的修复时间。这样的时间戳就是相对的递增的了，在 Snowflake 中也就必须担心使用到历史的时间戳做编号。\n 参考: https://stackoverflow.com/questions/12392278/measure-time-in-linux-time-vs-clock-vs-getrusage-vs-clock-gettime-vs-gettimeof\n ","date":1589210667,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1589210667,"objectID":"51a2492f246dda8b416761c507335d33","permalink":"https://moyada.github.io/post/currenttimemillis-vs-nanotime/","publishdate":"2020-05-11T23:24:27+08:00","relpermalink":"/post/currenttimemillis-vs-nanotime/","section":"post","summary":"简介 在 Java 中有两种获取时间的方式，分别是在 java.lang.System 中的 public static native long currentTimeMillis() 和 public","tags":[],"title":"探究 currentTimeMillis 与 nanoTime 的不同","type":"post"},{"authors":[],"categories":["Python"],"content":"调试接口 由于时常使用 谷歌翻译，就想着把接口做成服务调用，省去登陆网页的麻烦。\n 需要更好的服务可以使用谷歌云服务 https://cloud.google.com/translate ，每月可获赠价值不超过 $10 的免费用量\n 用开发者工具调试页面接口拿到了翻译调用的接口\nhttps://translate.google.com/translate_a/single?client=webapp\u0026amp;sl=zh-CN\u0026amp;tl=en\u0026amp;hl=zh-CN\u0026amp;dt=at\u0026amp;dt=bd\u0026amp;dt=ex\u0026amp;dt=ld\u0026amp;dt=md\u0026amp;dt=qca\u0026amp;dt=rw\u0026amp;dt=rm\u0026amp;dt=sos\u0026amp;dt=ss\u0026amp;dt=t\u0026amp;otf=1\u0026amp;ssel=5\u0026amp;tsel=5\u0026amp;xid=1791807%2C45625687%2C45626150\u0026amp;kc=11\u0026amp;tk=718445.806187\u0026amp;q=%E4%BD%A0%E5%A5%BD\n但是在调试发现，接口中带了个签名参数 tk，通过查找 js 源文件，在 translate_m_zh-CN.js 这里发现了相关痕迹，但是解析起来太费劲了。。。\n调用模块 这个时候检索的能力就体验出来了，通过在 Google 里的一顿操作，得知 Node 里有相关使用库，它将 tk 的获取函数提取出来了。\n通过 npm install --save google-translate-api 安装模块到本地，修改源代码。\n  将 google-translate-api 和 google-translate-token 下的 index.js 里的 translate.google.com 替换为 translate.google.cn。\n  修改 google-translate-api/index.js 中请求参数 data 的数据 client: 'gtx'\n  使用 修改完成后便在国内也能调用。\nconst translate = require('google-translate-api'); translate('您好', {to: 'en'}).then(res =\u0026gt; { console.log(res.text); }).catch(err =\u0026gt; { console.error(err); });  在 Python 中使用可以这样方式调用 node\nimport os p = os.popen('node translate.js %s' % value) print(p.readlines()[0])   参考: https://www.zhihu.com/question/47239748\n ","date":1588169440,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1588169440,"objectID":"6ca15d46c79797fd7f080cf05d2f7ed7","permalink":"https://moyada.github.io/post/google-translate/","publishdate":"2020-04-29T22:10:40+08:00","relpermalink":"/post/google-translate/","section":"post","summary":"调试接口 由于时常使用 谷歌翻译，就想着把接口做成服务调用，省去","tags":[],"title":"谷歌翻译 API 调用","type":"post"},{"authors":[],"categories":["Java"],"content":"容器是 Spring 设计中一个核心组件，它负责管理 Bean 实例，并提供了接口 BeanFactory 使用。\n网上对这个有太多分析的文章了，但大多繁琐不堪，不易新手理解，这里就只对关键步骤做个简单分析。\n 文章中所研究的 Spring 版本为 5.1.4\n 创建 Bean 的创建是其生命周期中最复杂的一步，这边对 getBean 方法跟踪，进入到了 AbstractBeanFactory 的 doGetBean 方法，该方法的内容就是构造 Bean 的主要流程，这里只将关键的步骤提取出来。\nprotected \u0026lt;T\u0026gt; T doGetBean(final String name, @Nullable final Class\u0026lt;T\u0026gt; requiredType, @Nullable final Object[] args, boolean typeCheckOnly) throws BeansException { final String beanName = transformedBeanName(name); // 解析 Bean 名称 Object bean; Object sharedInstance = getSingleton(beanName); // 1. 获取 Bean 实例或构造工厂 if (sharedInstance != null \u0026amp;\u0026amp; args == null) { // 这里主要是对构造工厂进行创建实例 bean = getObjectForBeanInstance(sharedInstance, name, beanName, null); } else { BeanFactory parentBeanFactory = getParentBeanFactory(); // 检查父级构造工厂是否包含实例，是则交由父级工厂创建返回 ... final RootBeanDefinition mbd = getMergedLocalBeanDefinition(beanName); // 初始化当前 Bean 所依赖的 Bean ... // 2. 根据 Bean 的类型选择构造方式，这里分析单例模式 sharedInstance = getSingleton(beanName, () -\u0026gt; { try { return createBean(beanName, mbd, args); // 具体构造实例的逻辑 } catch (BeansException ex) { destroySingleton(beanName); throw ex; } }); bean = getObjectForBeanInstance(sharedInstance, name, beanName, mbd); } // 类型检查和转换 ... return (T) bean; }  获取单例 其实整个流程十分复杂，这里也能够看出 Spring 的严谨性。首先跟进 1. getSingleton()，它的逻辑虽然简单，但其实是对解决循环依赖问题非常关键的一步。\nprotected Object getSingleton(String beanName, boolean allowEarlyReference) { Object singletonObject = this.singletonObjects.get(beanName); if (singletonObject == null \u0026amp;\u0026amp; isSingletonCurrentlyInCreation(beanName)) { synchronized (this.singletonObjects) { singletonObject = this.earlySingletonObjects.get(beanName); if (singletonObject == null \u0026amp;\u0026amp; allowEarlyReference) { ObjectFactory\u0026lt;?\u0026gt; singletonFactory = this.singletonFactories.get(beanName); if (singletonFactory != null) { singletonObject = singletonFactory.getObject(); this.earlySingletonObjects.put(beanName, singletonObject); this.singletonFactories.remove(beanName); } } } } return singletonObject; }  这里有两个解决循环引用的要点，这里先知道就行。\n  一是 isSingletonCurrentlyInCreation(beanName)，这是标记了一个 Bean 正处于构造阶段中。\n  还有一个是 this.singletonFactories.get(beanName)，这里返回的是 Bean 实例的构造工厂，需要在其他位置通过调用 addSingletonFactory 加入进来。\n  创建 Bean 实例 创建实例调用的内容非常多，这边主要讲下构造、注入、处理器的过程。\n首先看到 2. getSingleton()，这里需要关注的只有这几步，\n  beforeSingletonCreation 和 afterSingletonCreation 分别为标记 Bean 在创建中和移除标记\n  使用前面的 createBean 创建实例。\n  addSingleton 则是将创建的实例加入到容器中。\n  public Object getSingleton(String beanName, ObjectFactory\u0026lt;?\u0026gt; singletonFactory) { beforeSingletonCreation(beanName); try { singletonObject = singletonFactory.getObject(); newSingleton = true; } finally { afterSingletonCreation(beanName); } if (newSingleton) { addSingleton(beanName, singletonObject); } return singletonObject; }  继续分析 createBean，其实里面主要是委托了 doCreateBean 方法来创建实例，解决循环引用的关键点就是这里的 addSingletonFactory，使得 Bean 在创建阶段就提供依赖引用。\nprotected Object doCreateBean(final String beanName, final RootBeanDefinition mbd, final @Nullable Object[] args) throws BeanCreationException { // 创建实例，会涉及构造器注入 BeanWrapper instanceWrapper = createBeanInstance(beanName, mbd, args); final Object bean = instanceWrapper.getWrappedInstance(); // 缓存实例引用 boolean earlySingletonExposure = (mbd.isSingleton() \u0026amp;\u0026amp; this.allowCircularReferences \u0026amp;\u0026amp; isSingletonCurrentlyInCreation(beanName)); if (earlySingletonExposure) { addSingletonFactory(beanName, () -\u0026gt; getEarlyBeanReference(beanName, mbd, bean)); } Object exposedObject = bean; // 初始化实例 populateBean(beanName, mbd, instanceWrapper); exposedObject = initializeBean(beanName, exposedObject, mbd); return exposedObject; }  初始化 当 Bean 在 doCreateBean 中完成了实例的创建，接着就会对实例进行属性注入、调用初始化方法、执行前置/后置处理器，而后将实例加入到 Spring 容器中，就完成了一个 Bean 的创建阶段。\n 这个过程也可以通过 AutowireCapableBeanFactory#initializeBean 来完成。\n 销毁 一个 Bean 实例的销毁可以随着 Spring 生命周期结束而触发，也可以通过调用 AutowireCapableBeanFactory 中的 destroyBean 来进行。\n他将构造一个 DisposableBeanAdapter 来执行不同实例的销毁流程，这里的代码流程清晰明了。\npublic void destroy() { for (DestructionAwareBeanPostProcessor processor : this.beanPostProcessors) { processor.postProcessBeforeDestruction(this.bean, this.beanName); // 执行前置销毁处理器 } // 执行实现 DisposableBean 的销毁方法 ((DisposableBean) this.bean).destroy(); // 执行自定义销毁方法 invokeCustomDestroyMethod(this.destroyMethod); }  ","date":1585376375,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1588007975,"objectID":"66a3dcfc07bf35b8883b5219f5cf1be0","permalink":"https://moyada.github.io/post/spring-bean/","publishdate":"2020-03-28T14:19:35+08:00","relpermalink":"/post/spring-bean/","section":"post","summary":"容器是 Spring 设计中一个核心组件，它负责管理 Bean 实例，并提供了接口 BeanFactory","tags":["Spring"],"title":"Spring Bean 生命周期简单分析","type":"post"},{"authors":[],"categories":[],"content":"爬虫与反爬虫是个在软件开发行业里一直存在的斗争。爬虫，一般常见的有窃取同行数据、分析行业数据、恶意攻击等，最终都是以牟利为目的。为了防止爬虫，就诞生了反爬虫技术，通过识别非法操作与正常操作来做到拦截爬虫请求。\n下面就来分析一下这些常见的爬虫与反爬虫都有哪些手段。\n爬虫 API 一般情况下，爬虫都是直接调用网站内请求数据的接口，这是成本最低的方式。通过分析接口请求规则，组装成 HTTP 请求，模拟正常用户操作。\n常见的 API 有数据型和操作型\n  例如通过某之家的接口 https://car.m.autohome.com.cn/ashx/car/GetModelConfigNew3.ashx?seriesId=18 ，通过接口可以获取到市场上车型参数的数据。\n  而某东的登陆接口 https://passport.jd.com/uc/loginService ，操作后保存 session，便可以在后面操作其他电商接口。\n   通过这些接口的使用，就出现了数据分析工具，黄牛抢购，轰炸机脚本。\n 模拟浏览器 在一些网站对接口升级防护后，可能原有的方式就失效了，这个时候再尝试分析请求接口就可能徒劳无功。但是，通过模拟正常用户操作的话，那不是又能够越过防护了，这时模拟浏览器手段的爬虫开始流行起来。\n这类爬虫手段可以做到像手工操作一样模拟，登陆、验证码、获取网页元素，为了提高效率还可以设置禁止加载图片和 css。\n常用的工具有 Python 的 selenium 和 pyppeteer，两者都可以很方便的操作网页元素，前者是市面上相对成熟的爬虫工具，\n代理池 上述的爬虫方式都是直接通过本机请求的，如果网站对来访的请求有流量控制策略，那么当请求过于频繁时，将可能被限制访问。\n这时可以通过 匿名代理 的手段来隐藏真实 ip，通常是使用 ip 代理池来实现，这个代理池可以是自身维护的也可以是第三方的付费服务，每次请求都从这个 ip 代理池中获取 ip 代理操作，这样网站收集到的请求地址就是代理的 ip。\n反爬虫 Header 拦截 在网站的目标访问用户可预知的情况下，可以设置一些 Header、User-Agent、Cookie 来简单拦截非法请求。\n但是这种手段十分容易被攻破，只需通过抓取正常请求信息进行解析，再对爬虫请求配置请求头就可以模拟正常用户操作。\n验证码 为了防止爬虫的大量请求影响网站可用性，通常会对一些关键接口增加验证码校验，比如字符验证码、问答验证码、滑动验证码、图形验证码。\n有些网站只是在接口外增加了验证码的保护，但爬虫不是像正常用户访问浏览器来请求的，而是绕过了验证码直接请求业务接口，所以需要将验证码与接口绑定在一起使用。\n数据加密 现在的网站为了防止爬虫，还会对页面数据进行混淆，直接返回 html 代码或使用 css 渲染数据，增加爬虫的成本。\n有的网站还会对一些关键接口的进行数据加密或者通信协议加密，需要动态跟踪加密过程来破解。这样使得爬虫分析接口变得几乎不可能，但是却避免不了通过模拟浏览器的操作。\n频次拦截 在对爬虫敏感的网站，会对请求数据进行收集分析，通过识别爬虫行为来拦截请求，通常使用 滑动窗口 对归类的请求进行统计。\n ip 代理技术就是为了防止请求被拦截的匿名手段。\n 总结 通常情况下，为了做到高效的反爬虫，会将各个反爬虫手段结合使用，有些还会反向分析爬虫工具针对性拦截。\n然而，再完善的防御，还是会有被突破的可能，这一切都是成本的博弈。只有当爬虫行为的 ROI 远远低于预期时，那么反爬虫就是成功的。\n 这是我的某宝下单脚本，由于该网站对交易请求做了加密，还在 selenium 做了很大功夫的防爬虫，于是便使用了能应对现有防御的 pyppeteer https://github.com/moyada/auto-order 。\n ","date":1584894522,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1584894522,"objectID":"57c7c719e915768f2582d882d0c781f9","permalink":"https://moyada.github.io/post/scrapy/","publishdate":"2020-03-23T00:28:42+08:00","relpermalink":"/post/scrapy/","section":"post","summary":"爬虫与反爬虫是个在软件开发行业里一直存在的斗争。爬虫，一般常","tags":[],"title":"爬虫与反爬虫","type":"post"},{"authors":[],"categories":[],"content":"今年参与了阿里巴巴举办的 中间件性能挑战赛，并且有幸进入到了复赛，虽然后期由于其他原因没法专心参与，不过通过这次比赛也让我在技术上收获了不少，这边小小的做下本次比赛的总结。\n初赛：《自适应负载均衡的设计实现》 赛题分析 初赛的题目是在 Dubbo 之上进行的插件开发，对参与者对于 Dubbo 的调用过程有一定的要求。官方在 gateway 端提供了 CallbackListenerImpl、TestClientFilter、UserLoadBalance 供开发。在 provider 端提供了 CallbackServiceImpl、TestRequestLimiter、TestServerFilter 供开发。\n将这些组件结合起来就形成了基本的调用链路。\n目标   provider 在接收请求大于处理线程池大小的时候，将会执行拒绝策略 AbortPolicyWithReport，并将线程栈信息以日志文件输出。这无疑增加了服务端的压力，那么就需要让 provider 在 TestRequestLimiter 进行限流，在剩余线程数量不足时拒绝进来的请求。\n  要完成自适应的负载均衡，那么就需要由 provider 端将权重推送至 gateway，这项工作通过 CallbackServiceImpl 和 CallbackListenerImpl 来完成。但是传输的数据为字符串，不包含 provider 标识，这时就需要能够获取 provider 的服务地址，连带指标推送给 gateway。\n  gateway 接收到请求时选择性能最优 provider，当所有 provider 压力均满时直接拒绝请求。\n  设计与实现 provider 拒绝服务 通过分析 AllChannelHandler 的源码发现，provider 在通过 Filter 后才会使用线程池处理请求，为了不让服务进入拒绝策略，就需要在线程池不足时利用 Filter 拒绝他。官方是允许使用 SPI 的，那么可根据 WrappedChannelHandler 的代码，从 DataStore 里获取所使用的线程池，提取出线程池最大线程数，在请求前后进行计数，拦截超出能力的请求。\npublic class WrappedChannelHandler implements ChannelHandlerDelegate { public WrappedChannelHandler(ChannelHandler handler, URL url) { this.handler = handler; this.url = url; executor = (ExecutorService) ExtensionLoader.getExtensionLoader(ThreadPool.class) .getAdaptiveExtension().getExecutor(url); String componentKey = Constants.EXECUTOR_SERVICE_COMPONENT_KEY; if (Constants.CONSUMER_SIDE.equalsIgnoreCase(url.getParameter(Constants.SIDE_KEY))) { componentKey = Constants.CONSUMER_SIDE; } DataStore dataStore = ExtensionLoader.getExtensionLoader(DataStore.class).getDefaultExtension(); dataStore.put(componentKey, Integer.toString(url.getPort()), executor); } ... }  经过了这一层拦截，分数就已经明显上去了，但是由于 provider 的能力各不相同，还需要通过计算权重进行请求分发。\n数据通信 当消费方与多个服务方都需要进行通信时，能够唯一确定数据的来源是关键，还是通过读源码，我发现能够从服务 URL 中获取到主机地址和端口号。在 provider 端，自定义暴露监听器保存系统的地址。在 gateway 端，自定义引用监听器将 URL 与地址进行一一映射。\n// gateway public class InvokerMapperListener implements InvokerListener { private static final Map\u0026lt;URL, String\u0026gt; addressMapper = new ConcurrentHashMap\u0026lt;\u0026gt;(); @Override public void referred(Invoker\u0026lt;?\u0026gt; invoker) throws RpcException { URL url = invoker.getUrl(); String address = getAddress(url); addressMapper.put(url, address); } } // provider public class ThreadPoolExporterListener implements ExporterListener { @Override public void exported(Exporter\u0026lt;?\u0026gt; exporter) throws RpcException { if (Context.ADDRESS != null) { return; } URL url = exporter.getInvoker().getUrl(); Context.ADDRESS = getAddress(url); } } public static String getAddress(URL url) { String ip = url.getParameter(Constants.BIND_IP_KEY); String port = url.getParameter(Constants.BIND_PORT_KEY); return ip + \u0026quot;:\u0026quot; + port; }  通信功能算是完成了，这时可以直接使用前面 provider 获取到的线程池大小作为权重，但是由于服务能力是动态变化的，为了达到更好的效果还需要进一步改进。\n动态负载 根据评测代码可知，消费服务在程序内部使用了 Semaphore 对请求进行了拦截，实际可容纳的请求小于线程数，并且并发数随着时间也在发生变化。\n如果单位时间内接收的请求数大于实际并发数时，则多余的请求将会被置为等待状态。当请求数持续大于并发数时，会导致请求堆积造成大量超时。因此在 Dubbo 中有个超时检测机制 org.apache.dubbo.remoting.exchange.support.DefaultFuture##TIME_OUT_TIMER，这是一个用于中止任务的时间轮，当一个请求进入执行阶段时，它将会被放入时间轮，在一定时间后结束请求返回错误信息。\n因此需使得请求在时间轮触发之前执行，这样才能保证不会造成异常响应。在这里我还是使用到了前面获取的线程池，由于线程在线程池中空闲的状态为 WAITING 或 TIMED_WAITING，在执行过程中工作线程的状态可能为 RUNNABLE、BLOCKED、WAITING、TIMED_WAITING，空闲线程与工作线程存在状态重叠，因而无法将 getActiveCount 用作并发数。\n因此在执行阶段 Filter 前后对当前线程进行标记，并放入一个 placeHolder 中保存，在退出 Filter 时移除标记。由此一来 placeHolder 中就只存在工作中的线程，在除去 BLOCKED 和 WAITING 状态的线程即为并发数。\n 为了避免并发冲突影响效率，采用无锁编程，预先创建好数组，利用线程id作为下标指定标记元素位置。\n 在得到实际并发数后，再通过与 cpu核心数、cpu频率 进行计算得出权重值，定时的发送给 gateway 用于选择最优 provider。\ngateway 将收到并发数作为负载均衡还远远不够，如果一个服务由于机器资源不足、网络故障等原因也将会导致请求异常，因此请求耗时也是一个考量负载的指标。由于网络消耗的存在，则在 gateway 端做请求耗时的收集，将并发数与耗时进行结合完成负载均衡策略。\n复赛：《实现一个进程内基于队列的消息持久化存储引擎》 赛题分析 赛题要求实现一个进程内消息持久化的存储引擎，提供了 4g 的堆内存，2g 的堆外内存，300g 的SSD磁盘。过程分别为发送、查询聚合消息、查询聚合结果，串行执行三个步骤，每个步骤需要在 30 分钟内完成，以每个阶段的 发送数\\时间 总和为成绩。\n设计   由于查询阶段需要对 时间戳 和 数值 进行条件过滤，考虑以 时间戳 和 数值 创建索引键对数据分散进行存储，以数据块为存储单位。\n  每个线程所发送消息的时间戳是递增的，对查询过滤天然适合，则为每个线程映射一个存储组件实例。\n  官方提供使用的存储介质为 SSD磁盘，大量数据写入的效率好，所以将数个数据块为一组单位，缓存于内存中，在写入数据达到下一组单位时进行文件存储。\n  在查询阶段为了更好的利用资源，使用 lru缓存 保存查询数据。\n  发送阶段完成后磁盘文件组织如下，以时间戳定位文件，再以数值选择文件内的数据块（图中以 8192 为时间戳分片大小，4096 为数值为片大小，均为 2 的幂次方，以位运算即可完成路由）。\n如查询条件为 { t: [8000, 22000], a: [5000, 20000] }，则选择文件 hash-0、hash-1、hash-2 为目标文件，分别对文件内的 index-1、index-2、index-3、index-4 数据块进行检索，其中 hash-1 index-2、hash-1 index-3 为中间数据，无需对数据进行条件过滤。\n实现 其实复赛的设计思路并不难，主要的难点是分片大小的选择，如何更好的利用内存不发生 OOM，以及利用多线程提升效率。\n在写入阶段，使用内存进行数据的缓存，利用时间戳的有序性检测是否进入下个文件数据集，由于需要对全量数据都进行哈希，采用了位移操作提升效率。\n在读取阶段，对条件使用哈希确定目标数据的分布范围，充分利用堆内存与堆外内存，将分配的 ByteBuffer 进行缓存，提高下次查询时的效率。同理，对于无需条件过滤的结果也可以通过缓存来提高效率。\n增加了缓存就需要考虑内存容量问题，为了避免 OOM 需要引入淘汰规则。直接使用 SoftReference 容易频繁产生 CMS GC，影响查询效率，而使用 WeakReference 缓存数据则具有不确定性，数据很可能被快速回收，失去了缓存的意义。\n经过分析后选择了LRU算法，在固定大小集合里缓存数据，对长久未使用的数据进行清理。传统的 LRU Cache 可用继承 LinkedHashMap 的方式实现，然而这个类是非线程安全的，在查询场景可能产生并发问题，因此重新实现了一个线程安全的 LRU Cache。\npublic class ConcurrentLRUCache\u0026lt;K, V\u0026gt; { private final Queue\u0026lt;K\u0026gt; keySet; private final Map\u0026lt;K, T\u0026gt; cache; private final AtomicInteger acquire; private final int outSize; private volatile boolean full = false; public ConcurrentLRUCache(int size) { this.keySet = new ConcurrentLinkedQueue\u0026lt;\u0026gt;(); this.cache = new ConcurrentHashMap\u0026lt;\u0026gt;(size, 1f); this.acquire = new AtomicInteger(size); this.outSize = size + 1; } public void put(K key, T value) { if (full) { K firstKey = keySet.poll(); cache.remove(firstKey); } else { int nextSize = acquire.incrementAndGet(); if (nextSize \u0026gt; outSize) { Thread.yield(); put(key, value); return; } if (nextSize == outSize) { full = true; } } cache.put(key, value); keySet.offer(key); } public T get(K key) { T value = cache.get(key); if (value == null) { return null; } if (keySet.remove(key)) { keySet.offer(key); } return value; } }   除了添加缓存外，还有其他优化手段，比如 多线程并发处理数据块、对分块数据进行压缩、数据与消息体分开存储、利用时间戳的顺序中断查询。\n 总结 在这次比赛中，主要收获了在系统设计上的锻炼，分析问题也更加全面了，以及在 无锁编程、NIO处理、编写高性能代码 方面的进步。如通过 async-profiler 发现乐观锁在大量请求下的性能问题，并转变思路使用无锁编程。了解到 MappedByteBuffer 在大量写入的情况下会频繁发生 pageCache 的 flush，可以先准备好 ByteBuffer 保存数据，之后再将整个 ByteBuffer 写入到 MappedByteBuffer 中。\n","date":1567972643,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1567972643,"objectID":"048a3a50d3d2015663465642303ae52e","permalink":"https://moyada.github.io/post/middleware-competition-5/","publishdate":"2019-09-08T19:57:23Z","relpermalink":"/post/middleware-competition-5/","section":"post","summary":"今年参与了阿里巴巴举办的 中间件性能挑战赛，并且有幸进入到了复","tags":[],"title":"第五届中间件性能挑战赛","type":"post"},{"authors":[],"categories":["JVM"],"content":"介绍 Shenandoah GC 是 OpenJDK 在 JDK12 推出的新一代 标记整理 的垃圾回收器，它的目标时为了使大容量内存应用在垃圾回收时只进行短暂的应用暂停，使用 -XX:+UseShenandoahGC 开启。\n它能够在垃圾回收周期中进行 并发整理 和 并发更新，不暂停应用线程，并将垃圾回收分解为多个阶段，来达到极短的暂停时间，同时不会随着堆内存大小而影响。\n 参考资料: https://wiki.openjdk.java.net/display/shenandoah/Main https://www.youtube.com/watch?v=VCeHkcwfF9Q https://www.youtube.com/watch?v=E1M3hNlhQCg https://www.researchgate.net/publication/306112816_Shenandoah_An_open-source_concurrent_compacting_garbage_collector_for_OpenJDK https://developers.redhat.com/blog/2019/06/27/shenandoah-gc-in-jdk-13-part-1-load-reference-barriers/ https://developers.redhat.com/blog/2019/06/28/shenandoah-gc-in-jdk-13-part-2-eliminating-the-forward-pointer-word/\n 特性 并发复制 Shenandoah GC 是如何做到并发复制的呢？这主要是利用了 读屏障 和 Brooks Pointers。\n Brooks Pointers 是为了保证并发环境下数据一致性而设计的字段，它在对象地址中占用了 8 位地址来标识实际对象地址的偏移值。\n通常情况下它指向当前对象地址自身，当进入并发整理的对象拷贝阶段时，GC 将会利用 CAS 操作替换新的地址偏移值，并保证只进行一次成功的操作。\n当应用线程操作该对象时将会使用 读屏障 获取 brooks pointers 偏移值再计算得出实际地址返回。\nhotspot/share/gc/shenandoah/shenandoahBrooksPointer.inline.hpp inline oop ShenandoahBrooksPointer::forwardee(oop obj) { shenandoah_assert_correct(NULL, obj); return oop(*brooks_ptr_addr(obj)); } inline HeapWord** ShenandoahBrooksPointer::brooks_ptr_addr(oop obj) { return (HeapWord**)((HeapWord*) obj + word_offset()); }  由于通常情况下并不需要使用读屏障来获取地址，Shenandoah GC 又引入了 slow path 的设计。\n它的作用是，只有当垃圾回收进行中，并且对象处于 collection set 中，那么程序才会使用 读屏障 来获取对象地址。\n同时 Shenandoah GC 还会对字节码进行优化，以确保程序正确的情况下减少用读屏障获取地址的使用。\n由于需要使用额外的空间来存储 brooks pointers，则必须使用 64 位地址，同时堆空间也会增加 3% ~ 15% 的开销，而 CAS 和 读屏障 则产生 2% ~ 20% 的吞吐量下降。\n空间划为 Shenandoah 与 G1 类似也是以 Region 来划分堆内存，但是不进行分代标记。\n每个 Region 对应一个数组用来表示有哪些 Region 存在对象指向自身 Region 中的对象，这就避免了 G1 在年轻代之间的引用关系需要扫描整个年轻代甚至是堆的情况。\nNUMA 与 ZGC 相同，利用 NUMA 架构的 CPU 亲和的内存分配策略，在分配对象时使用线程所处的 CPU 缓存，并且使 应用线程 与 GC线程 处于同一核心线程下，共享同一个 Region 的数据。\n触发策略 从 hotspot/share/gc/shenandoah/shenandoahControlThread.cpp::run_service() 可以观察到 Shenandoah GC 的垃圾收回触发策略，将会根据 内存分配情况 或 提交的垃圾回收事件 _requested_gc_cause 来决定所执行的具体垃圾回收流程。\n switch (mode) { case none: break; case concurrent_traversal: service_concurrent_traversal_cycle(cause); break; case concurrent_normal: service_concurrent_normal_cycle(cause); break; case stw_degenerated: service_stw_degenerated_cycle(cause, degen_point); break; case stw_full: service_stw_full_cycle(cause); break; default: ShouldNotReachHere(); }  回收过程 Shenandoah 的回收过程与 G1 类似，都是基于 Region 的收集策略，一般情况下将垃圾回收声明周期分解成数个阶段执行。\n 初始标记  暂停应用线程，扫描 GC Roots。\n并发标记  与应用程序并发进行，通过上一阶段的 GC Roots 遍历堆，使用 STAB 算法描绘存活对象图谱。\n最终标记  暂停应用线程，处理位于队列中的标记和更新操作，并预先进行下一阶段，可能与下一阶段同时完成。\n收集存在死亡对象的 Region\n并发清理  将无存活对象的 Region 进行清理并加入空闲列表。\n并发疏散  将收集集合中的对象复制至空闲 Region 中，此阶段不会造成应用线程暂停。\n初始更新引用  短暂的暂停应用线程，只确保疏散操作均已完成。\n并发更新引用  遍历堆中对象，更新疏散对象的引用。\n最终更新引用  暂停应用线程，堆当前的 Root Set 进行更新，对收集集合的 Region 进行回收。\n并发清理  回收无任何对象引用的 Region。\n","date":1564925402,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1564925402,"objectID":"38065d2a03a30f93a9046a94aeb8af9e","permalink":"https://moyada.github.io/post/shenandoah-gc/","publishdate":"2019-08-04T13:30:02Z","relpermalink":"/post/shenandoah-gc/","section":"post","summary":"介绍 Shenandoah GC 是 OpenJDK 在 JDK12 推出的新一代 标记整理 的垃圾回收器，它的目标时","tags":["GC"],"title":"Shenandoah GC 介绍","type":"post"},{"authors":[],"categories":["JVM"],"content":"什么是 ZGC 由于现在系统日趋增长的内存，传统的垃圾回收器在整理阶段需要花费更长的时间，为了提高 jvm 在大容量内存应用的回收效率，一款新的垃圾回收器 ZGC 在 JDK11 上正式公布问世。通过配置参数 -XX:+UseZGC 开启，目前仅支持 Linux x86 64位的系统。\nZGC 全称 Z Garbage Collector，是一款 低停顿 的标记整理垃圾收集器，它能够在大部分时间与应用线程并行运行。ZGC 在 Oracle 官方资料中表明能够保证垃圾回收中最高 10毫秒 的停顿，而作为低停顿的代价也只是最多下降 15% 的总吞吐量。\n 参考资料: https://openjdk.java.net/projects/zgc/ https://www.youtube.com/watch?v=7k_XfLGu-Ts https://www.youtube.com/watch?v=kF_r3GE3zOo https://dinfuehr.github.io/blog/a-first-look-into-zgc/ https://www.opsian.com/blog/javas-new-zgc-is-very-exciting/ https://mp.weixin.qq.com/s/KUCs_BJUNfMMCO1T3_WAjw https://www.youtube.com/watch?v=tShc0dyFtgw\u0026amp;t=2007s https://www.youtube.com/watch?v=7cWiwu7kYkE http://likehui.top/2019/04/11/ZGC-%E7%89%B9%E6%80%A7%E8%A7%A3%E8%AF%BB/\n 特性 基于 Region 的并发收集模式 ZGC 与 G1 类似，也是以 Region 划分堆内存结构的，不同的是，ZGC 中 Region 是以大小进行分组的，分别是 Small (2MB)、Medium (32MB)、Large (N*MB)，并且尚未进行分代。由于没有了分代，也就没有了 CardTable 和 RememberedSet 的开销。\n使用 NUMA架构技术高效的分配空间和进行对象的扫描 利用 NUMA 架构的 CPU 亲和的内存分配策略，在分配对象时使用线程所处的节点缓存，使线程在操作自身创建的对象时提高效率。\n设计颜色指针标记对象状态，保障引用关系一致 颜色指针就好比状态机，ZGC 在对象地址的其中 4bit 的空间用于标记颜色状态，这四个字节分别称之 Finalizable、 Remapped 、Marked1、 Marked0，通过在不同的收集阶段对指定标记的状态检测，从而采取不同的执行动作。\n由于需要额外的空间来存储标记，因此不支持 32 位平台和指针压缩。\n Makred0、 Marked1 用于识别对象在垃圾回收周期中是否被标记存活，存在两个的原因是因为一个被标记的对象可能来自上一个回收周期并未重新映射，此类对象则只需进行映射而无需重定位。 Remapped 表明该引用对象需要从地址映射表中获取新地址并转移。 Finalizable 表示这是一个 finalizar 对象，只有 Finalizer 可以对其进行访问。  具体逻辑见 hotspot/share/gc/z/zAddress.hpp、hotspot/share/gc/z/zAddress.cpp、hotspot/share/gc/z/zAddress.inline.hpp\n利用 读屏障 修改引用来提高对象的整理迁移功能 对比 G1 使用 写屏障 来保证引用关系一致，ZGC 则是使用 读屏障 来达到。\n在应用线程与 GC 线程同时操作同一对象时，通过读屏障检测对象状态，通过 CAS 对重映射对象进行迁移。\n这种设计使得无需暂停应用线程就能保证引用正确，而读屏障的性能开销只有约 4%。\n触发策略 通过 hotspot/share/gc/z/zDirector.cpp 中可得知，ZGC 与其他 GC 的回收策略有所不同，是一种主动式的垃圾回收模式。\nvoid ZDirector::run_service() { // Main loop while (_metronome.wait_for_tick()) { // 1 sample_allocation_rate(); const GCCause::Cause cause = make_gc_decision(); // 2 if (cause != GCCause::_no_gc) { ZCollectedHeap::heap()-\u0026gt;collect(cause); } } }    在 wait_for_tick 中，JVM 会利用时钟计算等待时间，当到达唤醒时间并且不在安全点期间则执行后续逻辑。\n  make_gc_decision 是根据条件返回回收策略，包含 4 种可执行垃圾回收的策略。\n   ** 定时执行 **  判断当前时间距离上次垃圾回收的差值，当时间差值大于设定的间隔时间时则触发垃圾回收。\n ** 内存预热 **  根据堆内存使用率判断是否进行垃圾回收，当每突破一个 10% 值时进行垃圾回收，例如超过 20%、30% 时。\n ** 吞吐量过大 **  对比剩余空间所需分配时间与最久 GC 时间差值，当大于指定间距时 (默认 0.1) 则说明存在空间不足分配的可能性，需要进行垃圾回收。\n ** 主动触发 **  当距离上次垃圾回收已经过了 5 分钟同时堆空间上涨了 10%，并且距离上次 GC 的时间大于最久 GC 时间的 49 倍。\n 当这些条件满足时 JVM 将会调用 Monitor (synchronized 底层线程安全模块) 唤醒线程，异步 执行垃圾回收。\n 回收过程 ZGC 的回收过程几乎是完全并发进行的，只会在三个阶段进行短短的暂停: 标记开始(mark-start)、标记结束(mark-final)、迁移开始(relocate-start)，具体流程可见于 src/hotspot/share/gc/z/zDriver.cpp::run_gc_cycle()。\n 【标记开始】 开始标记时，会暂停所有应用线程，标记出堆中的 GC Roots。  【并发标记】 释放应用线程，通过 GC Roots 遍历堆中所有对象，找出存活的对象集合 (类似一个 bitmap)。应用线程利用读屏障将对象的变化信息保存于线程中，之后转交由 GC 线程处理引用关系。  【标记结束】 完成所有对象的标记后，短时暂停应用线程，完成标记阶段。  【并发准备】 为下一阶段的重定位做准备，收集那些垃圾对象占比最大或最多的 page 加入 relocate set，每个 page 都分配一个 forwarding table 保存重定向地址，还进行一些其他数据的清理 (比如软弱虚引用、Finalizer 对象、字符串常量池、元数据)。  【迁移开始】 暂停应用线程，扫描 GC Roots 的指向对象，对 relocate set 内对象进行迁移并将重定位地址写入 forwarding table。将本地线程状态设置为 bad mask，对应用线程内对迁移对象的引用标记为 Remapped relocate。分配大块连续空间，以便能够存放要迁移的对象，申请一下阶段所需的工作线程。  【并发迁移】 对 relocate set 中 page 里剩余的存活对象进行迁移，将重定位地址写入 forwarding table 中。应用线程在操作 Remapped relocate 对象时将通过读屏障进行重新映射地址，同时 GC线程 也对程序内的对象引用进行重映射。当映射地址与原地址一致时则表明所有引用均已重映射，标记 page 在之后清除释放空间。   如未重映射对象在下一垃圾回收周期也被标记，则该对象则不会进行分配重定位地址，为了达到这一区别所以才有了 Makred0、 Marked1 两个标记标识。   停顿时间不会随着堆空间的大小增长，但是与 GC Root 的数量是成正比，而 GC Root 的数量则与应用线程的数量有关。 在 GC 的周期内，标记开始和迁移开始操作会比较花费时间，但所有停顿时间总共也是小于 10 毫秒。\n ","date":1561752730,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1561752730,"objectID":"4ba195715822a4e1cec5f0570f709e55","permalink":"https://moyada.github.io/post/zgc/","publishdate":"2019-06-28T20:12:10Z","relpermalink":"/post/zgc/","section":"post","summary":"什么是 ZGC 由于现在系统日趋增长的内存，传统的垃圾回收器在整理阶","tags":["GC"],"title":"ZGC 介绍","type":"post"},{"authors":[],"categories":["Java"],"content":"背景 最近有个需求需要嵌入至其他业务中，其中有个数据需要通过 Eureka 获取，正常情况下使用 @EnableDiscoveryClient 和 @EnableFeignClients 即可获取服务接口实例。可是由于我使用了 BeanPostProcessor 对注解进行了切片代理，并且目标项目也存在非 SpringCloud 项目，那么便只能通过底层 API 构建服务方实例了。\n方案 EurekaClient 提供了服务发现注册功能，但是在 Feign 所接收的属性中并没有用于负载均衡的，其中最有可能的就是 Client 属性了，这是用于负责服务请求的模块，那么就需要调研下是否能够通过 EurekaClient 构建出一个带有负载均衡功能的客户端。\n创建 LBClientFactory  Feign 的官方 Wiki 提供了构建服务实例的 方法，但 Feign 并不提供构建所需属性的实现，而是由其他框架适配 Feign 所提供的接口来实现每个功能。\n 在分析 Ribbon 的 Client 实现 RibbonClient，其构造器接收一个 LBClientFactory 参数，负载均衡的功能就是由它提供。\n通过搜索引擎发现了打通 Robbion 与 EurekaClient 的实现方式，需要引入依赖 \u0026lt;artifactId\u0026gt;ribbon-eureka\u0026lt;/artifactId\u0026gt;。\nprivate Client newClient(String vipAddress, Provider\u0026lt;EurekaClient\u0026gt; provider) { ServerList\u0026lt;DiscoveryEnabledServer\u0026gt; list = new DiscoveryEnabledNIWSServerList(vipAddress, provider); ServerListFilter\u0026lt;DiscoveryEnabledServer\u0026gt; filter = new ZoneAffinityServerListFilter\u0026lt;DiscoveryEnabledServer\u0026gt;(); ZoneAwareLoadBalancer\u0026lt;DiscoveryEnabledServer\u0026gt; lb = LoadBalancerBuilder.\u0026lt;DiscoveryEnabledServer\u0026gt;newBuilder() .withDynamicServerList(list) .withRule(new AvailabilityFilteringRule()) .withServerListFilter(filter) .buildDynamicServerListLoadBalancer(); return RibbonClient.builder().lbClientFactory(new LBClientFactory() { @Override public LBClient create(String clientName) { return LBClient.create(lb, ClientFactory.getNamedConfig(clientName)); } }).build(); }  其中需要使用 DiscoveryEnabledNIWSServerList 用于发现服务集合，它接收两个提供两个参数，一个是项目的 vipAddress，一个是 Provider。\n创建 EurekaClient 在 Eureka 的官方 Wiki 中提供了 EurekaClient 的 构造方式，需要传入 EurekaClientConfig 和 EurekaInstanceConfig 用来提供模块的配置信息。\n在 netflix 提供的 eureka-client 模块下，提供了 DefaultEurekaClientConfig 和 MyDataCenterInstanceConfig。\n这两个类默认将会读取 eureka-client.properties 下的配置，可以通过设置 eureka.client.props 参数更改读取的配置文件，也可以使用 ConfigurationManager 的静态方法来指定读取配置文件。\n除此之外，spring-cloud 也提供了相应的实现类 EurekaClientConfigBean 和 EurekaInstanceConfigBean，通过 spring 的配置资源解析器将属性装配成对象使用。\n入参已经拿到了，但是还未结束，在跟进 DiscoveryClient 代码实现中，发现他在构造方法中会对属性进行静态保存。\n// This is a bit of hack to allow for existing code using DiscoveryManager.getInstance() // to work with DI'd DiscoveryClient DiscoveryManager.getInstance().setDiscoveryClient(this); DiscoveryManager.getInstance().setEurekaClientConfig(config);  在这个项目中，有可能存在业务项目内部与嵌入模块使用了不同的 Eureka 服务，为了保持与业务项目的隔离，这里需要对官方提供的代码模版进行点改造。\nprivate static volatile EurekaClient eurekaClient = null; public EurekaClient initEurekaClient(EurekaInstanceConfig instanceConfig, EurekaClientConfig clientConfig) { if (null != eurekaClient) { return eurekaClient; } synchronized (DiscoveryManager.class) { if (null == eurekaClient) { DiscoveryClient discoveryClient = DiscoveryManager.getInstance().getDiscoveryClient(); EurekaClientConfig eurekaClientConfig = DiscoveryManager.getInstance().getEurekaClientConfig(); EurekaInstanceConfig eurekaInstanceConfig = DiscoveryManager.getInstance().getEurekaInstanceConfig(); // create the client InstanceInfo instanceInfo = new EurekaConfigBasedInstanceInfoProvider(instanceConfig).get(); ApplicationInfoManager infoManager = new ApplicationInfoManager(instanceConfig, instanceInfo); infoManager.setInstanceStatus(InstanceInfo.InstanceStatus.STARTING); EurekaClient client = new DiscoveryClient(infoManager, clientConfig); infoManager.setInstanceStatus(InstanceInfo.InstanceStatus.UP); eurekaClient = client; DiscoveryManager.getInstance().setDiscoveryClient(discoveryClient); DiscoveryManager.getInstance().setEurekaClientConfig(eurekaClientConfig); DiscoveryManager.getInstance().setEurekaInstanceConfig(eurekaInstanceConfig); } } return eurekaClient; }   在实际开发中可通过 DiscoveryManager 的静态属性对其进行管理的，避免重复构建。但是在这个场景下需要保证与业务之间的隔离，则以这种方式构建。\n 创建 Provider 在创建 LBClientFactory 的过程中，我们需要构建 DiscoveryEnabledNIWSServerList 用于服务的发现，由于构造方法接收的参数为 Provider\u0026lt;EurekaClient\u0026gt;，这里还需要对 EurekaClient 再经过包装后使用。\nnew Provider\u0026lt;EurekaClient\u0026gt;() { @Override public EurekaClient get() { return eurekaClient; } };  构造服务实例 通过上述步骤基本完成了一个 EurekaClient 到 RobbionClient 的各个过程，最后代入 Feign 的创建方法中便可构造使用 Eureka 进行服务发现的实例。\npublic \u0026lt;T\u0026gt; T getInstance(Class\u0026lt;T\u0026gt; target, String namespace, Provider\u0026lt;EurekaClient\u0026gt; provider) { return Feign.builder() .client(newClient(namespace, provider)) .encoder(new JacksonEncoder()) .decoder(new JacksonDecoder()) .options(new Request.Options(1000, 3000)) .logLevel(Logger.Level.FULL) .target(target, \u0026quot;http://\u0026quot; + namespace); }  ","date":1558169246,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1558169246,"objectID":"176dbba5b1f8b9865463a3e03f6bb5ce","permalink":"https://moyada.github.io/post/feign-eureka-without-springboot/","publishdate":"2019-05-18T08:47:26Z","relpermalink":"/post/feign-eureka-without-springboot/","section":"post","summary":"背景 最近有个需求需要嵌入至其他业务中，其中有个数据需要通过 Eureka","tags":["Spring"],"title":"在非 SpringBoot 工程中实现 Eureka 构建 Feign 服务","type":"post"},{"authors":[],"categories":["Java"],"content":"在 Java 中，对一个类的子类判断有三种方式，分别是 obj instanceof [TypeName]、class.isInstance(obj)、class.isAssignableFrom(class)，他们的作用都是进行父子类型判断，然而他们的区别又在什么地方。\n  其中 instanceof 是一个 Java 原语，通过对象与类型签名进行判断，需要在编译期就进行解析成字节码。跟进 JVM 源码里，在 templateTable.hpp 中发现了 instanceof 方法的定义，从其中 templateTable_x86.cpp、templateTable_arm.cpp 的 instanceof 方法可得，其实现方式主要是通过汇编指令从 klass 中获取标记进行判断，逻辑比较长也就不一一分析了。对于这段冗长的汇编代码，JVM 也进行了优化，当触发 JIT 编译时，会把这段逻辑编译成机器码写入 C1 层。\n  isInstance 是 Class 类下的 native 方法，接收参数为对象。分析了在 jni.cpp 中的大体流程，程序先通过 class 获取到 Klass，调用 object 内 klass 的 is_subtype_of 方法，传入方才获取的 Klass，判断二者地址是否相同，是则判定为同一类型，否则再调用 search_secondary_supers，判断父级类型是否存在与传入的 Klass 相匹配。\n  JNI_QUICK_ENTRY(jboolean, jni_IsInstanceOf(JNIEnv *env, jobject obj, jclass clazz)) JNIWrapper(\u0026quot;IsInstanceOf\u0026quot;); HOTSPOT_JNI_ISINSTANCEOF_ENTRY(env, obj, clazz); jboolean ret = JNI_TRUE; if (obj != NULL) { ret = JNI_FALSE; Klass* k = java_lang_Class::as_Klass( JNIHandles::resolve_non_null(clazz)); if (k != NULL) { ret = JNIHandles::resolve_non_null(obj)-\u0026gt;is_a(k) ? JNI_TRUE : JNI_FALSE; } } HOTSPOT_JNI_ISINSTANCEOF_RETURN(ret); return ret; JNI_END  // hotspot/share/oops/oop.inline.hpp bool oopDesc::is_a(Klass* k) const { return klass()-\u0026gt;is_subtype_of(k); }  // hotspot/share/oops/klass.hpp // subtype check: true if is_subclass_of, or if k is interface and receiver implements it bool is_subtype_of(Klass* k) const { juint off = k-\u0026gt;super_check_offset(); Klass* sup = *(Klass**)( (address)this + off ); const juint secondary_offset = in_bytes(secondary_super_cache_offset()); if (sup == k) { return true; } else if (off != secondary_offset) { return false; } else { return search_secondary_supers(k); } } bool Klass::search_secondary_supers(Klass* k) const { // Put some extra logic here out-of-line, before the search proper. // This cuts down the size of the inline method. // This is necessary, since I am never in my own secondary_super list. if (this == k) return true; // Scan the array-of-objects for a match int cnt = secondary_supers()-\u0026gt;length(); for (int i = 0; i \u0026lt; cnt; i++) { if (secondary_supers()-\u0026gt;at(i) == k) { ((Klass*)this)-\u0026gt;set_secondary_super_cache(k); return true; } } return false; }  isAssignableFrom 也是 Class 类下的 native 方法，接收参数为 Class 类。主要逻辑与 isInstance 相同，区别在于当 主体 Class 与 参数 Class 其中一个为原生类型时，则选择使用对象头判断类型是否相等。  isInstance 和 isAssignableFrom 对入参校验上也有区别，isInstance 当对象为空时将会返回 false isAssignableFrom 则会对参数进行非空校验。\nisInstance 和 isAssignableFrom 在方法标记上都有 @HotSpotIntrinsicCandidate，会被 JVM 使用更高效的字节码替换，节省了 JNI 调用的开销。\nJNI_QUICK_ENTRY(jboolean, jni_IsAssignableFrom(JNIEnv *env, jclass sub, jclass super)) JNIWrapper(\u0026quot;IsSubclassOf\u0026quot;); HOTSPOT_JNI_ISASSIGNABLEFROM_ENTRY(env, sub, super); oop sub_mirror = JNIHandles::resolve_non_null(sub); oop super_mirror = JNIHandles::resolve_non_null(super); if (java_lang_Class::is_primitive(sub_mirror) || java_lang_Class::is_primitive(super_mirror)) { jboolean ret = oopDesc::equals(sub_mirror, super_mirror); HOTSPOT_JNI_ISASSIGNABLEFROM_RETURN(ret); return ret; } Klass* sub_klass = java_lang_Class::as_Klass(sub_mirror); Klass* super_klass = java_lang_Class::as_Klass(super_mirror); assert(sub_klass != NULL \u0026amp;\u0026amp; super_klass != NULL, \u0026quot;invalid arguments to jni_IsAssignableFrom\u0026quot;); jboolean ret = sub_klass-\u0026gt;is_subtype_of(super_klass) ? JNI_TRUE : JNI_FALSE; HOTSPOT_JNI_ISASSIGNABLEFROM_RETURN(ret); return ret; JNI_END  总结一下，instanceof、isInstance、isAssignableFrom 其实无太大区别，instanceof 和 isInstance 适用于主体是对象，并且 instanceof 需要在编译期就指定类型，灵活性不如 isInstance。而 isAssignableFrom 是针对两个类的关系校验，在泛型对比上比较适合。\n 参考: https://stackoverflow.com/questions/496928/what-is-the-difference-between-instanceof-and-class-isassignablefrom\n ","date":1557087812,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1557087812,"objectID":"a509177e83ef430db30c8e0a2c3aca32","permalink":"https://moyada.github.io/post/instanceof-vs-isassignablefrom/","publishdate":"2019-05-05T20:23:32Z","relpermalink":"/post/instanceof-vs-isassignablefrom/","section":"post","summary":"在 Java 中，对一个类的子类判断有三种方式，分别是 obj instanceof [TypeN","tags":[],"title":"instanceOf、isInstance、isAssignableFrom 的区别","type":"post"},{"authors":[],"categories":["Java"],"content":"背景 最近接到一个需求，涉及到大流量的数据传输，那么就不可避免序列化，正巧我也有想法对最近主流的序列化框架做一次对比。\n参数对比的序列化的框架如下，将对 序列化数据字节大小、序列化\\反序列化平均耗时、序列化\\反序列化吞吐量 这三个维度进行对比。\n 该测试结果可能因为机器原因、框架使用方式、样本数据问题，导致结果不准确。\n 工程代码见 https://github.com/moyada/java-serializers\n   框架 版本     avro 1.8.2   hessian 4.0.60   jackson 2.9.8   fastjson 1.2.57   gson 2.8.5   kryo 4.0.2   protobuf 3.7.1   protostuff 1.5.9    这里我对所有框架再进行了一次封装，更方便接入测试，也是一般开发中的正常操作，在序列化框架的使用上主要是参考官方文档。\n测试环境 JDK 版本为 1.8.0_191，使用 BenchMark 进行测试，环境参数为\n# VM options: -server -Xms2048m -Xmx2048m -XX:+UseTLAB -XX:+UseG1GC # Warmup: 3 iterations, 40 s each # Measurement: 5 iterations, 60 s each # Timeout: 10 min per iteration # Threads: 10 threads, will synchronize iterations  测试的数据结构如下，数据统一为 {\u0026quot;id\u0026quot;: 34501231422, \u0026quot;name\u0026quot;: \u0026quot;moyada\u0026quot;, \u0026quot;age\u0026quot;: 18, \u0026quot;gender\u0026quot;: true, \u0026quot;scope\u0026quot;: 33.23, \u0026quot;identifies\u0026quot;: [\u0026quot;moyada\u0026quot;, \u0026quot;people\u0026quot;, \u0026quot;person\u0026quot;, \u0026quot;animal\u0026quot;], \u0026quot;info\u0026quot;: {\u0026quot;haha\u0026quot;: \u0026quot;666\u0026quot;, \u0026quot;test\u0026quot;: \u0026quot;111\u0026quot;}}。\npublic class User implements Serializable { private long id; private String name; private int age; private boolean gender; private Double scope; private List\u0026lt;String\u0026gt; identifies; private Map\u0026lt;String, String\u0026gt; info; }  序列化后数据对比    框架 字节大小     Avro 76   Protobuf 76   Protostuff 79   Kryo 109   Hessian 140   Gson 140   FastJson 140   Jackson 153    平均耗时对比 序列化平均耗时    框架 耗时 方差 单位时间     Avro 11189.699 228.857 ns   Fastjson 8859.637 58.009 ns   Gson 14581.029 59.314 ns   Hessian 16504.562 85.219 ns   Jackson 8795.401 48.109 ns   Kryo 12437.866 52.945 ns   Protobuf 10775.097 147.737 ns   Protostuff 6027.095 33.662 ns    反序列化平均耗时    框架 耗时 方差 单位时间     Avro 25422.477 658.969 ns   Fastjson 8736.501 81.286 ns   Gson 10366.847 941.759 ns   Hessian 9293.557 543.865 ns   Jackson 9594.744 103.369 ns   Kryo 9190.082 243.400 ns   Protobuf 5455.168 120.927 ns   Protostuff 4861.520 31.993 ns    平均耗时综合对比 吞吐量对比 序列化吞吐量    框架 吞吐量 方差 单位时间     Avro 951.174 15.053 ms   Fastjson 1160.132 11.835 ms   Gson 711.199 8.525 ms   Hessian 620.666 4.321 ms   Jackson 1215.150 19.994 ms   Kryo 836.276 16.079 ms   Protobuf 1103.661 18.079 ms   Protostuff 1756.591 27.101 ms    反序列化吞吐量    框架 吞吐量 方差 单位时间     Avro 389.745 24.479 ms   Fastjson 1103.777 29.458 ms   Gson 977.951 38.406 ms   Hessian 1153.816 44.385 ms   Jackson 1072.346 12.922 ms   Kryo 1098.548 33.257 ms   Protobuf 1847.549 43.935 ms   Protostuff 2055.013 61.317 ms    吞吐量综合对比 总结 综合对比下来，抛开未采样的内存占用及 cpu 消耗，大部分序列化框架效率还是比较不错的。\nAvro 在反序列化时耗时比较严重，怀疑是否因为多线程而导致的，并且在反序列化后 map 数据还发生了顺序变化。\nProtostuff 在各方面都优于其他框架，但是需要预先定义类，不过比起 Protobuf、Thrift 等预先定义数据格式已经方便很多了。\n如果传输量不是很大，但是对数据的可视化有要求的，那么 Fastjson 和 Jackson 是不错的选择，而且 json 格式在跨语言上也天然有优势。\n","date":1556914786,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1556914786,"objectID":"c1ada70a5347edb25bc2a9f73ff32fa9","permalink":"https://moyada.github.io/post/java-serializer/","publishdate":"2019-05-03T20:19:46Z","relpermalink":"/post/java-serializer/","section":"post","summary":"背景 最近接到一个需求，涉及到大流量的数据传输，那么就不可避免","tags":[],"title":"序列化框架对比","type":"post"},{"authors":[],"categories":["运维"],"content":"前言 系统监控是中大型企业中必不可少的组件，在线上服务器遇到负载问题时通过监控便能够查看系统状态快照，还能够通过监控系统开发其他效能组件，进一步提高系统的可用性。\n监控应用程序 通常情况下，要想获得应用的负载情况就需要改造原有工程，提供 pull 或 push 的方式将应用状况进行上报。\nPrometheus 使用的是 pull 模式，在应用中开放端口提供系统状态信息，监控系统可以定时从应用中拉取记录。\n 在 SpringBoot 应用中引入依赖  \u0026lt;!-- prometheus --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;io.micrometer\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;micrometer-registry-prometheus\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;!-- endpoint --\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.springframework.boot\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;spring-boot-starter-actuator\u0026lt;/artifactId\u0026gt; \u0026lt;/dependency\u0026gt;  配置暴露的 endpoint 及系统标识  management.metrics.tags.application=${spring.application.name} # 开放全部监控，或选择配置，如 prometheus, health management.endpoints.web.exposure.include=*  启动完成后通过 {host}:{port}/actuator/prometheus 可以查看暴露的度量指标\n监控中心 通过 https://prometheus.io/docs/prometheus/latest/getting_started/ 下载合适的 Prometheus 版本\n解压后修改 prometheus.yml 配置，增加目标应用的监控配置\n... scrape_configs: - job_name: 'targetProject' scrape_interval: 5s metrics_path: '/actuator/prometheus' static_configs: - targets: ['127.0.0.1:8080']  修改后通过命令 ./prometheus -config.file=prometheus.yml 启动 Prometheus，并进入管理页面 http://127.0.0.1:9090 检查 Endpoint 状态。\nGrafana 数据可视化   通过 http://docs.grafana.org/installation/ 选择合适的版本安装\n  访问 http://127.0.0.1:3000 ，默认账号 admin/admin\n  添加 Prometheus 数据源，进入 Configuration/DataSources 配置监控中心地址。\n  导入 Dashboard，对数据的采集展示配置可通过 https://grafana.com/dashboards 获取已有配置，填写 dashboardId 导入 (如 8919/4701)。\n   也可通过 Add panel 增加监控面板，再选择 Add Query 设置监控主体，监控语句可通过 http://127.0.0.1:9090/graph 获取。\n ","date":1553354310,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1553354310,"objectID":"76838551935ef1135e4702a9f59beb1e","permalink":"https://moyada.github.io/post/prometheus-grafana/","publishdate":"2019-03-23T15:18:30Z","relpermalink":"/post/prometheus-grafana/","section":"post","summary":"前言 系统监控是中大型企业中必不可少的组件，在线上服务器遇到负","tags":[],"title":"使用 Prometheus + Grafana 搭建监控系统","type":"post"},{"authors":[],"categories":["Java"],"content":"Spring 工程中一般以 xml (spring-framework) 和 yml (spring-boot) 做为配置文件，配置除了框架提供的也支持增加其他配置，它们是以同样的形式注册到 Spring 中的。\n1. xml 配置 这是早期 Spring 提供的配置方式，需要与 xsd 文件配合使用。\n文件的解析是需要通过实现 org.springframework.beans.factory.xml.NamespaceHandlerSupport 提供解析器，在 init 方法中调用 registerBeanDefinitionParser 将 xsd元素名称 与 元素解析器 进行绑定。\n对于 xsd元素 所绑定的解析器是 org.springframework.beans.factory.xml.BeanDefinitionParser，实现元素到 BeanDefinition 的转换，并交由 Spring 容器进行实例注册。\n最后需要将完成的解析器与 xsd文件 通过 META-INF/spring.handlers 和 META-INF/spring.schemas 进行映射，在 spring.schemas 中以 命名空间地址 = xsd文件路径 的形式配置，在 spring.handlers 中以 命名空间地址 = 解析器类全路径 的形式配置。\n 由于 yml 配置的便捷性导致了 xml 配置方式在开发中逐渐被替换。\n 2. yml 配置 跟随 spring-boot 一起出现的配置模式，相较于 xml 显得尤其简便。同时也舍弃了 xml 的解析器，使用等同于 @Conditional 的注册 Configuration 在 Spring 的生命周期进行容器管理。\nEnable 注解 这种方式主要是提供注解使用，并在注解内配置 @Import 显式的注册 Configuration。\n例如 @EnableAspectJAutoProxy, @EnableScheduling, @EnableMBeanExport。\n自动装配 通过创建 META-INF/spring.factories 文件，配置需要装配的 Configuration 即可。其原理是使用了 @EnableAutoConfiguration 注解，通过注册的 AutoConfigurationImportSelector 扫描所有依赖 jar 包内的 META-INF/spring.factories，将配置的 Configuration 进行注册。与显式注解形式配置有所不同，这种方式配置的 Configuration 还可以使用 @AutoConfigureAfter 和 @AutoConfigureBefore 控制执行顺序。\n 这种是最为常见的使用方式，一般还需构建 spring-boot-starter 提供使用，具体使用见 官方文档\n 动态注册配置 结合了 Enable 注解 和 自动装配 的方式，能够更加灵活的配置 Configuration。实现方式为提供 Enable注解，并且在注解内配置 @Import ImportSelector，通过 ImportSelector 返回 Configuration 列表提供给 Spring 注册，可以根据条件控制返回的 Configuration，又或是提供类似 自动装配 的功能。\n例如 @EnableAutoConfiguration, @EnableAsync, @EnableCaching。\n","date":1550953864,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1550953864,"objectID":"e78f6adcc2cfa2a8d3ae4e12d7e8c802","permalink":"https://moyada.github.io/post/spring-configure/","publishdate":"2019-02-23T20:31:04Z","relpermalink":"/post/spring-configure/","section":"post","summary":"Spring 工程中一般以 xml (spring-framework) 和 yml (spring-boot) 做为配置文件，配置除了框架提供的也支","tags":["Spring"],"title":"Spring 自定义配置加载","type":"post"},{"authors":[],"categories":["Java"],"content":"工作流程 注解处理器是一种应用于编译期间的模块，在编译完源文件后，编译器会解析类信息，转换成抽象语法树，接着执行注册的注解处理器，解析语法树是否发生了变化并重新生成源文件，接着调用下一个注解处理器。\n 编译器具体处理过程可查看 OpenJDK 官方文档: https://openjdk.java.net/groups/compiler/doc/compilation-overview/index.html\n   定义注解 创建注解处理器的第一步就是需要定义相关注解，并且在注解上定义 @Retention，当指定为 RetentionPolicy.SOURCE 时，该注解即在编译结束后会被擦除。\n  创建处理器 接着就需要创建处理器了，一般可通过继承 javax.annotation.processing.AbstractProcessor 定义处理器，由于注解处理器是通过反射获取的，所以需要提供无参构造函数。\n  设置解析注解 重写 getSupportedAnnotationTypes 或定义 @SupportedAnnotationTypes 将先前定义的注解类名加入解析目标，也可以使用 * 通配符。\n  指定支持版本 对于存在源文件版本需求的处理器，则可以通过重写 SupportedSourceVersion 或定义 @SupportedSourceVersion 来指定版本。\n  初始化处理器 注解处理器拥有许多可供使用的工具类，但是这些工具类需要通过 init 方法的 ProcessingEnvironment 才可获取，一般做法也是重写此方法，提取所需工具对象保存至处理器中。\n  实现处理流程 注解处理器的核心流程为 process 方法，可通过参数 RoundEnvironment 获取被注解标记的元素，实现想提供的功能，一般为 动态创建源文件 或 修改语法树。\n  注册处理器 注册注解处理器的方式可以在编译时通过 javac -processor 指定。 也可以配置自动加载，依照 ServiceLoader 形式，在 META-INF/services 下创建名为 javax.annotation.processing.Processor 的文件，将创建的注解处理器全类名填入，由于注解处理器是作用于编译期的，在编译时需要增加参数 -proc:none 以不使用注解处理器。\n  创建文件 文件的创建需要通过 javax.annotation.processing.Filer 来实现，可通过 init 方法获取。 通过 Filer 可以新建源文件并获取 JavaFileObject，以 Java 代码的方法将内容写入源文件。\nMapStruct 和 JavaPoet 就是利用这个功能开发的工具。\n修改语法树 对比创建文件，修改语法树则是十分复杂且麻烦的工作，同样要通过 init 获取语法树构造器 com.sun.source.util.Trees。 通过 Trees 可以将元素转换为语法树，并接受 Visitor 以进行语法树节点扫描和修改，一般监视器的实现可以通过继承 TreeTranslator 或 TreeScanner，对需要的方法进行重写。\n而语法树操作的难点在于其他方面:\n  文档的缺少，这是无疑是对开发人员不友好的。\n  不稳定 api，有可能这个版本还能用的，在下一个版本就无效了。\n  未知的异常，可能由于操作失误而引发的，而且通过异常信息无法准确定位问题。\n  无法很好的控制注解处理器之间的顺序。\n  Lombok 就是一种修改语法树的工具。\n 这是我开发的一款通过修改语法树增加方法校验功能的工具: https://moyada.github.io/medivh/\n ","date":1547581215,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1547581215,"objectID":"ba8668fe3af6ba7b82603b042ce358ef","permalink":"https://moyada.github.io/post/java-annotation-processor/","publishdate":"2019-01-15T19:40:15Z","relpermalink":"/post/java-annotation-processor/","section":"post","summary":"工作流程 注解处理器是一种应用于编译期间的模块，在编译完源文件","tags":[],"title":"Java 注解处理器","type":"post"},{"authors":[],"categories":["JVM"],"content":"介绍 在 Java 中 synchronized 是用于并发环境下使用临界区的原语。\n它是通过获取对象头的 Mark Word 来实现互斥功能的，当使用方式不同时所操作的对象也不同。\n  声明在方法内时，锁对象由开发者所指定\n  声明在方法上，锁对象则为当前类的实例\n  声明在静态方法上，锁对象就是由类加载器所加载的 Class\n  这里简单记录 synchronized 代码块在虚拟机内部的运转，版本为 OpenJDK11。\n获取同步锁 当线程进入临界区时，会根据是否开启了偏向锁选择进入 ObjectSynchronizer::fast_enter 方法或者 ObjectSynchronizer::slow_enter 方法。\nObjectSynchronizer::fast_enter   检查当前 Mark Word 的锁状态是否为偏向锁，否则进入 slow_enter。\n  检查虚拟机当前是否处于安全点，是则先进行检查是否需要撤销偏向锁。\n  检查对象头是否为偏向锁模式，否则使用 CAS 修改 Mark Word 存储的线程 id，并初始化获取锁时间点和年龄。\n  当已经处于偏向锁模式时，并且当前占有锁的时间已过期，则可以使用 CAS 进行锁替换或者更新年龄。\n  当任意 CAS 操作失败时，则表明存在其他线程已对锁状态进行了修改，需要执行 slow_enter。\n  更新对象头信息，检查是否需要撤销偏向锁。\n  ObjectSynchronizer::slow_enter   判断 Mark Word 的锁状态是否为无锁或偏向锁，是则使用 CAS 修改对象头，成功后对当前 Region 栈锁进行释放。\n  否则判断 Mark Word 的锁状态是否为轻量级锁，并且对对象头的 BasicLock 进行加锁。\n  失败时将修改对象头使其不可重入，并将锁膨胀为重量级锁，修改 Mark Word。\n  通过 ObjectMonitor 管理当前线程，当对象头为轻量级锁时，获取空闲 ObjectMonitor 使用，并配置至对象头内。\n   ObjectMonitor 的获取方式为依次从 线程空间中查找空闲监视器、全局空间中查找空闲监视器、重新创建监视器 选取尝试。  等待与唤醒 wait 当处于临界区内的线程由于某种原因选择将自身挂起时，将执行 ObjectSynchronizer::wait。\n  判断当前 Mark Word 是否为偏向锁，是则对其进行撤销。\n  释放临界区占用锁，获取管理当前线程的的 ObjectMonitor。\n  将线程封装为 ObjectWaiter 加入至 _WaitSet 队尾。\n  设置 LoadLoad 内存屏障，防止重排序问题。\n  判断是否该等待线程是否已经存在，是否重新启动该线程。\n  关闭非运行线程与重入锁的响应。\n  判断线程是否已被中断，是则抛出异常。\n  notify/notifyAll   检查等待队列 _WaitSet，为空则直接返回。\n  使用 _WaitSetLock 保护操作等待队列不被其他线程干扰。\n  根据策略选择从等待队列中获取元素加入到阻塞队列 _EntryList 或 _cxq 或 直接唤醒。\n  设置被移动线程为可与重入锁响应。\n  释放 _WaitSetLock 锁。\n  阻塞线程 enter 当进入临界区的线程获取锁失败时，将交由锁对象的 objectMonitor 来管理，调用 enter 方法修改该线程状态为阻塞，并封装为 ObjectWaiter 加入到名为 _EntryList 的链表中。\nexit 当有线程离开临界区，将会调用 objectMonitor 的 exit 方法，根据 QMode 的不同的选择从 阻塞队列 或 等待队列 中获取 ObjectWaiter，也可能将等待队列的部分或全部加入阻塞队列后从阻塞队列中获取。\n","date":1547415564,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1547415564,"objectID":"61ee1d6507b464842921c3d979eb5fc6","permalink":"https://moyada.github.io/post/java-synchronized/","publishdate":"2019-01-13T21:39:24Z","relpermalink":"/post/java-synchronized/","section":"post","summary":"介绍 在 Java 中 synchronized 是用于并发环境下使用临界区的原语。 它是通过获取对","tags":[],"title":"synchronized 原理总结","type":"post"},{"authors":[],"categories":["Maven"],"content":"当项目准备发布至 maven 中央仓库时，基本上按照官方指南操作就行了。\n https://central.sonatype.org/pages/ossrh-guide.html\n 创建发布需求 在创建问题时需要注意，如果 groupId 选择的是私有域名时，那么管理员会要求验证域名的归属，而对于 github 的子域名则无需验证。\n接下来管理员会要求你进行第一次的发布操作，在发布前你需要使用 gpg 创建你的秘钥。\n创建秘钥 Mac 下可以通过 brew 下载安装，使用命令 gpg --gen-key 生成，完成后通过 gpg --list-keys 即可查看已创建秘钥。\n接下来需要将秘钥发布到远程服务器上，如 gpg --keyserver hkp://keyserver.ubuntu.com:11371 --send-keys \u0026lt;sec_key\u0026gt;，发布后可以使用 gpg --keyserver hkp://keyserver.ubuntu.com:11371 --recv-keys \u0026lt;sec_key\u0026gt; 进行验证。\n发布项目 发布完成后就可以进行项目的配置了，注意 \u0026lt;gpg.executable\u0026gt;gpg\u0026lt;/gpg.executable\u0026gt; 这项配置填写的是你实际操作秘钥的程序。\n发布时需要验证秘钥的密码，可以选择添加参数 -Dgpg.passphrase 或者验证时手动输入。\n 如果发生错误提示 gpg: signing failed: Inappropriate ioctl for device 是由于 gpg 无法在当前终端弹出密码输入页面，执行 export GPG_TTY=$(tty) 以支持弹窗。   如果进行本地安装则可以使用 Dgpg.skip 参数或在 maven-gpg-plugin 插件下增加配置 \u0026lt;configuration\u0026gt;\u0026lt;skip\u0026gt;true\u0026lt;/skip\u0026gt;\u0026lt;/configuration\u0026gt; 跳过验证步骤。\n 验证发布 发布成功后还需要回到需求问题下回复管理员，待管理员回复后一会可在中央仓库查看到自己的项目了。\n后续版本的发布则直接进行发布就可以了。\n","date":1546444992,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1546444992,"objectID":"ffa2b1769f1f51e959c95766d6d54e66","permalink":"https://moyada.github.io/post/maven-central/","publishdate":"2019-01-02T16:03:12Z","relpermalink":"/post/maven-central/","section":"post","summary":"当项目准备发布至 maven 中央仓库时，基本上按照官方指南操作就行了。","tags":[],"title":"发布 jar 包至 maven 官方中央仓库","type":"post"},{"authors":[],"categories":["JVM"],"content":"JMX 的全称为 Java Management Extensions，是一种监控、管理正在运行的 Java 应用程序的机制，并且支持开发人员自定义 MBean 监视器。\n常用 MXBean 通过查询 java.lang.management.PlatformManagedObject 的继承接口能够得知当前 JDK 版本提供的所有 MXBean。\n   类名 功能     java.lang.management.CompilationMXBean 编译器的管理接口   java.lang.management.ClassLoadingMXBean 类加载模块的管理接口   java.lang.management.BufferPoolMXBean 堆外内存和映射内存的管理接口   java.lang.management.MemoryManagerMXBean 内存管理器的管理接口   java.lang.management.MemoryMXBean 虚拟机的内存系统的管理接口   java.lang.management.MemoryPoolMXBean 内存池的管理接口   java.lang.management.OperatingSystemMXBean 操作系统的管理接口   java.lang.management.GarbageCollectorMXBean 垃圾回收的管理接口，继承至 MemoryManagerMXBean   java.lang.management.RuntimeMXBean 虚拟机的运行时系统的管理接口   java.lang.management.ThreadMXBean 线程的管理接口   java.lang.management.PlatformLoggingMXBean 日志模块的管理接口   javax.management.DynamicMBean 扩展管理接口，用于自定义管理器    在 com.sun.management 包下，还提供了部分 MXBean 的扩展接口，对原来管理器的功能进行了增强。\n管理方式 监视器的获取方式分为 本地、远程、代理，通常情况下使用远程方式进行管理。\n本地 对于运行在本机的程序直接使用 java.lang.ManagementFactory 的静态方法便可以获取。\n远程 远程模式可以通过建立与其他虚拟机的连接后对其进行操作。\n 建立连接  String url = \u0026quot;service:jmx:rmi:///jndi/rmi://\u0026quot; + host + \u0026quot;:\u0026quot;+ port + \u0026quot;/\u0026quot; + extend; JMXServiceURL serviceURL = new JMXServiceURL(url); JMXConnector conn = JMXConnectorFactory.connect(serviceURL); MBeanServerConnection connection; try { connection = conn.getMBeanServerConnection(); } catch(IOException e) { e.printStackTrace(); }  监听管理  MemoryMXBean memBean = ManagementFactory.getPlatformMXBean(connection, MemoryMXBean.class);  代理 由于 Mbean 在注册的时候有 ObjectName 的存在，对于自定义 MBean 则必须使用此方式指定 ObjectName 方可获取。\nMemoryMXBean memBean = ManagementFactory.newPlatformMXBeanProxy(connection, ManagementFactory.MEMORY_MXBEAN_NAME, MemoryMXBean.class); // 指定 MBean 的特定属性值 ObjectName objectName = new ObjectName(\u0026quot;domain:type=name\u0026quot;); // 对应 getUser 或者 setUser 操作 connection.setAttribute(objectName, new Attribute(\u0026quot;User\u0026quot;,\u0026quot;remote\u0026quot;)); DynamicMBean dynamicMBean = MBeanServerInvocationHandler.newProxyInstance(connection, objectName, DynamicMBean.class, true);  注册方式 自定义 MBean Java 规范对注册的 MBean 的命名有严格的规范，要求必须是以 MBean 结尾的接口 (MXBean 也行，不过为了与 JDK 的区分，一般使用 MBean)。\n注册的方法也是有标准的，以 set 或 get 开头并且参数规范的方法将会被隐藏，对于参数只支持 基本类型、数组、void。隐藏的方法可以通过 属性 来访问，属性将由 JDK 解析方法名生成。\n为了方便 ManagementFactory 调用，可以使用提供的 DynamicMBean 接口进行实现，或者使用更简便的 com.sun.jmx.mbeanserver.StandardMBeanSupport 进行构建。\n注册 MBean 的注册管理是通过 javax.management.MBeanServer 来进行的，并且指定名称 javax.management.ObjectName。\nStandardMBeanSupport mbean = new StandardMBeanSupport(new Object(), Interface.class); MBeanServer beanServer = ManagementFactory.getPlatformMBeanServer(); try { final ObjectName objectName; try { objectName = ObjectName.getInstance(\u0026quot;domain:type=name\u0026quot;); } catch (MalformedObjectNameException e) { e.printStackTrace(); return; } // 跳过 ManagementPermission 的权限校验 AccessController.doPrivileged(new PrivilegedExceptionAction\u0026lt;Void\u0026gt;() { public Void run() throws MBeanRegistrationException, NotCompliantMBeanException { try { if (beanServer.isRegistered(objectName)) { beanServer.unregisterMBean(objectName); } beanServer.registerMBean(mbean, objectName); return null; } catch (InstanceAlreadyExistsException | InstanceNotFoundException var2) { return null; } } }); } catch (PrivilegedActionException e) { e.printStackTrace(); }  开放端口 当需要通过远程进行 Java 应用管理时，就需要通过提供端口以供访问了，通过先前的 MBeanServer 构建 JMX 连接。\ntry { LocateRegistry.createRegistry(port); } catch (RemoteException e) { return; } try { JMXServiceURL url = new JMXServiceURL(\u0026quot;service:jmx:rmi:///jndi/rmi://127.0.0.1:\u0026quot; + port + \u0026quot;/\u0026quot; + extend); JMXConnectorServer cs = JMXConnectorServerFactory.newJMXConnectorServer(url, null, beanServer); cs.start(); } catch (IOException e) { e.printStackTrace(); }  安全 对远程开放端口可设置 SSL、权限校验，只需对 JMXConnectorServer 增加配置选项即可\nMap\u0026lt;String, Object\u0026gt; env = new HashMap\u0026lt;String, Object\u0026gt;(); // 对 env 增加配置 ... JMXConnectorServer cs = JMXConnectorServerFactory.newJMXConnectorServer(url, env, mbs); cs.start();  开启 SSL 连接 // Server env.put(RMIConnectorServer.RMI_CLIENT_SOCKET_FACTORY_ATTRIBUTE, new SslRMIClientSocketFactory()); env.put(RMIConnectorServer.RMI_SERVER_SOCKET_FACTORY_ATTRIBUTE, new SslRMIServerSocketFactory();  设置权限认证 // Server SimpleAuthenticator auth = new SimpleAuthenticator(); evn.put(JMXConnectorServer.AUTHENTICATOR, auth); env.put(\u0026quot;jmx.remote.sasl.callback.handler\u0026quot;, new CallbackHandler() {...}); class SimpleAuthenticator implements JMXAuthenticator { private final Map\u0026lt;String, Auth\u0026gt; authRole; public SimpleAuthenticator() { authRole = new HashMap\u0026lt;\u0026gt;(); } public boolean addAuth(String username, String password) { return addAuth(username, password, true); } public boolean addAuth(String username, String password, boolean readOnly) { if (authRole.containsKey(username)) { return false; } authRole.put(username, new Auth(password, readOnly)); return true; } public boolean removeAuth(String username) { return authRole.remove(username) != null; } @Override public Subject authenticate(Object credentials) { if (!(credentials instanceof String[])) { throw new SecurityException(\u0026quot;Authentication failed!\u0026quot;); } String[] credentialsInfo = (String[]) credentials; if (credentialsInfo.length != 2) { throw new SecurityException(\u0026quot;Authentication failed!\u0026quot;); } String userName = credentialsInfo[0]; Auth auth = authRole.get(userName); if (auth == null) { throw new SecurityException(\u0026quot;Invalid Authentication!\u0026quot;); } String password = credentialsInfo[1]; if (auth.password.equals(password)) { return new Subject(auth.readOnly, Collections.singleton(new JMXPrincipal(userName)), Collections.EMPTY_SET, Collections.EMPTY_SET); } throw new SecurityException(\u0026quot;Invalid Authentication!\u0026quot;); } class Auth { String password; boolean readOnly; Auth(String password, boolean readOnly) { this.password = password; this.readOnly = readOnly; } } }  // Client String[] credentials = new String[] { \u0026quot;username\u0026quot; , \u0026quot;password\u0026quot; }; env.put(JMXConnectorServer.AUTHENTICATOR, credentials); env.put(\u0026quot;jmx.remote.sasl.callback.handler\u0026quot;, new CallbackHandler() {...}); JMXConnector conn = JMXConnectorFactory.connect(serviceURL, env);  协议扩展 // Server Security.addProvider(new com.sun.security.sasl.Provider()); env.put(\u0026quot;jmx.remote.profiles\u0026quot;, \u0026quot;TLS SASL/PLAIN\u0026quot;); env.put(\u0026quot;jmx.remote.x.access.file\u0026quot;, \u0026quot;config\u0026quot; + File.separator + \u0026quot;access.properties\u0026quot;); JMXServiceURL url = new JMXServiceURL(\u0026quot;jmxmp\u0026quot;, null, 5555); JMXConnectorServer cs = JMXConnectorServerFactory.newJMXConnectorServer(url, env, beanServer); cs.start();  // Client Security.addProvider(new com.sun.security.sasl.Provider()); env.put(\u0026quot;jmx.remote.profiles\u0026quot;, \u0026quot;TLS SASL/PLAIN\u0026quot;); JMXServiceURL url = new JMXServiceURL(\u0026quot;jmxmp\u0026quot;, null, port); JMXConnector jmxc = JMXConnectorFactory.connect(url, env);   详细步骤可见: https://docs.oracle.com/cd/E19698-01/816-7609/6mdjrf86r/index.html\n 监听 主要用于 JMX 连接状态和 MXBean 调用的监听。\n通过实现 javax.management.NotificationListener 创建监听处理器，加入到 NotificationBroadcaster 的实现类下。\njmxConnector.addNotificationListener((notification, handback) -\u0026gt; {...}, null, handback);  如果需要自定义监听广播可以继承 NotificationBroadcasterSupport 或 NotificationEmitterSupport，其内部已经实现了 addNotificationListener、removeNotificationListener 方法。\n","date":1544969504,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544969504,"objectID":"9966403b2d5b6bfaddca5bc716a8afb9","permalink":"https://moyada.github.io/post/java-management/","publishdate":"2018-12-16T14:11:44Z","relpermalink":"/post/java-management/","section":"post","summary":"JMX 的全称为 Java Management Extensions，是一种监控、管理正在运行","tags":[],"title":"JMX 简介","type":"post"},{"authors":[],"categories":["JVM"],"content":"在 JVM 虚拟机的内存管理中，有可能存在老年代对象引用新生代的情况，在 Major GC 时，为了标记这些引用的新生代对象，需要通过扫描老年代来间接标记。\n然而，正常扫描全部老年代来获取的做法效率太低下了，由此便产生了称为 CardTable (卡表) 的数据。\nCard Table 保存了所在由老年代所引用的新生代对象的集合，同时利用写屏障，在引用对象变化时，对引用记录标记为 \u0026ldquo;脏\u0026rdquo; ，那么当下次 GC 到来时，只用扫描脏页 (Dirty Page) 便可以标记出由老年代引用的新生代存活对象。并且在 GC 后，由于复制算法导致了数据的迁移，根据迁移的位置决定是否对引用记录再次进行标记。\n在 G1 中，除了 Card Table 还存在 Remembered Set，更好的解决了跨代引用的问题。\n它记录了新生代被老生代引用的记录，存活于 Region 中，对比 Card Table，Remembered Sets 只需通过自身就能得知是否存在跨代引用，无需借助老年代。\n配合 G1 回收算法，在对 Region 进行回收时，无需借助外部数据就能获取全部存活对象，更大的提高了 GC 的效率。\n其实在 G1 中，Remembered Sets 是借助 Card Table 来实现的。\n http://blog.ragozin.info/2011/06/understanding-gc-pauses-in-jvm-hotspots.html\n ","date":1544836894,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544836894,"objectID":"7487e59cc1051a8bbcfbe5aa67f7794b","permalink":"https://moyada.github.io/post/card-table/","publishdate":"2018-12-15T01:21:34Z","relpermalink":"/post/card-table/","section":"post","summary":"在 JVM 虚拟机的内存管理中，有可能存在老年代对象引用新生代的情况","tags":[],"title":"跨代引用","type":"post"},{"authors":[],"categories":["Java"],"content":"Java 安全机制是针对程序在操作本地资源时的权限限制，避免在执行有害代码时 (例如网络上下载的 jar 包)导致不可预估的损失。\n这里简单介绍下使用方法。\n配置安全策略   创建以 .policy 结尾的文件\n  配置授权规则，可以参考 Java 默认的策略文件 ${java.home}/jre/lib/security/java.policy\n  以下面配置文件的语法为例\ngrant codebase \u0026quot;file:${user.dir}/-\u0026quot; { permission java.io.FilePermission \u0026quot;${user.home}/*\u0026quot;, \u0026quot;write\u0026quot;; };  其中定义了一条对 ${user.dir}/permission/ 路径下所有文件的权限，规定对 ${user.home} 路径下一层级的文件拥有写入权限。\ncodebase \u0026quot;url\u0026quot; 为可选项，表示权限规则的授予目标，不设置则对所有文件生效。也可使用 其他目标语法，或者自定义语法。\npermission 表示一条权限规则，后面需跟随 继承 Permission 类的全路径类名、构造方法参数，以 ; 结尾，可设置多条规则。\n设置策略文件    追加策略文件 -Djava.security.policy=my.policy\n  替换策略文件 -Djava.security.policy==my.policy\n  开启安全机制 一般开启安全机制的方式有两种，设置 JVM 参数，或者通过代码配置。\n配置 JVM Options -Djava.security.manager -Djava.security.policy=my.policy  代码设置 static { String dir = System.getProperty(\u0026quot;user.dir\u0026quot;); System.setProperty(\u0026quot;java.security.policy\u0026quot;, dir + \u0026quot;/my.policy\u0026quot;); if (System.getSecurityManager() == null) { System.setSecurityManager(new SecurityManager()); } }  注意在使用代码时会与 JVM Options 方式冲突，抛出 java.security.AccessControlException: access denied 异常信息，需要配置权限规则解决，可以选择追加在 Java 策略文件里。\ngrant { permission java.lang.RuntimePermission \u0026quot;setSecurityManager\u0026quot;; permission java.util.PropertyPermission \u0026quot;java.security.policy\u0026quot;, \u0026quot;write\u0026quot;; permission java.util.PropertyPermission \u0026quot;os.name\u0026quot;, \u0026quot;read\u0026quot;; permission java.util.PropertyPermission \u0026quot;user.home\u0026quot;, \u0026quot;read\u0026quot;; permission java.util.PropertyPermission \u0026quot;user.dir\u0026quot;, \u0026quot;read\u0026quot;; };  跳过权限检查 对于开启了安全策略后又不想定义权限规则时，则可以使用 AccessController 类的 doPrivileged 方法，跳过 checkPermission 步骤，直接调用方法体。\nAccessController.doPrivileged(new PrivilegedAction\u0026lt;Object\u0026gt;() { @Override public Object run() { ... return null; } });  那么你可能会想，这样在其他依赖中也调用此方法不是绕过了安全机制。其实并不会，Java 在打包时会对实现了 PrivilegedAction 接口的元类信息进行清除，强制调用则会抛出 java.lang.NoClassDefFoundError。\n第三方工具 如果觉得默认的策略规则配置太繁琐了，那么可以使用 pro-grade 这个第三方依赖，他通过自定义语法简化了规则的配置，具体步骤可以参考 官网\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;net.sourceforge.pro-grade\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;pro-grade\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.1.3\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;compile\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;  ","date":1544538010,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1544538010,"objectID":"69a787a5f883dbe73f69b2af9156ade0","permalink":"https://moyada.github.io/post/java-security/","publishdate":"2018-12-11T14:20:10Z","relpermalink":"/post/java-security/","section":"post","summary":"Java 安全机制是针对程序在操作本地资源时的权限限制，避免在执行有","tags":[],"title":"Java安全机制","type":"post"},{"authors":[],"categories":[],"content":"随着 Paas 技术和 Serverless 架构的发展，Docker 这一虚拟化技术也随之兴起，很好的解决了 应用程序 与 运行环境 的不一致问题。\n在 Docker 的管理里，应用程序时以容器的方式运行的，一个容器其实就是一个进程，通过 Namespaces 限制进程所能查看到的信息，并且使用 CGroups 限制进程所能使用的资源，挂载 rootfs 配置容器的可操作的数据，使用指定网络模型进行容器间通信。\nDocker 是通过编写 Dockerfile 来配置应用环境、代码文件、执行步骤等一系列正常发布流程，通过 docker build path 命令将操作打包成一个 Image 镜像 (可在 Dockerfile 同目录下增加 .dockerignore 设置排除规则，加快打包速度)，并执行 Dockerfile 的构建命令。\n镜像构建完毕，便可以使用 docker run 命令将镜像以 Container 容器的形式构建并启用，执行 DockerFile 配置的运行命令。\nscratch\n https://draveness.me/docker\n ","date":1542368030,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1542368030,"objectID":"6b024c506dc816f0d0119c92586bfdc5","permalink":"https://moyada.github.io/bak/docker/","publishdate":"2018-11-16T11:33:50Z","relpermalink":"/bak/docker/","section":"bak","summary":"随着 Paas 技术和 Serverless 架构的发展，Docker 这一虚拟化技术也随之兴","tags":[],"title":"初识 Docker","type":"bak"},{"authors":[],"categories":["领域驱动设计"],"content":"简介 一个应用系统常常包含许多模块，有基础组件、业务逻辑、数据操作、外部依赖、服务提供等等。但软件系统发展到一定程度时，其复杂性也随之增长，给后期的开发和维护带来难度。\n而领域驱动设计则是针对 复杂性 的一个解决手段，使架构能够自我进化。同时由于领域驱动设计强调领域模型的重要性，与微服务思想恰到好处，自然被越来越多的架构设计所采纳。\n软件的复杂性，其源头主要是由于对业务需求的抽象设计不足所导致的，按照我在日常开发流程中的接触，认为主要原因是 分工 所导致的认识不全面，开发人员只关注于需求，没有梳理出项目所需的业务知识。\n一个完整的领域驱动设计周期需要包括 建立业务领域模型、 分析领域场景、 建立统一语言、 识别限界上下文、 设计分层架构 这几个阶段。\n建模 领域建模是领域驱动设计周期中最重要的一个阶段，一个良好的模型设计能使得系统结构清晰整洁、分层合理，对日后的变化达到可进化性、可扩展性、可定制性。\n这个阶段需要先与项目的相关人员都进行沟通，基于对象事件进行分析说明，解决存在困惑，使得成员对业务期望有普遍理解，初步达成领域知识的共识。\n  首先，需要对业务建立逻辑模型与物理模型，识别业务需求，将业务逻辑与技术实现进行隔离。\n  对业务逻辑进行分治、抽象、封装，做到化繁为简，降低系统的复杂性。\n  分析识别问题域，根据需求目标的重要性确定其优先级（主要功能与基础功能先之、外部协作功能次之）\n    事件风暴 是一个常用且高效的领域事件建模方法。\n 分析场景 通过分析业务逻辑提炼场景，才能更好的完善领域模型，常用的方式有 用例、用户故事、测试驱动开发，每个方式的关注点也大相径庭。\n用例 用例是软件开发中最熟悉的设计方法，它以 领域 为核心，通过梳理整个流程，抽象出业务领域模型。\n用户故事 相比与用例的抽象，用户故事则是具体的。它将接收特定的事件并根据一定的条件转化为结果进行输出，强调 业务规则 与 业务流程。\n测试驱动开发 测试驱动开发的目的在于对职责进行 拆分，模拟现实场景分解任务，保证测试任务的粒度足够细。\n  四色原型 是对事件分析的手段，也叫 彩色UML。\n 建立统一语言 统一语言是领域驱动设计之中十分重要的一个环节，其核心价值在于 理解。在进行需求沟通时，为避免不一致的理解所产生的认识障碍，需要建立出团队中各个成员都理解的的术语进行交流，这一过程就是建立统一语言。\n统一语言体现在两个方面：统一的领域术语、领域行为描述\n统一的领域术语 领域术语的设立目的是为了规避那些表达含义混淆的术语，提高沟通和交流的效率。\n正确的术语建立需要业务人员通过对模型需求进行分析，提炼出概念一致的中英文语言及解释，甚至提供详细的案例说明来确保能够做到表达明确，并通过 术语表 进行维护。\n领域行为描述 领域行为描述是对业务过程的详细解释，遵守且延伸于领域术语，侧重于体现完整的业务需求以及复杂的业务规则。\n根据领域行为描述中的前置条件、业务规则、流程状态、执行结果，并且直接融入编码实现，使得代码逻辑清晰可读，自身就能对领域行为进行描述。\n限界上下文 限界上下文的含义是保证目标业务流程不受外部因素干扰，即项目的系统架构与组织结构都是可控的。要正确理解限界上下文，就需要对 上下文 和 边界 有清晰的认识。\n上下文 上下文划分的价值主要体现在三个方面，领域逻辑层面、团队合作层面、技术实现层面。\n  领域逻辑层面 限界上下文确定了领域模型的业务边界，维护了模型的完整性与一致性，从而降低系统的业务复杂度。\n  团队合作层面 限界上下文确定了开发团队的工作边界，建立了团队之间的合作模式，避免团队之间的沟通变得混乱，从而降低系统的管理复杂度。\n  技术实现层面 限界上下文确定了系统架构的应用边界，保证了系统层和上下文领域层各自的一致性，建立了上下文之间的集成方式，从而降低系统的技术复杂度。\n  边界 边界的职责是确定限界上下文的 控制力，体现了高内聚低耦合的思想，主要包括以下几个要素。\n  最小完备 要求限界上下文的控制权在其自身，无需依赖其他上下文的信息，整个业务流程是安全的。\n  自我履行 自我履行是指对外部的请求能够很好的判断该请求是否属性当前上下文的职责范围内，还是应该交付给其他上下文。\n  稳定空间 稳定空间就是要对限界上下文拥有掌控权，对外部交互以接口的形式进行抽象。\n  独立进化 指的是当限界上下文发生变化时，不会对外界造成影响，意在服务演化中的兼容性。\n  分层架构 软件设计中的分层架构已经成为了开发人员心中的规范了，领域驱动设计也有一套分层的依据与原则。\n分层的方式一般是对系统整体进行水平切分，目的在于打造出抽象层次不同的架构，将业务与技术分离开。\n根据关注点可分为面向用户、面向应用、面向业务、面向资源，业务相关性由低至高。\n 根据业务特性，设计适当的分层架构。例如 六边形架构、洋葱圈架构、事件驱动模型、函数式编程、QCRS模式 等。  面向资源 该层为基础设施层，主要提供了具体的外部资源获取方式，可能有数据库、文件系统、远程通信，属于最稳定的一组服务。\n面向业务 该层为业务流程的拆分，将职责的抽象与实现剥离，提供抽象的接口，隐藏内部的实现。\n面向应用 该层为业务流程的合成，根据业务规则将抽象接口进行组装，通过依赖注入实现接口，提供完整的业务功能。\n面向用户 该层的职责主要提供了外部进程访问领域资源的手段，这里的用户可以是前端接口、远程通信服务。\n 基于个人理解的六边形架构的 maven archetype 实现\n https://www.jdon.com/ddd.html https://www.jianshu.com/p/b6ec06d6b594 https://tech.meituan.com/DDD%20in%20practice.html\n ","date":1540756442,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1540756442,"objectID":"a674689408b77860e2ebba6921ca600c","permalink":"https://moyada.github.io/post/domain-driven-design/","publishdate":"2018-10-28T19:54:02Z","relpermalink":"/post/domain-driven-design/","section":"post","summary":"简介 一个应用系统常常包含许多模块，有基础组件、业务逻辑、数据","tags":[],"title":"领域驱动设计学习","type":"post"},{"authors":[],"categories":["Java"],"content":"在对不同工具做性能对比测试时，由于jvm的运行期优化可能导致结果的偏差。 所以，为了在大程度上避免这种偏差问题，则会用到OpenJDK的性能基准测试项目 JMH。\n项目构建 可以通过maven命令构建项目\nmvn archetype:generate \\ -DinteractiveMode=false \\ -DarchetypeGroupId=org.openjdk.jmh \\ -DarchetypeArtifactId=jmh-java-benchmark-archetype \\ -DgroupId=\u0026lt;you_groupId\u0026gt; \\ -DartifactId=\u0026lt;you_artifactId\u0026gt; \\ -Dversion=1.0-SNAPSHOT  或者在已有项目中引入依赖包\n\u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.openjdk.jmh\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jmh-core\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${jmh.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.openjdk.jmh\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;jmh-generator-annprocess\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${jmh.version}\u0026lt;/version\u0026gt; \u0026lt;scope\u0026gt;provided\u0026lt;/scope\u0026gt; \u0026lt;/dependency\u0026gt;  基本使用 注解    参数 作用 范围     @State 配置每个实例的生命周期 类   @BenchmarkMode 测试的维度，有吞吐量、平时时间、随机取样、单次运行 方法、类   @OutputTimeUnit 输出结果的时间单位 方法、类   @Warmup 预热迭代，以保证即时编译的工作 方法、类   @Measurement 设置执行测试迭代的参数 方法、类   @Fork 使用额外虚拟机测试数量 方法、类   @Setup 测试前置执行逻辑 方法   @TearDown 测试结束执行逻辑 方法   @Benchmark 标记该方法需要进行测试，并生成class类 方法   @Param 指定参数的测试范围 属性   @CompilerControl 设置即时编译的效果 构造器、类、方法    启动 编写 main 方法编译启动或打包成 jar 包运行\npublic static void main(String[] args) throws RunnerException { Options opt = new OptionsBuilder() .include(MyBenchmark.class.getSimpleName()) .jvmArgs(\u0026quot;-server\u0026quot;, \u0026quot;-Xms2048m\u0026quot;, \u0026quot;-Xmx2048m\u0026quot;) .addProfiler(GCProfiler.class) .addProfiler(StackProfiler.class) .build(); new Runner(opt).run(); }   https://blog.csdn.net/lxbjkben/article/details/79410740\n ","date":1539444233,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1539444233,"objectID":"64de216155b2bae1f173bff73aacbcf1","permalink":"https://moyada.github.io/post/jmh/","publishdate":"2018-10-13T15:23:53Z","relpermalink":"/post/jmh/","section":"post","summary":"在对不同工具做性能对比测试时，由于jvm的运行期优化可能导致","tags":[],"title":"Java 基准测试框架(JMH)","type":"post"},{"authors":[],"categories":["Git"],"content":"当在公网环境下使用 git 仓库不小心把敏感信息提交上去时，则可以使用 filter-branch 对代码仓库进行清洗。\n1. 先对本地历史进行清洗 git filter-branch --force --index-filter 'git rm --cached --ignore-unmatch \u0026lt;file_path\u0026gt;' --prune-empty --tag-name-filter cat -- --all    filter-branch 是让git重写每个分支\n  \u0026ndash;force 假如遇到冲突也让git强制执行\n  \u0026ndash;index-filter 选项指定重写的时候应该执行什么命令\n  \u0026ndash;prune-empty 选项告诉git，如果因为重写导致某些commit变成了空（比如修改的文件全部被删除），那么忽略掉这个commit\n  \u0026ndash;tag-name-filter 表示对每一个tag如何重命名，重命名的命令紧跟在后面，当前的tag名会从标注输入送给后面的命令，用cat就表示保持tag名不变。\n  其后的 \u0026ndash; 表示分割符，最后的 \u0026ndash;all 表示对所有的文件都考虑在内\n  2. 然后更新仓库源引用为刚才的结果 git for-each-ref --format=\u0026quot;%(refname)\u0026quot; refs/original/ | xargs -n 1 git update-ref -d git reflog expire --expire=now --all git gc --prune=now  3. 更新标签 git push --all --force git push --tags --force    https://www.jianshu.com/p/11822884b924 https://blog.csdn.net/lwfcgz/article/details/49453375 https://www.cnblogs.com/developer-ios/p/6211903.html https://stackoverflow.com/questions/7654822/remove-refs-original-heads-master-from-git-repo-after-filter-branch-tree-filte https://git-scm.com/book/zh/v1/Git-%E5%86%85%E9%83%A8%E5%8E%9F%E7%90%86-Git-References\n ","date":1537870311,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1537870311,"objectID":"4b53a23b484a89616ad108aa8f10f115","permalink":"https://moyada.github.io/post/git-filter/","publishdate":"2018-09-25T10:11:51Z","relpermalink":"/post/git-filter/","section":"post","summary":"当在公网环境下使用 git 仓库不小心把敏感信息提交上去时，则可以使","tags":[],"title":"Git 历史记录清洗","type":"post"},{"authors":[],"categories":["Git"],"content":"删除仓库文件 当不小心提交了不应提交的文件后，可以用此方法处理。\n  git rm -r --cached \u0026lt;file_path\u0026gt;\n  更新 .gitignore 添加忽略文件。\n  提交修改\n  这样本地文件不会删除，但是 git 仓库里的文件则会被标记删除，\n停止跟踪文件 当有一份文件，只需要一份基础版本，每个机器独自增加配置时，则可以使用 git update-index --assume-unchanged \u0026lt;file_path\u0026gt;，忽略文件后续的变更。\n当需要对这个基础版本再此迭代时，可以使用git update-index --no-assume-unchanged \u0026lt;file_path\u0026gt;，重新跟踪文件的修改。\n","date":1537867286,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1537867286,"objectID":"c8b7925f6d88577cca1fbc1e29cd7ab3","permalink":"https://moyada.github.io/post/git-ignore/","publishdate":"2018-09-25T09:21:26Z","relpermalink":"/post/git-ignore/","section":"post","summary":"删除仓库文件 当不小心提交了不应提交的文件后，可以用此方法处理","tags":[],"title":"Git 文件忽略","type":"post"},{"authors":[],"categories":[],"content":"因为 HashMap 是非线程安全的，在并发环境下应避免使用，改为 ConcurrentHashMap。\n 虽然在 jdk8 修复了该问题，但仍然还存在其他并发问题。\n 其产生的主要原因是扩容时元素的循环引用，在这里简单描述下。\n// jdk7 中造成问题的核心代码 void transfer(Entry[] newTable, boolean rehash) { int newCapacity = newTable.length; for (Entry\u0026lt;K,V\u0026gt; e : table) { while(null != e) { Entry\u0026lt;K,V\u0026gt; next = e.next; // 1 if (rehash) { e.hash = null == e.key ? 0 : hash(e.key); } int i = indexFor(e.hash, newCapacity); e.next = newTable[i]; // 2 newTable[i] = e; e = next; } } }    例如 HashMap 中有A, B两个元素，并且哈希值都相等，同处于下标为 0 的链表中，顺序为 A -\u0026gt; B -\u0026gt; null。\n  此时添加元素C将触发扩容操作，但由于有两个线程同时添加了元素，所以将同时触发两次扩容操作。\n  假设 线程1 先进行了扩容操作，但是由于某种原因，在 代码 1 位置处代码执行完被阻塞了，此时 e = A，next = B。\n  接着 线程2 顺利的进行了扩容操作，由于重组方式采用的是头插法 (代码 2)，所以新的链表顺序为 B -\u0026gt; A -\u0026gt; null，将B的next设置为A。\n  当线程2结束后 线程1 也恢复了扩容操作，由于当时现场的e = A，next = B，并且 线程2 将 B 的next 设置为了A，所以相比线程2的扩容将多进行一次 A -\u0026gt; B的操作，这样就造成了 A -\u0026gt; B -\u0026gt; A -\u0026gt; ... 的环路。\n  当获取一个下标相同但不存在的key时，将发生死循环现象。\n   用大白话来说，就是你在一堆抽完又放回的扑克牌中取一张不存在的牌。\n参考: https://tech.meituan.com/java_hashmap.html\n ","date":1534424313,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1534424313,"objectID":"d9c6b1e01055aedd5b454b38fcde18cc","permalink":"https://moyada.github.io/post/hashmap-problem/","publishdate":"2018-08-16T12:58:33Z","relpermalink":"/post/hashmap-problem/","section":"post","summary":"因为 HashMap 是非线程安全的，在并发环境下应避免使用，改为 Concu","tags":[],"title":"HashMap 在并发环境下的死循环问题","type":"post"},{"authors":null,"categories":null,"content":"cpu相关 uptime 查看系统平均负载状态，以 cpu 个数为标准，通过 cat /proc/cpuinfo | grep 'physical id' | sort | uniq | wc -l 可获取 cpu 个数，如果负载过高则可根据 cpu 使用率判断是由于存在大量 cpu 调用还是 I/O 中断。\ntop 查看cpu指标，P 对cpu资源占用进行排序，M 对内存占用进行排序，H 切换为线程模式，top -Hp  查看进程内线程情况。\nhtop top的增强版\nvmstat 查看服务器的CPU使用率、内存使用、虚拟内存、交换情况、io读写情况。\npidstat 查看进程的上下文切换情况，使用 pidstat -w 1 -p \u0026lt;pid\u0026gt; 查看进程的每秒钟上下文切换情况。\nsar 查看历史性能指标数据，可采样性能指标，如 sar -u 1 5 对cpu使用率进行每秒一次采样，共5次。sar -n 5 2 对网络进行采样。\nmpstat 可以针对cpu核心进行性能指标采样。\ndstat 查看系统资源利用率。\npstack 显示进程内的栈跟踪，可以用来查看java的native栈。\nperf 性能瓶颈剖析工具\ncat /proc/interrupts 查看系统的中断状态\ncat /proc/stat 查看系统的cpu状态，可用cat /proc/stat | grep ctxt \u0026amp;\u0026amp; sleep 30 \u0026amp;\u0026amp; cat /proc/stat | grep ctxt查看每秒上下文切换\ncat /proc//stat | cat /proc//task//stat 查看进程或线程的cpu状态\ndmesg 查看进程活动状态\nsystemtap gdb 进程 pidstat 查看进程的 cpu、内存、I/O、上下文切换等性能信息。\njstack 对top获取的线程进行 printf \u0026lsquo;%x\\n\u0026rsquo;  转换为16进制，再通过 jstack  | grep -A 10  找出线程信息。\n内存相关 pmap io相关 btrace iotop 监控磁盘读写状态\niostat 查看到系统磁盘io状态信息\n网络相关 iptraf 流量监控监控工具\nnload 查看总流量状态\nifstat 查看网卡流量状态\niftop 监控网卡的实时流量\nnmap 网络扫描和主机检测的工具\nnetstat 查看系统的网络状态信息\nvnstat VPS流量查看/监测工具，vnstat -u -i \u0026lt;mac_name\u0026gt;\nlsof 检测开放端口 lspof -i:\ntelnet 检测端口是否开放\nnetcat 检测端口是否开放工具 nc -vv 192.168.42.128 1521\n","date":1534113939,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1534113939,"objectID":"27be8e9ede73258ae5fc12a7a421d69d","permalink":"https://moyada.github.io/bak/performance/","publishdate":"2018-08-12T22:45:39Z","relpermalink":"/bak/performance/","section":"bak","summary":"cpu相关 uptime 查看系统平均负载状态，以 cpu 个数为标准，通过 cat /proc/cpuinfo |","tags":null,"title":"性能分析","type":"bak"},{"authors":[],"categories":["Java"],"content":"oracle 在 jdk8 中引入了接口的默认方法，用 default 关键字标识。\npublic inteface Listener { default void start() { ... } }  该原语特性能将接口的 default 方法以 public 可见范围赋予所有实现类，同时允许重写。\n由于默认方法是定义在接口上的方法，只能使用接收参数和接口方法，并且是 public 可见范围，导致了使用的局限性。\n在实际开发中的常见场景为，一个功能的主流程固定，并且需由数个方法组成，而方法根据场景可能会有多种实现 (可以对照 Map 接口理解)。\n 参考: https://stackoverflow.com/questions/19998454/interface-with-default-methods-vs-abstract-class-in-java-8\n ","date":1533859091,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1533859091,"objectID":"1515e4bb94951bb4839018a09f4705f8","permalink":"https://moyada.github.io/post/default-method/","publishdate":"2018-08-09T23:58:11Z","relpermalink":"/post/default-method/","section":"post","summary":"oracle 在 jdk8 中引入了接口的默认方法，用 default 关键字标识。 public inteface Listener { default void start()","tags":[],"title":"java8 default method 的使用见解","type":"post"},{"authors":[],"categories":["JVM"],"content":"由于JVM分代设计，GC也根据原因不同而产生不同效果的GC，并且在Java的发展过程中根据不同的GC策略也有不同的过程实现。\nStop-the-World 在 HotSpot 虚拟机中，Stop-the-World 也被称之为 safepoint，在此阶段内，所有运行 Java 代码与 JVM 交互的应用线程将会被挂起。\n以便在执行 GC 复制算法、栈上替换代码、JIT 去优化、清除 code cache、重定义 Class、偏向锁的去除、debug 操作等任务时保证数据的一致性。\nYoungGC 发生在新生代的GC称为 Young GC，也叫 YGC，是 JVM 运行过程中最频繁的GC。\n原因及过程 YoungGC 的产生原因主要是eden区内存不足以分配新对象或者剩余空间达到GC触发条件。 在发生 GC 时，虚拟机会将 eden 区和 survival from 区中存活的对象拷贝进 survival to 区，清理其余对象。\nParNew 需要STW暂停，找出活跃对象，标记为 reachable。\n从 GC ROOTs 找出活跃的对象，还要根据 CardTable 的 Dirty 标记 (晋升至老年代，并且引用新生代对象) 找出老年代引用的新生代对象。\n首先检查老年代的连续可用空间是否可容纳存活对象，如果小于或者不允许担保失败，则需要进行 Full GC。\n检查空间足够则将存活对象进行复制，初始化 MarkWork，将根据年龄选择拷贝对象的目标空间。\nG1 大体步骤与ParNew类似，也需要 SWT 暂停。 不同的是，G1的 survivor 只有一个区域，并且使用 RegionSet 来维护块之间的引用。\n G1存在一种 Mixed GC，除了回收新生代之外，还会回收压缩部分老年代。\n Old GC 属于老年代GC的统称，也叫 Old GC，一般都是伴随着 Young GC ，主要目的是释放老年代空间，并将相邻对象进行压缩，防止过多的内存碎片。\n原因及过程 OldGC的产生原因为YoungGC所需的堆内存空间不足、方法区空间不足、堆内空间达到回收阀值，也有可能人为触发。 发生GC时，标记所有存活对象，可将存活对象进行压缩，对不再使用的类及其子类进行卸载，清理CodeCache，清理弱引用，常量池的清理。\nCMS   初始标记 暂停所有应用线程，从 GC ROOTs 标记出老年代边缘的存活对象。\n  并发标记 根据标记对象进行扫描，查找所有可到达对象。\n  重新标记 并发地对上一阶段中引用关系变化的对象进行再标记，然后再暂停应用线程，最后检查是否有发生引用变化。\n  并发清理 对未标记的对象进行收集，释放空间至空闲列表，此阶段可能将卸载此类。\n  并发重置 重新计算堆空间，清理数据，为下一次 GC 周期做准备。\n   https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/cms.html#CJAGIIEJ\n G1 G1 的收集虽然也分为新生代和老年代，但在步骤上其实是有交叉的地方\n  初始标记 需要暂停应用线程，标记出 Roots，暂停时间较短，可能会根据 Region 优先级选择执行，从 GC ROOTs 标记出边缘的存活对象。\n  根区域扫描 从标记的存活区域中查找出老年代的引用并进行标记，为了保证数据的正确，在下一次新生代 GC 可能发生之前此阶段必须完成.\n  并发标记 根据标记对象进行扫描，查找出所有可到达对象，有可能被 Young GC 打断。过程中还会涉及 SATB，记录引用关系变化。\n  再次标记 需要 STW，将上一阶段中引用关系发生变化的对象进行再标记。\n  清理 整理对象、更新 RSets 和将部分老年代加入下次回收周期，需要暂停应用线程，对于清空 Region 加入空闲列表的操作可以并发进行。\n   https://www.oracle.com/technetwork/articles/java/g1gc-1984535.html https://docs.oracle.com/javase/9/gctuning/garbage-first-garbage-collector.htm#JSGCT-GUID-F1BE86FA-3EDC-4D4F-BDB4-4B044AD83180\n Full GC Full GC 是对整个堆进行清理的回收算法，包括新生代和老年代。\n在 CMS 中可指定使用并发的 Full GC，在 JDK10 中 G1 对 Full GC 也改进为了并发模式。\n除手动触发因素外，Full GC 的产生通常是由老年代空间不足、方法区空间不足所引起。\n所有的垃圾回收算法都会在 Full GC 时暂停应用线程，因此在对延迟要求高的程序中，Full GC 是应该尽力避免的。\n","date":1531656365,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1531656365,"objectID":"cf27dc5282cc5045bcdb73ea719bcf95","permalink":"https://moyada.github.io/post/jvm-gc/","publishdate":"2018-07-15T12:06:05Z","relpermalink":"/post/jvm-gc/","section":"post","summary":"由于JVM分代设计，GC也根据原因不同而产生不同效果的GC，","tags":["GC"],"title":"Java GC过程","type":"post"},{"authors":[],"categories":["Java"],"content":"概念 volatile原语保障了多线程下变量的原子性、可见性、有序性。\n原子性 在32位虚拟机下对long、double类型的赋值操作会拆分位高位、低位两步完成修改，而volatile可使用内存屏障来达到原子性，保证不存在中间值，但是由于读取的一刻其他线程也有可能改变值，所以复合操作无法达到原子性。\n 64位下不存在该问题，并且近代jdk中普通操作也能达到原子性\n 可见性 其目的是使多线程环境下对共享变量的修改能被其他线程立即查看到。\n由于线程对变量的读取是先从线程的工作内存(cpu缓存)中获取，不存在才从主内存中获取。\n那么在多线程环境下多普通共享变量的修改操作就会由于cpu缓存中已存在而导致的数据不一致。\n为了解决这个问题，处理器会对编译后指令增加lock指令前缀，大部分处理器架构采用了RingBus + MESI协议的方式来解决，部分老版本cpu架构则采用锁总线来达到效果。\n原理是在修改数据时候更新cpu缓存之后立即写回主存、并且通知到使用相同变量线程，将该变量设置为无效，当读取变量时再从主存或者寄存器中获取。\n 由于volatile的可见性，也可用来完成轻量锁的实现，例如线程的终止判断\n 有序性 操作系统为了使cpu流水线的各个阶段不存在空闲内核，往往会多当前编译好的指令进行重排序，但是只会保证单条线程的程序正确性，并不保障并发环境下的正确性。\nJVM为了保证volatile域的可见性(happens-before)，会在编译时对指令前后都加入内存屏障指令lock前缀，使得不会将后面的指令重排序到内存屏障之前的位置。\n 当第二个操作是volatile写时，不管第一个操作是什么，都不能重排序。这个规则确保volatile写之前的操作不会被编译器重排序到volatile写之后。 当第一个操作是volatile读时，不管第二个操作是什么，都不能重排序。这个规则确保volatile读之后的操作不会被编译器重排序到volatile读之前。 当第一个操作是volatile写，第二个操作是volatile读时，不能重排序。   最经典的场景有double check单例，由于重排序，可能出现对象尚未创建成功，但是对象引用缺被赋值使用，造成空指针异常。\n ","date":1531591277,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1531591277,"objectID":"ef9fa4ecc937ba8f7ec7ccc9facfa5bc","permalink":"https://moyada.github.io/post/volatile/","publishdate":"2018-07-14T18:01:17Z","relpermalink":"/post/volatile/","section":"post","summary":"概念 volatile原语保障了多线程下变量的原子性、可见性、","tags":[],"title":"volatile 浅析","type":"post"},{"authors":null,"categories":null,"content":"发生上下文切换的原因有很多，比如 时间片耗尽 任务抢占 主动挂起 硬件中断 IO阻塞 锁机制\n在CPU对进程、线程进行上下文切换时，系统需要将当前寄存器内数据保存，也就是所谓的保存现场，当再次获取时间片运行时进行置换。\n这种开销需要操作系统进行资源管理和线程协调，当大频率发生上下文切换时，会造成很大的性能损耗。\n并且，并发环境下的程序处理是十分复杂，当处于共享资源时，需要考虑线程的执行顺序和数据的一致性。\n所以，在设计程序时，需要考虑合理的并发数设置，不使cpu大部分时间空闲，也不能产生大量上下文切换。\n设置线程数公式为 (线程等待时间 / cpu执行线程时间 + 1) * cpu核心数目\n如果是高并发程序和执行时间长的计算密集程序，应尽量使得并发数和cpu核心数一致。\n如果是IO密集型程序，cpu执行时间短，则可以加大并发数设置。\n","date":1531588326,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1531588326,"objectID":"28bd7355afb0ee0a7058b0b9a4187feb","permalink":"https://moyada.github.io/bak/multi-thread/","publishdate":"2018-07-14T17:12:06Z","relpermalink":"/bak/multi-thread/","section":"bak","summary":"发生上下文切换的原因有很多，比如 时间片耗尽 任务抢占 主动挂起 硬","tags":null,"title":"上下文切换","type":"bak"},{"authors":[],"categories":[],"content":"单机环境下有著名的 ACID理论，但是对于现代互联网下的分布式环境 ACID 就无能为力了。 所以，随着分布式系统的发展，一套针对分布式环境下 CAP定理 也随之产生。\nCAP 定理 CAP 定理是分布式计算领域公认的理论，所关心的是在互相连通和共享数据的多节点环境下的数据读写操作，主要可分为 C、A、P 三点。\n一般分布式环境下是无法保证 C、A、P 三个要素都满足，需依据业务进行取舍。\n一致性 (Consistence) 要求各节点之间读取的数据一致，必须保证 client 能够查看到所写的数据变化，即 读己之所写。\n 由于节点之间数据同步存在时差，并不强要求同一时刻数据的 强一致性，但需保证 最终一致性。\n 可用性 (Availability) 即为非故障节点能够返回合理的数据，不能是错误或者超时。\n 由于无法保障强一致性，故不要求数据的正确性，即在合理范围内则可。\n 分区容错性 (Partition Tolerance) 要求由于拥塞、丢包、中断、超时等故障造成 网络分区时，系统各节点能够正常服务。\n思考 在实际中，节点之间网络状况无法做到 100% 可靠，即 CAP 三者中的P是必须考虑的。\n而 CA 在理论上是无法同时满足的，即当出现网络分区时，为了保证数据 一致性，系统应不允许写入，则无法保证 可用性。\n因此，在考虑设计分布式架构时，一般选择 CP 或 AP 架构，具体设计时需要考虑业务特性。\nBASE理论 BASE 理论是对 CAP 定理的延伸和补充，在 AP 方案的基础上进行平衡，保证一定时间内最终达到 C 的要素。\n基本可用 (Basically Available) 在系统故障时，能保证核心功能可用。\n软状态 (Soft Status) 允许数据不一致情况，但要求该中间数据不会影响整理系统的可用性。\n最终一致性 (Eventual Consistency) 即要求在一定时间后达到各节点的数据一致，属于特殊的 弱一致性。\n https://www.cnblogs.com/nucdy/p/7483108.html http://xinklabi.iteye.com/blog/2341034\n ","date":1530971061,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1530971061,"objectID":"fd04318bbe01924861ff9d74e7050770","permalink":"https://moyada.github.io/bak/cap-base/","publishdate":"2018-07-07T13:44:21Z","relpermalink":"/bak/cap-base/","section":"bak","summary":"单机环境下有著名的 ACID理论，但是对于现代互联网下的分布式","tags":[],"title":"CAP定理和BASE理论","type":"bak"},{"authors":[],"categories":["Java"],"content":"synchronized 在 jdk1.6 之后,synchronized 原语通过引入偏向锁、轻量锁进行了优化。\nsynchronized 是通过 monitor_enter 和 monitor_exit 来控制的，通过 javap 反编译能观察到。\n线程在进入 synchronized 代码块时，将通过获取对象头内 Mark Work 的锁标记来决定是否进入 临界区。\n偏向锁 没有多线程竞争环境，如果没有设置 -XX:-UseBiasedLocking 关闭偏向锁的话将会通过 CAS 获取锁，并设置持有锁的线程 id，当该线程再次尝试获取锁时，如果锁内线程为当前线程则直接判断获取锁标记。\n轻量锁 在多个线程尝试获取偏向锁时，当线程获取偏向锁失败时将会膨胀为轻量锁，通过CAS操作来获取锁标记进入临界区。\n重量锁 如果轻量锁的 CAS 操作失败时，将会升级为重量级锁。\n重量锁依赖底层的 Mutex Lock 总线锁，需要将用户态切换为内核态，成本较大。\n重入锁 在 synchronized 偏向锁和 ReentrantLock 中都设计了重入锁，\n自旋锁 当多线程环境下，线程获取锁标记或立马释放时，自旋锁就有其意义。\n在 Java 源码的AbstractQueuedSynchronizer 中，线程的出现竞争时就是先是尝试进行自旋锁，之后再进行锁升级。\n自旋锁消除了用户态切换至内核态的上下文切换，但是也增加cpu的消耗。\n锁降级 在jvm进入安全点时，会检测空闲的 monitor 并对其进行锁降级以提高下次获取锁时的效率。\n","date":1528798844,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1528798844,"objectID":"343f7c390fd8fa9ae4ffb272d7ce3db8","permalink":"https://moyada.github.io/post/java-lock/","publishdate":"2018-06-12T10:20:44Z","relpermalink":"/post/java-lock/","section":"post","summary":"synchronized 在 jdk1.6 之后,synchronized 原语通过引入偏向锁、轻量","tags":[],"title":"Java 锁机制","type":"post"},{"authors":[],"categories":["Java"],"content":"由于jdk9中对lombok所依赖的类进行了迁移，所以使用lombok的程序无法直接升级。需按照如下方式升级：\n 升级lombok依赖  \u0026lt;properties\u0026gt; \u0026lt;lombok.version\u0026gt;1.18.0\u0026lt;/lombok.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${lombok.version}\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.7.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;1.7\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;1.7\u0026lt;/target\u0026gt; \u0026lt;encoding\u0026gt;UTF-8\u0026lt;/encoding\u0026gt; \u0026lt;annotationProcessorPaths\u0026gt; \u0026lt;path\u0026gt; \u0026lt;groupId\u0026gt;org.projectlombok\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;lombok\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;${lombok.version}\u0026lt;/version\u0026gt; \u0026lt;/path\u0026gt; \u0026lt;/annotationProcessorPaths\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt;  升级maven编译插件及配置  \u0026lt;properties\u0026gt; \u0026lt;java.version\u0026gt;9\u0026lt;/java.version\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;groupId\u0026gt;org.apache.maven.plugins\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;maven-compiler-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;3.7.0\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;source\u0026gt;${java.version}\u0026lt;/source\u0026gt; \u0026lt;target\u0026gt;${java.version}\u0026lt;/target\u0026gt; \u0026lt;showDeprecation\u0026gt;true\u0026lt;/showDeprecation\u0026gt; \u0026lt;showWarnings\u0026gt;true\u0026lt;/showWarnings\u0026gt; \u0026lt;fork\u0026gt;true\u0026lt;/fork\u0026gt; \u0026lt;compilerargs\u0026gt; \u0026lt;arg\u0026gt;-Werror\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-Xlint:all\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-J--add-opens=jdk.compiler/com.sun.tools.javac.code=ALL-UNNAMED\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-J--add-opens=jdk.compiler/com.sun.tools.javac.comp=ALL-UNNAMED\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-J--add-opens=jdk.compiler/com.sun.tools.javac.file=ALL-UNNAMED\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-J--add-opens=jdk.compiler/com.sun.tools.javac.main=ALL-UNNAMED\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-J--add-opens=jdk.compiler/com.sun.tools.javac.model=ALL-UNNAMED\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-J--add-opens=jdk.compiler/com.sun.tools.javac.parser=ALL-UNNAMED\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-J--add-opens=jdk.compiler/com.sun.tools.javac.processing=ALL-UNNAMED\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-J--add-opens=jdk.compiler/com.sun.tools.javac.tree=ALL-UNNAMED\u0026lt;/arg\u0026gt; \u0026lt;arg\u0026gt;-J--add-opens=jdk.compiler/com.sun.tools.javac.util=ALL-UNNAMED\u0026lt;/arg\u0026gt; \u0026lt;/compilerargs\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/plugin\u0026gt;   参考: https://github.com/rzwitserloot/lombok/issues/985\n ","date":1528318316,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1528318316,"objectID":"a09e6a7fd23b4100bf29341c4842fab0","permalink":"https://moyada.github.io/post/lombok-java9/","publishdate":"2018-06-06T20:51:56Z","relpermalink":"/post/lombok-java9/","section":"post","summary":"由于jdk9中对lombok所依赖的类进行了迁移，所以使用l","tags":[],"title":"在 jdk9 下使用 Lombok","type":"post"},{"authors":[],"categories":[],"content":"ConcurrentHashMap 是 jdk 提供的针对并发环境下的集合类容器，是为了解决 HashMap 在并发环境下的线程安全问题。\nJDK7   利用分段锁(Segment)和 ReentrantLock 类实现并发控制的，类中维护了一组 Segment，通过对 key 进行 hash 获取相应的 Segment，Segment 内部维护了一组 HashEntry，类似 HashMap 结构，并且在并发修改阶段对管程进行加锁控制。\n  size() 方法使用的是遍历 Segment 加锁获取，在获取大小的时候会影响数据的修改。\n  JDK8 而 jdk8 中 ConcurrentHashMap 具体的变化有：\n  不在使用分段锁，而是恢复成与 HashMap 相似的结构。\n  对 hash 算法进行改进，使用高位移到低位异或，避免哈希碰撞。原因是 jdk 的哈希寻址是使用低位，而有些数据的哈希值差异主要在高位。\n  使用链表加红黑树的数据结构进行存储，哈希碰撞时使用链表，当链表长度大于 8 时，将当前链表的数据结构变形为红黑树，这样做的目的是为了解决当链表长度过大而造成的查询开销。\n  对数据的修改使用了 CAS 和 sychronized 进行并发控制，原因是 sychronized 在近代 JVM中 已经经过大量优化，性能与 ReentrantLock 差距不大，放弃使用 ReentrantLock 一方面能够节省的内存开销，另一方面能够降低开发成本。\n  使用了类似 LongAdder 的数据结构存储大小，并使用了缓存行填充。\n  避免初始开销，延迟加载数据结构。\n  ","date":1527345162,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1527345162,"objectID":"a733970612059545f60f8fdbf3c03cb9","permalink":"https://moyada.github.io/post/concurrenthashmap/","publishdate":"2018-05-26T14:32:42Z","relpermalink":"/post/concurrenthashmap/","section":"post","summary":"ConcurrentHashMap 是 jdk 提供的针对并发环境下的集合类容器，是为了解决 HashMap 在并发环","tags":[],"title":"ConcurrentHashMap 原理分析","type":"post"},{"authors":[],"categories":["Java"],"content":"使用MAT分析内存泄漏主要是检测对象是否可达，是否无用。\n通过jmap -dump:format=b,file=[file_name]] [pid] 生成hprof文件\n在Eclipse Marketplace安装 Memory Analyzer，打开dump文件\n 注意: dump 导出后的内存跟实际监控看到的内存大小不一致的时候, 有可能是使用了堆外内存  Overview 面板 Remainder(剩余) 应用 Heap 可分配的内存, 如果可分配内存很小, 则可以考虑加大或者进行优化\nHistogram 面板 (类 的角度) 可以查看内存中实例的数量以及占用内存的大小\nDominator Tree 面板 (对象实例 的角度) 按照占用内存由大到小的顺序列举了对象列表情况\nTop Consumers 面板 (按类和包进行分组分析大消耗对象) Leak Suspects 面板 (内存泄漏分析报表) Shallow size 是指对象本身占用内存的大小, 不包含对其他对象的引用 Retained size 是指 Shallow size + 该对象能直接或者间接访问到的对象的 Shallow size 之和，也就是指 该对象被 GC 之后所能回收的内存的总和 List Objects with incoming references 查看这个对象持有的外部对象引用\nwith outcoming references 查看这个对象被哪些外部对象引用\nPath To GC Roots exclude weak references 排除 软引用\nexclude soft references 排除 弱引用\nexclude weak/soft references 排除 软／弱引用\nexclude all phantim/weak/soft etc. references 查看 强引用\nGC root Unreachable 没有引用标记, 会被回收, 不会产生 leak, 由于没有 GC 发生所以没有被释放\n 参考文档: MAT 使用进阶 美团技术 Linux 与 JVM 的内存关系 Java内存泄漏分析 追踪 Netty 异常占用堆外内存的经验分享\n ","date":1527070699,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1527070699,"objectID":"e289a4a2d33653e3c8613b44279fd728","permalink":"https://moyada.github.io/post/mat/","publishdate":"2018-05-23T10:18:19Z","relpermalink":"/post/mat/","section":"post","summary":"使用MAT分析内存泄漏主要是检测对象是否可达，是否无用。 通过","tags":[],"title":"使用 Eclipse Memory Analyzer (MAT) 分析内存泄漏","type":"post"},{"authors":null,"categories":null,"content":"  服务器开放端口限制，可增加端口转发，防止ip暴露。例如只开放80端口，全部输入escape\n  生产机不能主动连接外网，作为生产机，开放22+key pair，并对端口严密监控\n  开发人员用VPN/SSH Tunnel 访问生产机\n  重要服务器单独部署\n  DDoS流量清洗，防C段攻击，使用稳定版本linux，注意kernel、openssl的0day漏洞\n  端口监控，异常流量，异常访问\n  服务器进行权限划分，细分权限，增强内网安放\n  把密码放生产机本地，除了root，一概不准读\n  密码应该放到Vault里管理\n  设置HttpOnly\n  ","date":1527047166,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1527047166,"objectID":"1bda9b5c2cf45e680f21ae3337ffed4b","permalink":"https://moyada.github.io/bak/service-safety/","publishdate":"2018-05-23T03:46:06Z","relpermalink":"/bak/service-safety/","section":"bak","summary":"服务器开放端口限制，可增加端口转发，防止ip暴露。例如只开放","tags":null,"title":"服务器安全","type":"bak"},{"authors":[],"categories":["JVM"],"content":"JVM(Java虚拟机) JVM 是 JRE 包含的 Java 程序运行所需的程序，屏蔽各种硬件和操作系统的内存访问差异，通用一份 jar 包。 另外，JVM还提供了内存管理的功能，使得开发人员无需关心底层内存如何管理。\n https://www.youtube.com/watch?v=ZBJ0u9MaKtM\n 类加载机制 Java虚拟机的类加载有加载 (load)、链接 (link)、初始化 (initialize) 三个步骤\n当一个类被实例化时或者类中静态方法被调用时将进行类加载\n加载 将不同的类数据源以字节码的形式加载到内存中以供类加载器使用，数据的来源可以是 jar 包、class 类、网络数据，一个类数据有且只有一个存在于一个类加载器中。\n正常的类加载是以双亲委任机制，不同的类加载器是以继承的方式链接的，当通过某个类加载器加载一个类数据时，当这个类加载器存在父类加载器时，那么它会先从父类加载器中寻找类数据，不存在再在自身中寻找，并且父类也是遵循这个机制。\n Tomcat的类加载器重写了这个加载机制，会优先在自身中查找，这跟Tomcat所加载类的所在位置有关。\n 链接 链接包含了验证、准备、解析三个步骤\n  验证确保了类加载的正确性，它校验了字节码数据是符合Class类规范，常量类型是否支持，语义分析，分析数据流和控制流校验程序语义，符号引用校验。\n  准备环节是为一个类的静态域分配内存空间，并赋予零值。\n  解析负责转化类中的符号引用，将类引用转换为直接引用，将类中的常量值转换为常量池中引用。\n   如果类字段的字段属性为 ConstantValue，即同时被 final 、static 修饰的基础类型数据，并且在定义时即赋值，如 static final String CONSTANT_COMPILE = \u0026quot;java\u0026quot;;，那么在准备阶段变量就会被初始化为属性所指定的值。\n 初始化 对类的静态域赋予正确的初始值，执行静态代码块为赋值静态域。\n异常   ClassNotFoundException 这种错误是发生在加载环节，当一个类在双亲委任机制中无法获取到时，便会抛出此异常。常见情景是依赖包的冲突。\n  NoClassDefFoundError 这个错误主要是发生在链接环节的解析中，当一个类的静态域引用至另一个类中的属性，而这个类无法获取时，那么虚拟机就会抛出此异常。\n  运行时数据区域 Java 虚拟机在运行程序的过程中把内存数据划分为不同的区域\n线程隔离的(指令区)   程序计数器：指向线程下一个执行的指令的地址(本地指针或者起始指令的偏移量)，当执行的是本地方法时为 undefined。 许多操作都需要依赖程序计数器来完成，例如在时间片抢占后切换线程能够恢复到正确的位置。\n  虚拟机栈：包含了线程生命周期的方法调用，一个 Java 方法调用即为一个栈帧，根据调用顺序压入线程栈空间。 栈帧存储当前线程运行方法所需要的局部变量表（基本数据类型、对象引用）、操作数栈、动态链接、方法返回地址，保证了多线程下调用方法的隔离性。\n  本地方法区：与虚拟机栈作用相似，区别是执行 native 方法。\n  线程共享的(数据区)   方法区／元空间 (MetaSpace)：存放类信息、静态域数据(对象实例存于堆中)、类编译期间生成的各种字面量和符号引用、字节码、JIT 编译后的机器码、动态代理产生的数据，使用本地内存存储，几乎不会被回收。\n  堆 (Heap)：运行时常量池、对象实例域，是垃圾收集管理的主要区域。可分为新生代、老年代。\n  直接内存：用于 NIO 数据交换的内存空间，只受实际内存及 JVM 参数限制。\n  内存溢出 内存溢出是由于虚拟机空间分配失败所导致的致命性错误。\n  方法栈 (StackOverFlowError) 常见原因有递归或大循环调用方法导致栈帧数量过多、线程内定义大量的本地变量。\n  堆 (OutOfMemoryError) 常量池溢出、线程持续占有对象都将可能导致堆溢出。\n  方法区 (OutOfMemoryError) 主要原因为动态创建大量的类，并且卸载无法满足新的元类存储。\n  执行引擎 解释器 (Interpreter) 解释字节码，执行相应的命令\n分析器 (Hotspot profiler) 将频繁调用的热点方法编译成与本地平台相关的机器码\nJIT (即时编译器) 优化解释器，将字节码翻译成本地平台相关的机器码执行 常见的 JIT 有 C1、C2，在 Java10 引入 Graal\n常见的 JIT 优化手段有\n  公共子表达式消除 当一个大表达式已经被计算过后，再次出现已经包含了的表达式则不必重新计算，直接用结果代替。\n  数组边界检查消除 消除大循环体内对元素越界检查\n  方法内联 将频繁调用方法替换为调用方法代码\n  逃逸分析 当开启了标量替换 (-XX:+EliminateAllocations) 和逃逸分析 (-XX:+DoEscapeAnalysis) 后，会对线程栈内的对象进行分析，将只存活于栈帧内的可分解对象进行基础类型数据替换处理。\n  同步消除 (-XX:+EliminateLocks) 在开启逃逸分析和 -server 模式后，将会对无多线程竞争的锁进行消除。\n  优化技术\n  编译器策略：延迟编译，分层编译，栈上替换，延迟优化，程序依赖图表示，静态单赋值表示。\n基于性能监控的优化技术：乐观空值断言，乐观类型断言，乐观类型增强，乐观数组增强，裁剪未被选择的分支，乐观的多态内联。分支频率预测，调用频率预测\n基于证据的优化技术：精确性推断，内存值推断，内存值跟踪，常量折叠，重组，操作符退化，空值检查消除。类型检测退化，类型检测消除，代数化简，公共子表达式消除\n数据流敏感重写：条件常量传播，基于六承载的类型缩减转换，无用代码消除\n语言相关的优化技术：类型继承关系分析，去虚拟机化，符号常量传播，自动装箱，消除逃逸分析，锁消除，锁膨胀，消除反射\n内存及代码位置交换：表达式提升，表达式下沉，冗余存储消除，相邻存储合并，交汇点分离\n循环变换：循环展开，循环剥离，安全点消除，迭代分离，范围检查消除\n局部代码调整：内联，全局代码提升，基于热度的代码分离，Switch 调整\n控制流图变换：本地代码编排，本独代码封包，延迟槽填充，着色图寄存器分配，线性扫描寄存器分配，复写聚合，常量分裂，复写移除，地址模式匹配。指令窥孔优化，基于确定有限状态机的代码生成\n Graal [jdk10] 启动方式 -XX:+UnlockExperimentalVMOptions -XX:+UseJVMCICompiler  GC(垃圾收集器)策略 Java虚拟机在运行时会产生大量的对象，有些对象将不会再被使用，为了使内存不被这些无用的对象占用，垃圾收集器就需要分析出已经死亡的对象，将其所用空间回收。\n虚拟机从一部分称为 GC Roots 的节点开始搜索引用链，找出存活的引用 (并非特指对象)，对其余对象标记为虚引用，准备下一阶段进行回收释放内存空间。对重写了 finilize() 方法对象封装并放入队列中，在 GC 结束后单线程执行方法后移除。\nSerial 标记清除整理 算法，单线程进行垃圾回收，无上下文切换开销，但 cpu 利用率较低，并且无法与应用线程并行进行。\nParallel 基于吞吐量优先的并行收集器，对年轻代使用 标记复制 算法，对老年代使用 标记清除整理 算法，适用于多核处理器，有效利用系统资源。\nCMS(Concurrent Mark Sweep) 以 标记清除 算法为基础，以响应时间优先的并发收集器，对年轻代使用 标记复制 算法，对老年代使用 标记清除 算法。 使用 空闲空间列表 来管理老年代内存，在老年代 GC 阶段大部分工作可以与应用线程并发执行，并且可在老年代空间内存利用率达到阀值时触发 CMS GC。\n收集工作分为数个阶段：初始标记、并发标记、并发预清理、并发可取消的预清理、最终标记、并发清除、并发重置\nCMS 由于不进行内存整理容易造成老年代内存碎片，并且当堆内存较大时，可能产生不可预估的暂停时间。\nG1(Garbage-First) 以 复制 算法为基础，为了能够得到良好的停顿时间而产生的一款实时收集器。 将内存空间以块 (Region) 进行分配空间，一般划分 2048 个，优先回收大垃圾的回收机制。使用空闲空间列表来管理所有内存。\n虚拟机在分配空间时会选定一个 Region(TLAB将分别指定一个Region)，当 Region 的剩余空间不足以分配对象或者小于最小可空间时，将重新指定下一个 Region 分配空间。\nHRegion 当分配对象的大小大于 Region 空间的一半，将会分配一个 Humongous Region 直接进入老年代，省略年轻代的内存复制过程，这个 Humongous Region 的大小将为能容纳对象的最小 Region 空格倍数。\nSATB (snapshot-at-the-beginning) 对象初始化时的快照，引用变化时使用 write barrier 进行更新，在 GC 中利用了此列表进行扫描。\nRSet 与 CMS 不同，G1 使用了记录 Region 引用关系的 Remembered Set 来记录，内部为多个 Card Table ，并且是用于记录 被引用 的对象集合。 使用 三色标记法 + 写屏障(write barrier) 来更新其引用关系。\nG1 解决了 CMS 中的各种疑难问题, 包括暂停时间的可预测性, 并终结了堆内存的碎片化。\nZGC 是一个可伸缩的低延迟垃圾收集器，暂停时间不超过10毫秒，暂停时间不会随堆或实时设置大小而增加\n https://blog.csdn.net/renfufei/article/details/54885190 https://www.zhihu.com/question/53613423/answer/135743258\n 内存模型(JMM) heap 根据空间利用率、垃圾回收存活年龄分为年轻代、老年代，永久代。\n年轻代 年轻代又可细分为 Eden空间、S0空间 (From Survivor)、S1空间 (To Survivor) Eden Space 中存在线程私有的空间 TLAB，是每个线程的缓冲区，存放一些用过即丢弃的对象。\n老年代 当新生代的对象超过设定年龄，或者同龄对象达到幸存区的一半，这些对象将被划入老年代(Old Space)。 只有当老年代空间不足分配发生 Full GC 时 (CMS 中可以为 CMS GC)，才会对老年代的数据进行回收。\n永久代 用于存放元类数据，在并发标记时和类加载器卸载时将会对相关数据进行回收。 当一个类加载器死亡时，相对应的元数据也被销毁，释放其块空间。\nPermgenSpace java8 之前的永久代实现，也称为方法区，为一块固定空间大小，当空间不足时会进行Full GC。 由于区空间大小固定，在大量动态创建类的程序中容易造成OOM。\nMetaSpace 源自 JRockit，在 Java8 与 Hotspot 合并，将 native method area 概念加入 Hotspot，由此得来 MetaSpace 替换原有的 PermGen，容量仅受可用的本地内存限制。\nMetaSpace 的空间是以块 (Chunk) 为单位，这个块的大小取决与申请空间的类加载器类型。\n当类加载器加载类时，从块分配器中获取一份块内存空间存在类元数据，并映射此地址。\n由于每个类加载器申请的块大小不一致，MetaspaceVM 也还未使用压缩技术，这就容易导致内存碎片的产生。\nTLAB 当大量线程申请空间时，JVM 需要对并发操作保障不会发生指针碰撞，这样便增加了复杂性，降低性能。\n因此，在 jdk1.6 以后便引入了 TLAB 技术。\nTLAB 全名 Thread-local allocation buffers，是在线程初始化的时候在堆中新生代申请一块线程私有的分配空间(允许所有线程访问)，减少同步开销，使用参数 -XX:UseTLAB 开启。\n https://www.jianshu.com/p/cd85098cca39\n PLAB 全名 promotion-local allocation buffers，用于 Young GC 时的空间分配及复制。\n其他还有 CLAB，全名 core-local allocation buffers，用于全局的空间分配。\n","date":1526757357,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1526757357,"objectID":"c05fe8a3df823e85722c5cf8e5b66fc7","permalink":"https://moyada.github.io/post/jvm/","publishdate":"2018-05-19T19:15:57Z","relpermalink":"/post/jvm/","section":"post","summary":"JVM(Java虚拟机) JVM 是 JRE 包含的 Java 程序运行所需的程序，屏","tags":[],"title":"Java 虚拟机总结","type":"post"},{"authors":[],"categories":["JVM"],"content":" table th:nth-of-type(1) { width: 250px; } table th:nth-of-type(2) { width: 30px; } table th:nth-of-type(3) { width: 300px; } table th:nth-of-type(4) { width: 150px; }  空间 通用    参数 常用 说明 备注     -Xms\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt; ● Heap 初始化的大小    -Xmx\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt; ● Heap 最大值    -Xmn\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt; ● 新生代的大小 G1 GC 下建议不设置该参数   -Xss\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt; ● 线程栈的大小，默认 1M    -XX:MaxDirectMemorySize=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt;  设置 NIO 的直接缓存最大容量    -XX:SurvivorRatio=\u0026lt;size\u0026gt; ● Eden 和 Survior(from和to) 大小比例，默认是 8    -XX:AutoBoxCacheMax=\u0026lt;size\u0026gt;  设置自动装箱池缓存大小 server模式专有   -XX:+UseAdaptiveGCBoundary  动态化使用资源    -XX:+UseAdaptiveSizePolicy  动态调整各个代区的内存大小，每次 minor gc 后会重新计算 eden，from 和 to 的大小    -XX:NewSize=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt;  设置新生代的初始大小    -XX:MaxNewSize=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt;  设置新生代的最大值    -XX:NewRatio=\u0026lt;size\u0026gt;  设置新生代和老年代的比例    -Dsun.reflect.noInflation=\u0026lt;boolean\u0026gt;  反射时是否使用代理类 默认 false   -Dsun.reflect.inflationThreshold=\u0026lt;size\u0026gt;  反射时生成代理类调用的次数，之后使用 JNI 字节码调用 默认 15   -XX:MaxRAM=\u0026lt;size\u0026gt;  设置最大内存参数    -XX:MinRAMFraction=\u0026lt;size\u0026gt;  设置最大内存除数，默认为 4，即堆空间内 MaxRAM 的四分之一    -XX:ErgoHeapSizeLimit=\u0026lt;size\u0026gt;  限制堆内存上限     Java8之前    参数 常用 说明 备注     -XX:PermSize ● 方法区的初始化大小 java8 后废弃   -XX:MaxPermSize ● 方法区的最大值 java8 后废弃    Java8之后    参数 常用 说明 备注     -XX:MetaspaceSize=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt; ● 元空间的初始化大小 java8 后新增   -XX:MaxMetaspaceSize=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt; ● 元空间的最大值 java8 后新增，初始大小是 21M    Java9之后    参数 常用 说明 备注     -XX:G1HeapRegionSize=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt; ● 设置每个区域块大小 1M-32M 之间,必须是2的幂   -XX:G1NewSizePercent=\u0026lt;size\u0026gt;  设置年轻代大小占堆的最小值百分比 默认值是 Java 堆的 5%   -XX:G1MaxNewSizePercent=\u0026lt;size\u0026gt;  设置年轻代大小占堆的最大值百分比 默认值是 Java 堆的 60%    性能 通用    参数 常用 说明 备注     -server ● 虚拟机会以 server 模式运行，该模式与 C2 编译器共同运行，更注重编译的质量，启动速度慢，但是运行效率高，适合用在服务器环境下，针对生产环境进行了优化    -XX:+AlwaysPreTouch ● JVM 启动时就会先访问所有分配给它的内存,让操作系统把内存真正的分配给JVM    -XX:+UseTLAB ● 通过快速对象分配模式在 TLAB（Thread-local allocation buffers）中进行分配对象 以避免大量的线程通信所导致的性能下降   -XX:TLABSize=\u0026lt;size\u0026gt;  设置 TLAB 的初始化大小    -XX:-ResizeTLAB  禁用自动调整 TLAB    -XX:+UseLargePages  使用最大值内存页 需要 Linux kernel \u0026gt;= 4.7   -XX:+UseTransparentHugePages ● 对大对象分配使用大内存页分配 需要 Linux kernel \u0026gt;= 4.7   -XX:+UseNUMA ● 对象分配优先使用 NUMA 本地内存    -XX:+PerfDisableSharedMem ● GC 日志指向 /dev/shm，避免 IO 造成的 JVM 停顿    -XX:-OmitStackTraceInFastThrow ● 强制要求 JVM 始终抛出含堆栈的异常    -XX:+ShowHiddenFrames  展示虚拟机隐藏的栈信息    -XX:ObjectAlignmentInBytes=\u0026lt;size\u0026gt;  设置 java 对象的内存对齐，默认是 8 字节，指定的值必须是 2 的幂次，且必须在 8 和 256 之间    -XX:+PageAlignDirectMemory  设置堆外内存使用内存对齐    -XX:+UseCompressedOops ● 在 64 位环境下，压缩对象头    -XX:+UseFastAccessorMethods  原始类型的快速优化    -XX:+UseFastEmptyMethods  空方法优化    -XX:+UseFastJNIAccessors  引用类或 int 的成员方法优化    -XX:LargePageSizeInBytes=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt;  Heap 中内存页的最大值，参数必须是 2 的幂，不可设置过大    -XX:-UseBiasedLocking  禁用偏向锁 在存在大量锁对象的创建并高度并发的环境下禁用偏向锁能够带来一定的性能优化   -XX:BiasedLockingStartupDelay=\u0026lt;size\u0026gt;   延迟(秒钟)启用偏向锁   -XXtlaSize:min=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt;,preferred=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt;  调整 TLA，每个线程私有的空间的默认最小大小和默认首选大小    -XX:+AlwaysAtomicAccesses  实现对所有 Access 的原子性保证    -XX:+EliminateAllocations  开启标量替换    -XX:+DoEscapeAnalysis  进行逃逸分析之后，创建的可分解的对象都将由栈上分配 标量替换，栈上分配，受限于栈的空间大小   -XX:+PrintEscapeAnalysis  查看逃逸分析结果    -XX:+EliminateLocks  分析并且消除无线程竞争下的锁 同步消除，必须开启 -XX:+DoEscapeAnalysis 和 -server 模式   -XX:+PrintEliminateAllocations  查看标量的替换情况    -XX:LiveNodeCountInliningCutoff=\u0026lt;size\u0026gt;  max number of live nodes in a method    -XX:+PositiveIdentityHash  只允许分配正数的哈希值     JIT    参数 常用 说明 备注     -XX:+EnableJVMCI  使用 Graal java10   -XX:+UseJVMCICompiler  启动 Graal JIT编译器 java10   -XX:+TieredCompilation ● 启用分层编译策略，根据编译器编译、优化的规模与耗时，划分出不同的编译层次 java8 默认开启   -XX:TieredStopAtLevel=\u0026lt;size\u0026gt;  设置 JIT 编译的最高层级    -XX:+UseCodeCacheFlushing ● 当代码缓存被填满时让 JVM 放弃一些编译代码    -XX:InitialCodeCacheSize=\u0026lt;size\u0026gt;  设置初始代码缓存的大小    -XX:ReservedCodeCacheSize=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt;  设置代码缓存的最大值    -XX:CompileThreshold=\u0026lt;size\u0026gt;  当某个方法被调用 + 循环次数累计超过该值时，触发标准的 JIT 编译    -XX:InterpreterBackwardBranchLimit=\u0026lt;size\u0026gt;  当某个方法被调用 + 循环次数累计超过该值时，触发 OSR 形式的 JIT 编译    -XX:HugeMethodLimit=\u0026lt;size\u0026gt;  JIT 编译字节码大小超过 size 字节的方法就是巨型方法    -XX:+DontCompileHugeMethods  不编译巨型方法    -XX:-UseCounterDecay  禁止 JIT 调用计数器衰减    -XX:+CompileCommand=command,method[,option]  定制编译需求，比如过滤某个方法不做 JIT 编译    -XX:+InlineSynchronizedMethods  对同步方法进行内联    -XX:MaxInlineLevel=\u0026lt;size\u0026gt;  在进行方法内联前，方法的最多嵌套调用次数 默认为 9   -XX:MaxInlineSize=\u0026lt;size\u0026gt;  内联方法的最大字节码大小 默认为 35   -XX:FreqInlineSize=\u0026lt;size\u0026gt;  内联 频繁执行 的方法的最大字节码大小 默认为 325   -XX:MaxTrivialSize=\u0026lt;size\u0026gt;  归属于不重要的方法的最大字节码大小 默认为 6   -XX:MinInliningThreshold=\u0026lt;size\u0026gt;  方法被内联的最小调用次数 默认为 250   -XX:MaxRecursiveInlineLevel=\u0026lt;size\u0026gt;  对方法的递归调用做内联优化 默认为 1   -XX:Tier1MaxInlineSize=\u0026lt;size\u0026gt;  1层内联方法的最大字节码大小 默认为 8   -XX:Tier1FreqInlineSize=\u0026lt;size\u0026gt;  1层内联 频繁执行 的方法的最大字节码大小 默认为 35   -XX:LiveNodeCountInliningCutoff=\u0026lt;size\u0026gt;  方法内最大存活的 JIT IR 节点数量 默认为 20000    Docker    参数 常用 说明 备注     -XX:ActiveProcessorCount=\u0026lt;size\u0026gt;  指定 jvm 使用 cpu 个数    -XX:+UseContainerSupport  支持容器化功能，默认开启    -XX:+UseCGroupMemoryLimitForHeap  开启 CGroup Namespace jdk10 后废弃    GC 通用    参数 常用 说明 备注     -XX:+UseCompressedClassPointers ● 开启压缩类指针 64 位平台上默认打开   -XX:+UseParNewGC ● 设置年轻代为多线程收集 可以和 CMS GC 一起使用   -XX:+ParallelRefProcEnabled ● 并行的处理对象标记过程    -XX:ParallelGCThreads=\u0026lt;size\u0026gt; ● 指定并行处理 GC 的线程数 默认 GC 线程数为 CPU 的数量   -XX:ParGCCardsPerStrideChunk=\u0026lt;size\u0026gt; ● 设置每个线程每次扫描的 Card 数量 CardTable 用来标记老年代的某一块内存区域中的对象是否持有新生代对象的引用,卡表的数量取决于老年代的大小和每张卡对应的内存大小   -XX:MinHeapFreeRatio=\u0026lt;size\u0026gt;  指定堆内存在使用率以下进行收缩    -XX:+DisableExplicitGC  禁止代码中显示调用 GC CMS 下可使用 -XX:+ExplicitGCInvokesConcurrent 替换   -XX:+GCLockerInvokesConcurrent  并发的执行 GC Lock    -XX:ConcGCThreads=\u0026lt;size\u0026gt;  设置并行GC的线程数 设置为并行垃圾回收线程数 (ParallelGCThreads) 的 1/4 左右   -XX:MaxTenuringThreshold=\u0026lt;size\u0026gt;  设置新生代经过多少次YGC晋升到老生代    -XX:PretenureSizeThreshold=\u0026lt;size\u0026gt;  晋升老年代对象年龄 无默认值，Paralle Scavenge收集器无法识别   -XX:CompressedClassSpaceSize=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt;  设置指针压缩空间大小    -XX:+OptimizeStringConcat  字符串concat优化 默认开启   -XX:+UseParallelGC  选择垃圾收集器为并行收集器 不能和 CMS GC 一起使用,系统吨吐量优先   -XX:GCTimeRatio=\u0026lt;size\u0026gt;  设置吞吐量大小    -XX:SoftRefLRUPolicyMSPerMB=\u0026lt;size\u0026gt;  设置每兆空间中软引用的生命周期 (多少毫秒后清除)    -Xnoclassgc  不对 Class 元数据进行 GC     CMS    参数 常用 说明 备注     -XX:+UseConcMarkSweepGC ● 启用 CMS 低停顿垃圾收集器    -XX:+CMSParallelRemarkEnabled ● 开启并行标记    -XX:+ExplicitGCInvokesConcurrent ● 命令JVM无论什么时候调用系统 GC，都执行 CMS GC，而不是 Full GC    -XX:+ExplicitGCInvokesConcurrent  AndUnloadsClasses ● 保证当有系统 GC 调用时，永久代也被包括进 CMS 垃圾回收的范围内    -XX:+CMSConcurrentMTEnabled  并发的 CMS 阶段将以多线程执行 默认开启   -XX:+CMSParallelInitialMarkEnabled  开启初始标记过程中的并行化    -XX:ParallelCMSThreads=\u0026lt;size\u0026gt;  设定 CMS 的线程数量    -XX:CMSInitiatingOccupancyFraction=\u0026lt;size\u0026gt; ● 指定 CMS 老年代在对内存占用率达到多少百分比的时候开始GC    -XX:CMSInitiatingPermOccupancyFraction=\u0026lt;size\u0026gt;  指定 CMS 永久代在对内存占用率达到多少百分比的时候开始GC    -XX:+UseCMSInitiatingOccupancyOnly  只使用 CMSInitiatingOccupancyFraction 设置的回收阈值，否则交由 JVM 动态调整    -XX:CMSTriggerRatio  当 CMSInitiatingOccupancyFraction 错误时的生成策略    -XX:+CMSScavengeBeforeRemark  重新标记之前对年轻代做一次 Minor GC    -XX:+CMSClassUnloadingEnabled ● 在 CMS GC 时对永久代进行垃圾回收(类卸载) 在 Full GC 时会扫描 MetaSpace/PermGen   -XX:CMSFullGCsBeforeCompaction=\u0026lt;size\u0026gt;  指定进行多少次Full GC之后，执行内存空间整理    -XX:UseCMSCompactAtFullCollection  在 Full GC 的时候，对年老代的压缩 可能会影响性能，但是可以消除碎片    G1    参数 常用 说明 备注     -XX:+UseG1GC ● 使用G1垃圾回收器    -XX:InitiatingHeapOccupancyPercent=\u0026lt;size\u0026gt; ● 设置触发并发标记周期时的堆内存占用率阈值. G1之类的垃圾收集器用它来触发并发GC周期,基于整个堆的使用率,而不只是某一代内存的使用比 值为 0 则表示一直执行 GC 循环，默认值为 45   -XX:+G1UseAdaptiveIHOP ● 开启自适应并发标记控制    -XX:G1ConcRefinementThreads=\u0026lt;size\u0026gt;  设置 Remenbered Set 的工作线程数目    -XX:MaxGCPauseMillis=\u0026lt;size\u0026gt;  设置每次年轻代垃圾回收的最长时间    -XX:+UseStringDeduplication ● 使用字符串去重机制 G1 收集器下生效   -XX:G1MixedGCLiveThresholdPercent=\u0026lt;size\u0026gt; ● 设置启动混合垃圾回收周期的老年代占用率阈值 默认占用率为 65%   -XX:G1HeapWastePercent=\u0026lt;size\u0026gt; ● 设置允许浪费的堆百分比，如果触发回收百分比小于该百分比，JVM 则不会启动混合垃圾回收周期 默认值是 10%   -XX:G1MixedGCCountTarget=\u0026lt;size\u0026gt; ● 设置标记周期完成后，执行混合垃圾回收老年代的目标次数 默认值是 8   -XX:G1OldCSetRegionThresholdPercent=\u0026lt;size\u0026gt; ● 设置混合垃圾回收期间要回收的最大旧区域数 默认值是 Java 堆的 10%   -XX:G1ReservePercent=\u0026lt;size\u0026gt;  设置作为预留存活区在 heap 中的百分比 默认值是 10%   -XX:+G1SummarizeConcMark      -XX:+G1PrintHeapRegions  打印 G1 收集器收集的区域    -XX:+G1SummarizeRSetStats  打印标记过程引用信息(Print RSet processing information)    -XX:G1SummarizeRSetStatsPeriod=\u0026lt;size\u0026gt;  指定 GC 周期频率报告    -XX:-G1EagerReclaimHumongousObjects  禁用 G1 优先尝试回收大对象    -XX:+G1TraceEagerReclaimHumongousObjects  G1 在每个 Young GG 周期都会回收消亡的 Humongous 对象 默认开启   -XX:+G1ConcRegionFreeingVerbose  Debug JVM     ZGC    参数 常用 说明 备注     -XX:+UseZGC  启动 ZGC 垃圾回收器 java11，非正式版本需开启 -XX:+UnlockExperimentalVMOptions 解锁参数     https://wiki.openjdk.java.net/display/zgc/Main\n Shenandoah GC    参数 常用 说明 备注     -XX:+UseShenandoahGC  启动 Shenandoah 垃圾回收器 jdk12，非正式版本需开启 -XX:+UnlockExperimentalVMOptions 解锁参数   -XX:ShenandoahInitFreeThreshold=\u0026lt;size\u0026gt;  设置触发垃圾回收的初始阈值    -XX:ShenandoahMinFreeThreshold=\u0026lt;size\u0026gt;  无条件触发垃圾回收的最小空间阀值    -XX:ShenandoahAllocSpikeFactor=\u0026lt;size\u0026gt;  设置预留堆空间百分比    -XX:ShenandoahGarbageThreshold=\u0026lt;size\u0026gt;  设置一个 Region 被视为 可回收 的垃圾对象所需百分比    -XX:ShenandoahFreeThreshold=\u0026lt;size\u0026gt;  设置启动垃圾回收的空闲堆空间百分比    -XX:ShenandoahAllocationThreshold=\u0026lt;size\u0026gt;  设置上一次垃圾回收周期的分配内存百分比    -XX:+ShenandoahPacing  根据垃圾回收效率分配应用程序的线程与可用空间    -XX:ShenandoahPacingMaxDelay=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt;  在最大延迟时间之前，将不干预应用程序的分配    -XX:+ShenandoahDegeneratedGC  当程序遇到分配失败时，Shenandoah 将会暂停应用线程，直到完成后续垃圾回收工作    -XX:+ShenandoahVerify  检测垃圾回收异常    -XX:+ShenandoahGCHeuristics=[ passive | aggressive ]  暂停应用线程执行垃圾回收 或 执行紧凑的垃圾回收并疏散所有非空 Region    -XX:+ShenandoahVerifyOptoBarriers  验证 C2 模式      https://wiki.openjdk.java.net/display/shenandoah/Main\n 日志 Java9之后\njvm日志使用 -Xlog[\u0026lt;what\u0026gt;][:[\u0026lt;output\u0026gt;][:[\u0026lt;decorators\u0026gt;][:\u0026lt;output-options\u0026gt;]]] 记录 可以使用 java -Xlog:help 查看帮助文档\n 案例   -Xlog:disable -Xlog:gc+liveness=info,rt*=off:file=../logs/gc_%t.log:time,uptimemillis,pid:filecount=5,filesize=1024 先关闭所有日志，打开 gc 和存活对象的日志，关闭包含 rt 的日志级别，输出日志至文件，额外包含时间、耗时、进程 id，以 5 个 1M 的文件循环保存历史日志文件。\n 参考: http://www.cnblogs.com/IcanFixIt/p/7259712.html https://juejin.im/post/5a981f056fb9a028bf04bec4 https://blog.gceasy.io/2017/10/17/43-gc-logging-flags-removed-in-java-9/\n http://openjdk.java.net/jeps/158  通用    参数 常用 说明 备注     -Xloggc=\u0026lt;file\u0026gt;  日志文件 例如 -Xloggc=/data/application/logs/gc.log   -XX:+verbosegc ● 打印每次GC的消息    -XX:+PrintGC ● 打印每次GC的消息    -XX:+PrintGCCause ● 打印 GC 的原因    -XX:+PrintGCDetails ● 打印GC日志详情 建议开启   -XX:+PrintGCTimeStamps  输出GC的时间戳 以基准时间的形式   -XX:+PrintGCDateStamps  输出GC的时间戳 以日期的形式，如 2013-05-04T21:53:59.234+0800   -XX:ErrorFile=\u0026lt;file\u0026gt; ● 当 JVM 出现致命错误时，生成错误文件，包括了导致 jvm crash 的重要信息    -XX:+PrintGCApplicationStoppedTime ● 打印 JVM 的停顿时间    -XX:+PrintGCApplicationConcurrentTime  打印 JVM 在两次停顿之间的正常运行时间    -XX:+HeapDumpOnOutOfMemoryError ● 遇到 OutOfMemoryError 时拍摄一个堆转储快照，并将其保存在一个文件中。    -XX:+HeapDumpBeforeFullGC ● 遇到 Full GC 前拍摄一个堆转储快照，并将其保存在一个文件中。    -XX:+HeapDumpAfterFullGC  遇到 Full GC 后拍摄一个堆转储快照，并将其保存在一个文件中。    -XX:HeapDumpPath=\u0026lt;file\u0026gt; ● 指定导出堆的存放路径    -XX:-OmitStackTraceInFastThrow ● 要求 JVM 始终抛出含堆栈的异常    -XX:+UseGCLogFileRotation  开启日志文件的循环    -XX:NumberOfGCLogfiles=\u0026lt;size\u0026gt;  配置日志循环文件个数    -XX:GCLogfileSize=\u0026lt;size\u0026gt;\u0026lt;unit\u0026gt;  指定日志文件大小    -XX:NativeMemoryTracking=[off | summary | detail]  查看 JVM 本地方法使用情况 jcmd  VM.native_memory [summary \u0026amp;##124; detail \u0026amp;##124; baseline \u0026amp;##124; summary.diff \u0026amp;##124; detail.diff \u0026amp;##124; shutdown] [scale= KB \u0026amp;##124; MB \u0026amp;##124; GB]    -XX:+PrintNMTStatistics  在 JVM 退出时打印 NMT 报告    -verbose:class  在程序运行的时候有多少类被加载 verbose:class 来监视 java -verbose:class   -verbose:gc  在虚拟机发生内存回收时在输出设备显示信息    -verbose:jni  输出 native 方法调用的相关情况    -XX:+PrintHeapAtGC  在进行 GC 的前后打印出堆的信息    -XX:+PrintFlagsInitial  显示所有可设置参数及默认值    -XX:+PrintFlagsFinal  显示可以获取到所有设置后参数及值    -XX:+UnlockDiagnosticVMOptions  解锁对 JVM 进行诊断的选项参数    -XX:+PrintCommandLineFlags  显示出 JVM 初始化完毕后所有跟最初的默认值不同的参数及它们的值    -XX:+PrintTenuringDistribution  打印内存模型各代信息    -XX:+DisplayVMOutput  打印 JVM 输出    -XX:+LogVMOutput  记录 JVM 输出到日志    -XX:+PrintJNIGCStalls  打印进入临界区 (JVM 传向 JNI) 的线程信息    -XX:+PrintFLSStatistics=\u0026lt;size\u0026gt;  GC 前后输出内存的统计信息 当 size \u0026gt; 1 时还会输出 IndexedFreeLists 统计信息   -XX:+PrintSafepointStatistics  输出 safepoint 的统计信息    -XX:+PrintSafepointStatisticsCount=\u0026lt;size\u0026gt;  输出 safepoint 的统计次数    -XX:+PrintAdaptiveSizePolicy  打印自适应收集的大小    -XX:+PrintReferenceGC  跟踪系统内的软引用,弱引用,虚引用和 finallize 队列    -XX:+PrintClassHistogram  打印出实例的数量以及空间大小     JIT    参数 常用 说明 备注     -XX:+PrintInlining  打印内联优化的方法    -XX:+PrintCompilation  简单的输出一些关于从字节码转化成本地代码的编译过程    -XX:+LogCompilation  输出 JIT 的编译信息    -XX:+PrintAssembly  通过使用外部的 disassembler.so 库打印汇编的字节码和 native 方法来辅助分析 需要和-XX:UnlockDiagnosticVMOptions一起使用   -XX:+TraceClassLoading  动态跟踪类的加载    -XX:+TraceClassUnloading  动态跟踪类的卸载    -XX:+PrintInterpreter  打印解释过程中生成的汇编指令 exclude，跳过编译指定的方法; compileonly，只编译指定的方法; inline/dontinline，设置是否内联指定方法; print，打印生成的汇编代码   -XX:+PrintAssembly  打印JIT编译过程中生成的汇编指令 无法使用该参数可以用 -XX:+PrintOptoAssembly 来代替    G1    参数 常用 说明 备注     -XX:G1LogLevel=fine, finer, finest  日志包含信息以及每个工作线程的信息    -XX:+PrintStringDeduplicationStatistics  打印字符串去重的影响     其他    参数 常用 说明 备注     -Dcom.sun.management.jmxremote=\u0026lt;boolean\u0026gt;  是否支持远程 JMX 监控    -Dcom.sun.management.jmxremote.port=\u0026lt;port\u0026gt;  指定远程监控端口号，随机分配 RMI 端口号    -Dcom.sun.management.jmxremote.ssl=\u0026lt;boolean\u0026gt;  是否对连接开启 SSL 加密    -Dcom.sun.management.jmxremote.authenticate=\u0026lt;boolean\u0026gt;  是否需要开启用户认证    -Dcom.sun.management.jmxremote.rmi.port=\u0026lt;port\u0026gt;  指定 RMI 与远程监控端口号    -Djava.rmi.server.hostname=\u0026lt;host\u0026gt;  指定 RMI 服务的对应主机名    -Djava.net.preferIPv4Stack=true  优先使用 IPv4    -Djava.security.egd=file:/dev/./urandom ● 使用非阻塞的随机数与熵池策略    -Djava.util.concurrent.ForkJoinPool.common.parallelism=\u0026lt;size\u0026gt;  修改 ForkJoinPool 的默认线程数    -XX:+UnlockExperimentalVMOptions  解锁 JVM 实验性参数    -XX:+UnlockCommercialFeatures  解锁 JVM 商业特性    -XX:+LogCommercialFeatures  对商业特性进行日志记录    -XX:+FlightRecorder  开启 JFR 监控    -XX:FlightRecorderOptions=\u0026lt;parameter\u0026gt;=\u0026lt;value\u0026gt;  设置 JFR 监控参数    -XX:OnError=command  设置当发生不可恢复的错误时执行的命令    -XX:OnOutOfMemoryError=command  设置当发生内存溢出错误时执行的命令    -XX:+AggressiveOpts  使用预设的优化參數    -Djava.awt.headless=true  使用计算能力模拟外设功能 例如创建图片    ","date":1524605144,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1524605144,"objectID":"32febb30fbadba76590060a1a156a0a5","permalink":"https://moyada.github.io/post/jvm-param/","publishdate":"2018-04-24T21:25:44Z","relpermalink":"/post/jvm-param/","section":"post","summary":"table th:nth-of-type(1) { width: 250px; } table th:nth-of-type(2) { width: 30px; } table th:nth-of-type(3) { width: 300px; } table th:nth-of-type(4) { width: 150px; } 空间 通用 参数","tags":["GC"],"title":"JVM 参数","type":"post"},{"authors":null,"categories":null,"content":"cpu top 是基本的系统监控命令，可以查看到当前系统的总cpu，内存，负载情况，以及各个进程的情况。 在多核cpu的系统中可以按1切换每个逻辑cpu的情况。\nvmstat 是一种低开销的系统性能观察方式，并且还能够查看到cpu队列(r)、io阻塞(b)、中断被处理数目(in)、上下文切换数目(cs)\ndstat dstat是实时地监控所有系统资源 常见选项 -l ：显示负载统计量 -m ：显示内存使用率（包括used，buffer，cache，free值） -r ：显示I/O统计 -s ：显示交换分区使用情况 -t ：将当前时间显示在第一行 –fs ：显示文件系统统计数据（包括文件总数量和inodes值） –nocolor ：不显示颜色（有时候有用） –socket ：显示网络统计数据 –tcp ：显示常用的TCP统计 –udp ：显示监听的UDP接口及其当前用量的一些动态数据 –output file [-cdn]：输出监控情况为文件保存，可用-cdn设置保存csv\n常见插件 -–disk-util ：显示某一时间磁盘的忙碌状况 -–freespace ：显示当前磁盘空间使用率 -–proc-count ：显示正在运行的程序数量 -–top-bio ：指出块I/O最大的进程 -–top-cpu ：图形化显示CPU占用最大的进程 -–top-io ：显示正常I/O最大的进程 -–top-mem ：显示占用最多内存的进程\niostat、mpstat、sar 使用 yum install sysstat 安装就会有这些功能\niostat是监控物理设备的 I/O 负载情况\n常见用法 iostat -d -k 1\t#查看TPS和吞吐量信息(磁盘读写速度单位为KB) iostat -d -m 1 #查看TPS和吞吐量信息(磁盘读写速度单位为MB) iostat -d -x -k 1\t#查看设备使用率（%util）、响应时间（await） iostat -c 1 10 #查看cpu状态\nmpstat是实时系统监控工具，并且可以查看多核心cpu中每个计算核心的统计数 常见用法 mpstat -P ALL 1\t#查看整体cpu与各个cpu的使用情况\nsar是对系统的活动进行监控报告，包括文件读写、系统调用、磁盘I/O、CPU效率、内存使用、进程活动、IPC 常见选项 -A：所有报告的总和\n-u：输出CPU使用情况的统计信息\n-v：输出inode、文件和其他内核表的统计信息\n-d：输出每一个块设备的活动信息\n-r：输出内存和交换空间的统计信息\n-b：显示I/O和传送速率的统计信息\n-a：文件读写情况\n-c：输出进程统计信息，每秒创建的进程数\n-R：输出内存页面的统计信息\n-y：终端设备活动情况\n-w：输出系统交换活动信息\n-o file:将命令结果以二进制格式存放在文件中，file 是文件名\n常见用法 sar -uq\t#查看CPU使用情况 sar -brw\t#查看内存使用情况 sar -bud\t#查看I/O使用情况\n内存 pmap 用于显示一个或多个进程的内存状态，需要带上进程端口号\n流量 nicstat 监控网卡及网络流量的工具\nnetstate 用于显示各种网络相关信息\n常见参数 -a (all)显示所有选项，默认不显示LISTEN相关 -t (tcp)仅显示tcp相关选项 -u (udp)仅显示udp相关选项 -n 拒绝显示别名，能显示数字的全部转化成数字。 -l 仅列出有在 Listen (监听) 的服務状态\n-p 显示建立相关链接的程序名 -r 显示路由信息，路由表 -e 显示扩展信息，例如uid等 -s 按各个协议进行统计 -c 每隔一个固定时间，执行该netstat命令。\nifstat 是一个统计网络接口活动状态的工具\niftop nmap ","date":1503445656,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1503445656,"objectID":"deb8164425bcb1486990f26ce6a62fb9","permalink":"https://moyada.github.io/bak/linux-cpu/","publishdate":"2017-08-22T23:47:36Z","relpermalink":"/bak/linux-cpu/","section":"bak","summary":"cpu top 是基本的系统监控命令，可以查看到当前系统的总cpu，内存","tags":null,"title":"linux资源查看","type":"bak"},{"authors":[],"categories":[""],"content":"在前后端交互的开发中可能会遇到跨域的问题，如果只是简单的 GET 请求的话可以利用 Json 来解决。\n对于非 GET 请求的话就可以采用 CORS 协议来解决了。CORS 是一个W3C标准，全称是\u0026quot;跨域资源共享\u0026rdquo;（Cross-origin resource sharing）。 它允许浏览器向跨源服务器，发出XMLHttpRequest请求，从而解决了只能同源使用的限制，具体详解参考 跨域资源共享 CORS 详解。\n如果你需要信息的绝对安全，不要依赖 CORS 当中的权限制度，应当使用更多其它的措施来保障，比如 OAuth2。\n对于 Java 服务器的话，常用的解决方案就是自定义个 Filter 来添加相应头。\n@Component public class CorsFilter implements Filter { private static final Logger logger = LoggerFactory.getLogger(CorsFilter.class); @Override public void init(FilterConfig filterConfig) throws ServletException { } @Override public void doFilter(ServletRequest servletRequest, ServletResponse servletResponse, FilterChain filterChain) throws IOException, ServletException { HttpServletResponse response = (HttpServletResponse) servletResponse; String origin = (String) servletRequest.getRemoteHost()+\u0026quot;:\u0026quot;+servletRequest.getRemotePort(); logger.info(\u0026quot;orgin: {} request cors resource.\u0026quot;, origin); response.setHeader(\u0026quot;Access-Control-Allow-Origin\u0026quot;, \u0026quot;*\u0026quot;); response.setHeader(\u0026quot;Access-Control-Allow-Methods\u0026quot;, \u0026quot;POST, GET, OPTIONS, DELETE\u0026quot;); response.setHeader(\u0026quot;Access-Control-Max-Age\u0026quot;, \u0026quot;3600\u0026quot;); response.setHeader(\u0026quot;Access-Control-Allow-Headers\u0026quot;, \u0026quot;x-requested-with,Authorization\u0026quot;); response.setHeader(\u0026quot;Access-Control-Allow-Credentials\u0026quot;,\u0026quot;true\u0026quot;); filterChain.doFilter(servletRequest, servletResponse); } @Override public void destroy() { } }  OPTIONS 是预请求必须允许。 Authorization 是做了 OAuth2 登录响应所必须的。 预请求在实际请求之前发出的请求，为了保证实际请求能够完成的权限请求，通过预请求的响应将能够确定实际请求是否的完成。\n// 预请求 OPTIONS /cors HTTP/1.1 Origin: http://api.alice.com // 实际请求类型 Access-Control-Request-Method: POST Access-Control-Request-Headers: X-Custom-Header Host: api.bob.com Accept-Language: en-US Connection: keep-alive User-Agent: Mozilla/5.0... // 预请求响应 Access-Control-Allow-Origin: * Access-Control-Allow-Methods: GET, POST, PUT Access-Control-Allow-Headers: X-Custom-Header Access-Control-Allow-Credentials（可选）- 表示是否允许cookies Access-Control-Max-Age（可选） – 以秒为单位的缓存时间，允许时应当尽可能缓存。 Content-Type: text/html; charset=utf-8  \u0026lt;filter\u0026gt; \u0026lt;filter-name\u0026gt;cors\u0026lt;/filter-name\u0026gt; \u0026lt;filter-class\u0026gt;CorsFilter\u0026lt;/filter-class\u0026gt; \u0026lt;/filter\u0026gt; \u0026lt;filter-mapping\u0026gt; \u0026lt;filter-name\u0026gt;cors\u0026lt;/filter-name\u0026gt; \u0026lt;url-pattern\u0026gt;/api/*\u0026lt;/url-pattern\u0026gt; \u0026lt;/filter-mapping\u0026gt;  在 Spring 中提供了更为简单便捷的方法。\n 使用 @CrossOrigin 注解来设置跨域访问所允许的域名 继承 WebMvcConfigurerAdapter 设置跨域相关配置  @Component public class CorsConfigurerAdapter extends WebMvcConfigurerAdapter { @Override public void addCorsMappings(CorsRegistry registry) { registry.addMapping(\u0026quot;/api/*\u0026quot;).allowedOrigins(\u0026quot;*\u0026quot;); } }   详细参考 Spring官方文档\n ","date":1500844908,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1500844908,"objectID":"ad538b927117c776b6bcd1481df70465","permalink":"https://moyada.github.io/post/cros/","publishdate":"2017-07-23T21:21:48Z","relpermalink":"/post/cros/","section":"post","summary":"在前后端交互的开发中可能会遇到跨域的问题，如果只是简单的 GET 请","tags":["Spring"],"title":"通过 CROS 协议解决跨域问题","type":"post"},{"authors":[],"categories":["Maven"],"content":"pom配置文件 命令  mvn clean: 清除target目录 mvn compile: 编译主程序 mvn test-compile: 编译测试程序 mvn test: 执行测试 mvn package: 打包项目输出到target目录下 mvn install: 安装项目到本地仓库 安装本地jar包: mvn install:install-file -Dfile=a.jar -DgroupId=com.a -DartifactId=a -Dversion=0.0.1 -Dpackaging=jar mvn deploy: 将打包好的包上传到远程仓库,[-N]跳过子模块 mvn site: 生成站点 mvn dependency: 操作依赖 获取远端依赖: mvn dependency:resolve 获取单个远端依赖: mvn dependency:get -Dartifact=\u0026lt;groupId\u0026gt;:\u0026lt;artifactId\u0026gt;:\u0026lt;version\u0026gt;  跳过测试用例 -Dmaven.test.skip=true\n依赖 坐标  \u0026lt;groupid\u0026gt; 项目坐标: 一般为公司域名倒写+项目名 \u0026lt;artifactId\u0026gt; 模块坐标: 项目子模块名 \u0026lt;version\u0026gt; 版本: 带SNAPSHOT表示为一个不稳定的版本，REALEASE表示为一个正式的版本  依赖的范围 依赖的范围可以通过\u0026lt;scope\u0026gt;标签来指定\n compile: 主程序范围的依赖，对主程序有效，对测试程序有效，参与打包 test: 测试范围的依赖，只对测试程序有效，不参与打包，比如junit provided: 不参与打包，只在开发阶段有效，比如servlet-api.jar  依赖的排除 对于不需要的传递性依赖，可以通过\u0026lt;exclusions\u0026gt;标签来排除依赖引用\n\u0026lt;dependency\u0026gt; ... \u0026lt;exclusions\u0026gt; \u0026lt;exclusion\u0026gt; \u0026lt;groupid\u0026gt;com.xxx\u0026lt;/groupid\u0026gt; \u0026lt;artifactid\u0026gt;xxxx\u0026lt;/artifactid\u0026gt; \u0026lt;/exclusion\u0026gt; \u0026lt;/exclusions\u0026gt; \u0026lt;/dependency\u0026gt;  版本号管理 对于多个同版本号的依赖可以通过\u0026lt;properties\u0026gt;配置来统一管理，在\u0026lt;version\u0026gt;以${标签名}引用\n\u0026lt;properties\u0026gt; \u0026lt;com.spring.version\u0026gt;4.3.0-REALEASE\u0026lt;/com.spring.version\u0026gt; \u0026lt;/properties\u0026gt; ... \u0026lt;version\u0026gt;${com.spring.version}\u0026lt;/version\u0026gt;  另外，还可以通过\u0026lt;properties\u0026gt;配置项目默认配置\n\u0026lt;!-- 配置项目字符集配置 --\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;project.build.sourceEncoding\u0026gt;UTF-8\u0026lt;/project.build.sourceEncoding\u0026gt; \u0026lt;/properties\u0026gt;  继承 继承功能可以统一管理各个模块工程中对依赖的版本，配置继承后要先安装父工程\n\u0026lt;!-- 子工程中声明父工程 --\u0026gt; \u0026lt;parent\u0026gt; \u0026lt;groupid\u0026gt;com.xxx\u0026lt;/groupid\u0026gt; \u0026lt;artifactId\u0026gt;xxxx\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;0.0.1-SNAPSHOT\u0026lt;/version\u0026gt; \u0026lt;!-- 以当前工程的pom.xml为基准的父工程pom.xml路径 --\u0026gt; \u0026lt;relativePath\u0026gt;../xxxx/pom.xml\u0026lt;/relativePath\u0026gt; \u0026lt;/parent\u0026gt;  \u0026lt;!-- 父工程依赖管理 --\u0026gt; \u0026lt;dependencyManagement\u0026gt; \u0026lt;dependencies\u0026gt; \u0026lt;dependency\u0026gt; ... \u0026lt;/dependency\u0026gt; \u0026lt;/dependencies\u0026gt; \u0026lt;/dependencyManagement\u0026gt;  聚合 聚合用于统一安装子工程模块，在父工程的pom.xml文件中配置\n\u0026lt;modules\u0026gt; \u0026lt;!-- 指定子工程的相对路径 --\u0026gt; \u0026lt;module\u0026gt;../xxx\u0026lt;/module\u0026gt; \u0026lt;/modules\u0026gt;  构建 maven通过命令mvn package 可以将项目打包，对于多模块的项目， 可以使用mvn package -pl 子项目名 -am 或 mvn package \u0026ndash;projects 子项目名 \u0026ndash;also-make 将父项目和子项目一起进行打包同时构建所需依赖\nmaven 还可以使用org.codehaus.cargo这个插件直接将项目打包部署到远程服务器上\n\u0026lt;!-- 配置构建过程 --\u0026gt; \u0026lt;build\u0026gt; \u0026lt;finalName\u0026gt;工程名\u0026lt;/finalName\u0026gt; \u0026lt;!-- 插件 --\u0026gt; \u0026lt;plugins\u0026gt; \u0026lt;plugin\u0026gt; \u0026lt;!-- cargo是启动/停止/配置servlet容器插件 --\u0026gt; \u0026lt;groupid\u0026gt;org.codehaus.cargo\u0026lt;/groupid\u0026gt; \u0026lt;artifactId\u0026gt;cargo-maven2-plugin\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;1.2.3\u0026lt;/version\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;container\u0026gt; \u0026lt;containerId\u0026gt;tomcat7x\u0026lt;/containerId\u0026gt; \u0026lt;home\u0026gt;/usr/local/devtools/apache-tomcat-7.0.55\u0026lt;/home\u0026gt; \u0026lt;/container\u0026gt; \u0026lt;configuration\u0026gt; \u0026lt;type\u0026gt;existing\u0026lt;/type\u0026gt; \u0026lt;home\u0026gt;/usr/local/devtools/apache-tomcat-7.0.55\u0026lt;/home\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;!-- 更改监听端口 --\u0026gt; \u0026lt;cargo.servlet.port\u0026gt;8088\u0026lt;/cargo.servlet.port\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;/configuration\u0026gt; \u0026lt;!-- 配置声明周期阶段 --\u0026gt; \u0026lt;executions\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;cargo-run\u0026lt;/id\u0026gt; \u0026lt;!-- 声明周期的阶段 --\u0026gt; \u0026lt;phase\u0026gt;install\u0026lt;/phase\u0026gt; \u0026lt;!-- 插件的目标 --\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;run\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;execution\u0026gt; \u0026lt;id\u0026gt;clean-deployer\u0026lt;/id\u0026gt; \u0026lt;!-- 声明周期的阶段 --\u0026gt; \u0026lt;phase\u0026gt;deploy\u0026lt;/phase\u0026gt; \u0026lt;!-- 插件的目标 --\u0026gt; \u0026lt;goals\u0026gt; \u0026lt;goal\u0026gt;deployer-undeploy\u0026lt;/goal\u0026gt; \u0026lt;/goals\u0026gt; \u0026lt;/execution\u0026gt; \u0026lt;/executions\u0026gt; \u0026lt;/plugin\u0026gt; \u0026lt;/plugins\u0026gt; \u0026lt;/build\u0026gt;     Goals Description     cargo:start Start a container.   cargo:run Start a container and wait for the user to press CTRL + C to stop.   cargo:stop Stop a container.   cargo:restart Stop and start again a container. If the container was not running before calling cargo:restart, it will simply be started.   cargo:configure Create the configuration for a local container, without starting it. Note that the cargo:start and cargo:run goals will also install the container automatically (but will not call cargo:install).   cargo:package Package the local container.   cargo:daemon-start Start a container via the daemon.   cargo:daemon-stop Stop a container via the daemon.   cargo:deployer-deploy (aliased to cargo:deploy) Deploy a deployable to a running container.   cargo:deployer-undeploy(aliased to cargo:undeploy) Undeploy a deployable from a running container.   cargo:deployer-start Start a deployable already installed in a running container.   cargo:deployer-stop Stop a deployed deployable without undeploying it.   cargo:deployer-redeploy(aliased to cargo:redeploy) Undeploy and deploy again a deployable. If the deployable was not deployed before calling cargo:deployer-redeploy (or its alias cargo:redeploy) it will simply be deployed.   cargo:uberwar Stop a deployed deployable without undeploying it.   cargo:deployer-stop Merge several WAR files into one.   cargo:install Installs a container distribution on the file system. Note that the cargo:start goal will also install the container automatically (but will not call cargo:install).   cargo:help Get help (list of available goals, available options, etc.).    仓库 本地仓库 远程仓库  私服: 搭建在局域网环境中，为局域网范围内的所有Maven工程服务 中央仓库: 架设在Internet上，为全世界所有Maven工程服务 中央仓库镜像: 架设在各大洲，为中央仓库分担流量。减轻中央仓库的压力，同时更快的响应用户请求  setting.xml配置文件 配置maven的本地仓库目录 localRepository标签\n设置默认jdk版本 \u0026lt;profiles\u0026gt; \u0026lt;profile\u0026gt; \u0026lt;id\u0026gt;jdk-1.8\u0026lt;/id\u0026gt; \u0026lt;activation\u0026gt; \u0026lt;activeByDefault\u0026gt;true\u0026lt;/activeByDefault\u0026gt; \u0026lt;jdk\u0026gt;1.8\u0026lt;/jdk\u0026gt; \u0026lt;/activation\u0026gt; \u0026lt;properties\u0026gt; \u0026lt;maven.compiler.source\u0026gt;1.8\u0026lt;/maven.compiler.source\u0026gt; \u0026lt;maven.compiler.target\u0026gt;1.8\u0026lt;/maven.compiler.target\u0026gt; \u0026lt;maven.compiler.compilerVersion\u0026gt;1.8\u0026lt;/maven.compiler.compilerVersion\u0026gt; \u0026lt;/properties\u0026gt; \u0026lt;/profile\u0026gt; \u0026lt;/profiles\u0026gt;  ","date":1490924537,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1490924537,"objectID":"55cfc5efc5461131898bf1da30deadab","permalink":"https://moyada.github.io/post/maven/","publishdate":"2017-03-31T01:42:17Z","relpermalink":"/post/maven/","section":"post","summary":"pom配置文件 命令 mvn clean: 清除target目录 mvn compile: 编译主程序 mvn test-compile:","tags":[],"title":"Maven 基本操作","type":"post"},{"authors":null,"categories":null,"content":"注释  两个减号是单行注释:\n-- 注释内容   多行注释:\n--[[ 注释内容 注释内容 --]]  数据类型 Lua是动态类型语言，变量不要类型定义,只需要为变量赋值。值可以存储在变量中，作为参数传递或结果返回。\nnil 这个最简单，只有值nil属于该类，表示一个无效值（在条件表达式中相当于false）。\nboolean 包含两个值：false和true。\nnumber 表示双精度类型的实浮点数\nstring 字符串由一对双引号或单引号或[[和]]间的一串字符来表示\nfunction 由 C 或 Lua 编写的函数\nuserdata 表示任意存储在变量中的C数据结构\nthread 表示执行的独立线路，用于执行协同程序\ntable Lua 中的表（table）其实是一个\u0026quot;关联数组\u0026rdquo;（associative arrays），数组的索引可以是数字或者是字符串。在 Lua 里，table 的创建是通过\u0026quot;构造表达式\u0026quot;来完成，最简单构造表达式是{}，用来创建一个空表。 对 table 的索引使用方括号 []。Lua 也提供了 . 操作。\nt[i] t.i -- 当索引为字符串类型时的一种简化写法 gettable_event(t,i) -- 采用索引访问本质上是一个类似这样的函数调用 site[\u0026quot;key\u0026quot;] = \u0026quot;www.w3cschool.cc\u0026quot; print(site[\u0026quot;key\u0026quot;]) print(site.key)  变量 Lua 变量有三种类型：全局变量、局部变量、表中的域。Lua 中的变量全是全局变量，那怕是语句块或是函数里，除非用 local 显式声明为局部变量。\n赋值 多个变量赋值 在对多个变量同时赋值，变量列表和值列表的各个元素用逗号分开，赋值语句右边的值会依次赋给左边的变量。\na, b = 10, 20   遇到赋值语句Lua会先计算右边所有的值然后再执行赋值操作，所以我们可以这样进行交换变量的值： ``` x, y = y, x -- swap 'x' for 'y' a[i], a[j] = a[j], a[i] -- swap 'a[i]' for 'a[j]' ```  当变量个数和值的个数不一致时，Lua会一直以变量个数为基础采取以下策略： a. 变量个数  值的个数 按变量个数补足nil b. 变量个数 0 1 nil a, b = a+1, b+1, b+2 \u0026ndash; value of b+2 is ignored print(a,b) \u0026ndash;\u0026gt; 1 2\na, b, c = 0 print(a,b,c) \u0026ndash;\u0026gt; 0 nil nil\n# 循环 ## while  while(condition) do statements end\n ## for  for var=exp1,exp2,exp3 do\n\u0026lt;执行体\u0026gt;\nend\nexp1为循环初始值。 exp2为循环中止条件。 exp3为步长递增，如果不指定则默认为1。 三个表达式在循环开始前一次性求值，以后不再进行求值。例如这些表达式都为函数的情况。 Lua有种类似java中的foreach语句，泛型for循环通过一个迭代器函数来遍历所有值。  for i,v in ipairs(a) \u0026ndash; i为元素的下表,v为元素的值,ipairs是Lua提供的一个迭代器函数，用来迭代数组。 do print(v) end\n ## repeat...until  repeat statements until( condition )\n在条件进行判断前循环体都会执行一次。 如果条件判断语句（condition）为 false，循环会重新开始执行，直到条件判断语句（condition）为 true 才会停止执行。 # 流程控制 ## if  if(布尔表达式) then \u0026ndash;[ 在布尔表达式为 true 时执行的语句 \u0026ndash;] end\nLua认为false和nil为假，true 和非nil为真。要注意的是Lua中 0 为 true。 ## if...else  if(布尔表达式) then \u0026ndash;[ 布尔表达式为 true 时执行该语句块 \u0026ndash;] else \u0026ndash;[ 布尔表达式为 false 时执行该语句块 \u0026ndash;] end\n ## if...elseif...else  if( 布尔表达式 1) then \u0026ndash;[ 在布尔表达式 1 为 true 时执行该语句块 \u0026ndash;]\nelseif( 布尔表达式 2) then \u0026ndash;[ 在布尔表达式 2 为 true 时执行该语句块 \u0026ndash;]\nelseif( 布尔表达式 3) then \u0026ndash;[ 在布尔表达式 3 为 true 时执行该语句块 \u0026ndash;] else \u0026ndash;[ 如果以上布尔表达式都不为 true 则执行该语句块 \u0026ndash;] end\n # 函数 Lua 编程语言函数定义格式如下：  optional_function_scope function function_name( argument1, argument2, argument3\u0026hellip;, argumentn) function_body return result_params_comma_separated end\n* optional_function_scope: 该参数是可选的制定函数是全局函数还是局部函数，未设置该参数默认为全局函数，如果你需要设置函数为局部函数需要使用关键字 local。 * argument1, argument2, argument3..., argumentn: 函数参数，多个参数以逗号隔开，函数也可以不带参数。 * result_params_comma_separated: 函数返回值，Lua语言函数可以返回多个值，每个值以逗号隔开。 ## 可变参数 Lua函数可以接受可变数目的参数，和C语言类似在函数参数列表中使用三点（...) 表示函数有可变的参数。 Lua将函数的参数放在一个叫arg的表中，#arg 表示传入参数的个数。  function average(\u0026hellip;) result = 0 local arg={\u0026hellip;} for i,v in ipairs(arg) do result = result + v end print(\u0026ldquo;总共传入 \u0026quot; .. #arg .. \u0026quot; 个数\u0026rdquo;) return result/#arg end\nprint(\u0026ldquo;平均值为\u0026rdquo;,average(10,5,3,4,5,6))\n # 字符串操作 * .. 连接两个字符串 * ＃ 一元运算符，返回字符串或表的长度。 # 模块 模块是由变量、函数等已知元素组成的 table，类似java的类。  \u0026ndash; 文件名为 module.lua \u0026ndash; 定义一个名为 module 的模块 module = {}\n\u0026ndash; 定义一个常量 module.constant = \u0026ldquo;这是一个常量\u0026rdquo;\n\u0026ndash; 定义一个函数 function module.func1() io.write(\u0026ldquo;这是一个公有函数！\\n\u0026rdquo;) end\nlocal function func2() print(\u0026ldquo;这是一个私有函数！\u0026quot;) end\nfunction module.func3() func2() end\nreturn module\n \u0026lt;br/\u0026gt; Lua提供了一个名为require的函数用来加载模块:  require(\u0026ldquo;\u0026lt;模块名\u0026gt;\u0026rdquo;) 或者 require \u0026ldquo;\u0026lt;模块名\u0026gt;\u0026rdquo;\n还给加载的模块定义一个别名变量，方便调用: local m = require(\u0026quot;module\u0026quot;) ## 加载机制 对于自定义的模块，模块文件不是放在哪个文件目录都行，函数 require 有它自己的文件路径加载策略，它会尝试从 Lua 文件或 C 程序库中加载模块。 当 Lua 启动后，会以环境变量 LUA_PATH 的值来初始环境变量用户加载模块。  ","date":1490716267,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1490716267,"objectID":"f0ca89a8ce27b97e15da2afb7ada491b","permalink":"https://moyada.github.io/bak/lua/","publishdate":"2017-03-28T15:51:07Z","relpermalink":"/bak/lua/","section":"bak","summary":"注释 两个减号是单行注释: -- 注释内容 多行注释: --[[ 注释内容 注释内","tags":null,"title":"Lua学习笔记","type":"bak"},{"authors":[],"categories":[],"content":"分表方法 在数据库表使用过程中，为了减小数据库服务器的负担、缩短查询时间，常常会考虑做分表设计。分表分两种，一种是纵向分表（将本来可以在同一个表的内容，人为划分存储在为多个不同结构的表）和横向分表（把大的表结构，横向切割为同样结构的不同表）。\n其中，纵向分表常见的方式有根据活跃度分表、根据重要性分表等。其主要解决问题如下：\n表与表之间资源争用问题； 锁争用机率小； 实现核心与非核心的分级存储，如UDB登陆库拆分成一级二级三级库； 解决了数据库同步压力问题。 横向分表是指根据某些特定的规则来划分大数据量表，如根据时间分表。其主要解决问题如下：\n单表过大造成的性能问题； 单表过大造成的单服务器空间问题。\n设计  使用明确、统一的标明和列名，例如 School, SchoolCourse, CourceID。 数据表名使用单数而不是复数，例如 StudentCourse，而不是StudentCourses。 数据表名不要使用空格。 数据表名不要使用不必要的前缀或者后缀，例如使用School，而不是TblSchool，或者SchoolTable等等。 数据库中的密码要加密，到应用中再解密。 （其实就是散列存储、单向加密） 使用整数作为ID字段，也许现在没有这个必要，但是将来需要，例如关联表，索引等等。 使用整数字段做索引，否则会带来很大的性能问题 。 使用 bit 作为布尔字段，使用整数或者varcha是浪费。同时，这类字段应该以“Is”开头。 要经过认证才能访问数据库，不要给每一个用户管理员权限。 尽量避免使用“select *”，而使用“select [required_column_list]”以获得更好的性能。 假如程序代码比较复杂，使用ORM框架，例如hibernate，iBatis。ORM框架的性能问题可以通过详细的配置去解决。 分割不常使用的数据表到不同的物理存储以获得更好的性能。 对于关键数据库，使用安全备份系统，例如集群，同步等等。 使用外键，非空等限制来保证数据的完整性，不要把所有的东西都扔给程序。 缺乏数据库文档是致命的。你应该为你的数据库设计写文档，包括触发器、存储过程和其他脚本。 对于经常使用的查询和大型数据表，要使用索引。数据分析工具可以帮助你决定如何建立索引。 数据库服务器和网页服务器应该放在不同的机器上。这回提高安全性，并减轻CPU压力。 Image和blob字段不应该定义在常用的数据表中，否则会影响性能。 范式（Normalization）要按照要求使用以提高性能。Normalization做的不够会导致数据冗余，而过度Normalization 会导致太多的join和数据表，这两种情况都会影响性能。 多花点时间在数据库设计上，否则你将来会付出加倍的时间来偿还。  索引 少建索引或不建索引。这个问题最突出，建议建表时 DBA 可以一起协助把关。 索引滥用。滥用索引将导致写请求变慢，拖慢整体数据库的响应速度（5.5 以下的 mysql 只能用到一个索引)。 从不考虑联合索引。实际上联合索引的效率往往要比单列索引的效率更高。 非最优列选择。低选择性的字段不适合建单列索引，如 status 类型的字段。\n优化 字段类型转换导致不用索引，如字符串类型的不用引号，数字类型的用引号等，这有可能会用不到索引导致全表扫描； mysql 不支持函数转换，所以字段前面不能加函数，否则这将用不到索引； 不要在字段前面加减运算； 字符串比较长的可以考虑索引一部份减少索引文件大小，提高写入效率； like % 在前面用不到索引； 根据联合索引的第二个及以后的字段单独查询用不到索引； 不要使用 select *； 排序请尽量使用升序 ; or 的查询尽量用 union 代替 （Innodb）； 复合索引高选择性的字段排在前面； order by / group by 字段包括在索引当中减少排序，效率会更高。 除了上述索引使用规则外，SQL 编写时还需要特别注意一下几点：\n尽量规避大事务的 SQL，大事务的 SQL 会影响数据库的并发性能及主从同步； 分页语句 limit 的问题； 删除表所有记录请用 truncate，不要用 delete； 不让 mysql 干多余的事情，如计算； 输写 SQL 带字段，以防止后面表变更带来的问题，性能也是比较优的 ( 涉及到数据字典解析，请自行查询资料)； 在 Innodb上用 select count(*)，因为 Innodb 会存储统计信息； 慎用 Oder by rand()。\n分析诊断工具 mysqldumpslow mysql profile mysql explain\n","date":1489688195,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1489688195,"objectID":"752da6cd5076d21ff11b1c3181377a15","permalink":"https://moyada.github.io/bak/database-design/","publishdate":"2017-03-16T18:16:35Z","relpermalink":"/bak/database-design/","section":"bak","summary":"分表方法 在数据库表使用过程中，为了减小数据库服务器的负担、缩","tags":[],"title":"数据库设计","type":"bak"},{"authors":null,"categories":null,"content":"数据类型    数据类型 描述     Byte 8位有符号补码整数   Short 16位有符号补码整数   Int 32位有符号补码整数   Long 64位有符号补码整数   Float 32位IEEE754单精度浮点数   Double 64位IEEE754单精度浮点数   Char 16位无符号Unicode字符, 区间值为 U+0000 到 U+FFFF   String 字符序列   Boolean true或false   Unit 表示无值，和其他语言中void等同。   Null null 或空引用   Nothing Nothing类型在Scala的类层级的最低端；它是任何其他类型的子类型。   Any Any是所有其他类的超类   AnyRef AnyRef类是Scala里所有引用类(reference class)的基类    scala中变量类型可由编译器的类型推断来确定，也可以显示声明数据类型，如下形式即可\nval str : String = null  在scala中有一种特殊的数据类型Unit，代表任意类型，也等价于Java中的void，以如下形式声明\nvar any = () any = 1 any = \u0026quot;any\u0026quot;  var与val的区别 var用作声明可变变量，val用作声明不可变变量\nfor 循环 for( var x \u0026lt;- Range ){ statement(s); }  Range 可以是一个数字区间表示 i to j ，或者 i until j。左箭头 \u0026lt;- 用于为变量 x 赋值。 i to j　的循环区间为[i,j]，而i until j 的循环区间为[i,j)。\n嵌套循环在 for 循环 中可以使用分号 (;) 来设置多个区间，它将迭代给定区间所有的可能值。\nfor( var x \u0026lt;- Range; var y \u0026lt;- Range ){ statement(s); }  循环集合 for( var x \u0026lt;- List ){ statement(s); }  循环过滤 for( var x \u0026lt;- List if condition1; if condition2...) { statement(s); }  存储返回值变量  var retVal = for{ a \u0026lt;- numList if a != 3; if a \u0026lt; 8 }yield a  break语句 // 导入以下包 import scala.util.control._ // 创建 Breaks 对象 val loop = new Breaks; // 在 breakable 中循环 loop.breakable{ // 循环 for(...){ .... // 循环中断 loop.break; } }  函数 函数定义格式如下：\ndef functionName ([参数列表]) : [return type] = { function body return [expr] }  方法定义由一个def 关键字开始，紧接着是可选的参数列表，一个冒号\u0026rdquo;：\u0026rdquo; 和方法的返回类型，一个等于号\u0026quot;=\u0026rdquo;，最后是方法的主体。\n可变参数: 函数的最后一个参数可以是重复的，参数类型后面以*设置 默认参数值: 参数后跟 =参数值 可以设置默认参数值 Scala的解释器在解析函数参数(function arguments)时有两种方式：\n 传值调用（call-by-value）：先计算参数表达式的值，再应用到函数内部 传名调用（call-by-name）：将未计算的参数表达式直接应用到函数内部 在进入函数内部前，传值调用方式就已经将参数表达式的值计算完毕，而传名调用是在函数内部进行参数表达式的值计算的。 这就造成了一种现象，每次使用传名调用时，解释器都会计算一次表达式的值。  object Test { def main(args: Array[String]) { delayed(time()); } def time() = { println(\u0026quot;获取时间，单位为纳秒\u0026quot;) System.nanoTime } def delayed( t: =\u0026gt; Long ) = { println(\u0026quot;在 delayed 方法内\u0026quot;) println(\u0026quot;参数： \u0026quot; + t) t } } \\\\ 输出 \\\\ 在 delayed 方法内 \\\\ 获取时间，单位为纳秒 \\\\ 参数： 241550840475831 \\\\ 获取时间，单位为纳秒  高阶函数 高阶函数可以使用其他函数作为参数，或者使用函数作为输出结果。\nobject Test { def main(args: Array[String]) { println( apply( layout, 10) ) } // 函数 f 和 值 v 作为参数，而函数 f 又调用了参数 v def apply(f: Int =\u0026gt; String, v: Int) = f(v) def layout[A](x: A) = \u0026quot;[\u0026quot; + x.toString() + \u0026quot;]\u0026quot; }  匿名函数 定义匿名函数的语法很简单，箭头左边是参数列表，右边是函数体。\ndef add2 = new Function1[Int,Int]{ def apply(x:Int):Int = x+1; // 简写： var inc = (x:Int) =\u0026gt; x+1 }  不给匿名函数设置参数则参数列表为()\n偏应用函数 使用偏应用函数绑定第一个 date 参数，第二个参数使用下划线(_)替换缺失的参数列表，并把这个新的函数值的索引的赋给变量。\ndef main(args: Array[String]) { val date = new Date val logWithDateBound = log(date, _ : String) logWithDateBound(\u0026quot;message1\u0026quot; ) Thread.sleep(1000) logWithDateBound(\u0026quot;message2\u0026quot; ) Thread.sleep(1000) logWithDateBound(\u0026quot;message3\u0026quot; ) } def log(date: Date, message: String) = { println(date + \u0026quot;----\u0026quot; + message) }  函数柯里化(Currying) 柯里化(Currying)指的是将原来接受两个参数的函数变成新的接受一个参数的函数的过程。新的函数返回一个以原有第二个参数为参数的函数。\n// 接收一个x为参数，返回一个匿名函数，该匿名函数的定义是：接收一个Int型参数y，函数体为x+y。 def add(x:Int)=(y:Int)=\u0026gt;x+y // 接收两个个String型参数s1, s2，返回一个匿名函数，函数体为s1 + s2。 def strcat(s1: String)(s2: String) = { s1 + s2 }  类和对象 类(class)是抽象的，不占用内存，而对象(object)是具体的，占用存储空间。\n继承  重写一个非抽象方法必须使用override修饰符。 只有主构造函数才可以往父类的构造函数里写参数。 在子类中重写父类的抽象方法时，你不需要使用override关键字。  单例对象 使用单例模式时，除了定义的类之外，还要定义一个同名的 object 对象，它和类的区别是，object对象不能带参数。\nTrait(特征) 类似于Java的抽象类，除了定义未实现的方法外，还可以定义属性和方法的实现， 并且可以多继承，使用的关键字是 trait。\n特征构造顺序  调用超类的构造器； 特征构造器在超类构造器之后、类构造器之前执行； 特质由左到右被构造； 每个特征当中，父特质先被构造； 如果多个特征共有一个父特质，父特质不会被重复构造 所有特征被构造完毕，子类被构造。  模式匹配 x match { case 1 =\u0026gt; \u0026quot;one\u0026quot; case 2 =\u0026gt; \u0026quot;two\u0026quot; case y: Int =\u0026gt; \u0026quot;int\u0026quot; case _ =\u0026gt; \u0026quot;many\u0026quot; }  match 对应 Java 里的 switch，但是写在选择器表达式之后。即： 选择器 match {备选项}。 只要发现有一个匹配的case，剩下的case不会继续匹配。\n样例类 使用了case关键字的类定义就是就是样例类(case classes)，样例类是种特殊的类，经过优化以用于模式匹配。\nobject Test { def main(args: Array[String]) { val alice = new Person(\u0026quot;Alice\u0026quot;, 25) val bob = new Person(\u0026quot;Bob\u0026quot;, 32) val charlie = new Person(\u0026quot;Charlie\u0026quot;, 32) for (person \u0026lt;- List(alice, bob, charlie)) { person match { case Person(\u0026quot;Alice\u0026quot;, 25) =\u0026gt; println(\u0026quot;Hi Alice!\u0026quot;) case Person(\u0026quot;Bob\u0026quot;, 32) =\u0026gt; println(\u0026quot;Hi Bob!\u0026quot;) case Person(name, age) =\u0026gt; println(\u0026quot;Age: \u0026quot; + age + \u0026quot; year, name: \u0026quot; + name + \u0026quot;?\u0026quot;) } } } // 样例类 case class Person(name: String, age: Int) }  在声明样例类时，下面的过程自动发生了：\n 构造器的每个参数都成为val，除非显式被声明为var，但是并不推荐这么做； 在伴生对象中提供了apply方法，所以可以不使用new关键字就可构建对象； 提供unapply方法使模式匹配可以工作； 生成toString、equals、hashCode和copy方法，除非显示给出这些方法的定义。  文件 I/O Scala 进行文件写操作，直接用的都是 java中 的 I/O 类 （java.io.File)：\nval writer = new PrintWriter(new File(\u0026quot;test.txt\u0026quot; )) writer.write(\u0026quot;菜鸟教程\u0026quot;) writer.close()  从屏幕上读取用户输入 val line = Console.readLine  从文件上读取内容 Source.fromFile(\u0026quot;test.txt\u0026quot; ).foreach{ print }  异常处理 捕获异常 try { val f = new FileReader(\u0026quot;input.txt\u0026quot;) } catch { case ex: FileNotFoundException =\u0026gt; { println(\u0026quot;Missing file exception\u0026quot;) } case ex: IOException =\u0026gt; { println(\u0026quot;IO Exception\u0026quot;) } } finally { println(\u0026quot;Exiting finally...\u0026quot;) }  抛出异常 throw new IllegalArgumentException  提取器(Extractor) 提取器是从传递给它的对象中提取出构造该对象的参数。\nScala 提取器是一个带有unapply方法的对象。unapply方法算是apply方法的反向操作：unapply接受一个对象，然后从对象中提取值，提取的值通常是用来构造该对象的值。\n提取器使用模式匹配 在我们实例化一个类的时，可以带上0个或者多个的参数，编译器在实例化的时会调用 apply 方法。我们可以在类和对象中都定义 apply 方法。 就像我们之前提到过的，unapply 用于提取我们指定查找的值，它与 apply 的操作相反。 当我们在提取器对象中使用 match 语句是，unapply 将自动执行。\n","date":1488447193,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1488447193,"objectID":"7f4205a7ebae3f3f3dde3a50e35e40cd","permalink":"https://moyada.github.io/bak/scala/","publishdate":"2017-03-02T09:33:13Z","relpermalink":"/bak/scala/","section":"bak","summary":"数据类型 数据类型 描述 Byte 8位有符号补码整数 Short 16位有符号补码整","tags":null,"title":"scala学习笔记","type":"bak"},{"authors":[],"categories":["Git"],"content":"设置基本配置  让Git显示颜色，会让命令输出看起来更醒目：  $ git config \\-\\-global color.ui true   设置全局用户信息  $ git config \\-\\-global user.name \u0026quot;Your Name\u0026quot; $ git config \\-\\-global user.email \u0026quot;email@example.com\u0026quot;   记录用户密码  git config credential.helper store ## 设置过期时间 git config credential.helper 'cache \\-\\-timeout=3600'   增加删除信息  $ git config \\-\\-list \\-\\-global $ git config \\-\\-global \\-\\-add user.name xyk $ git config \\-\\-get user.name $ git config \\-\\-global \\-\\-unset user.name xyk   设置命令别名  设置checkout别名为co $ git config \\-\\-global alias.co checkout 设置stash别名为sh $ git config \\-\\-global alias.co checkout  简单使用  初始化一个Git仓库，可以使用$ git init命令。 或者$ git clone [-b branch_name] \u0026ldquo;repository_url\u0026rdquo; 从远程仓库拉取 添加文件到Git仓库，分两步： 第一步，使用命令$ git add  添加文件到暂存区里。 第二步，使用命令$ git commit [-a] -m \u0026ldquo;message\u0026rdquo;，将暂存区的文件提交到本地仓库里。 要随时掌握工作区的状态，使用git status命令。 如果$ git status告诉你有文件被修改过，用$ git diff可以查看修改内容。 如果需要丢弃未暂存的文件，可以使用$ git checkout [--]  丢弃工作区的文件 如果需要丢弃已暂存的文件，可以使用$ git reset [HEAD]  丢弃暂存区的文件 移除文件: $ git rm --cached  移动重命名文件: $ git mv  \u0026lt;new_file\u0026gt; 将暂存区的文件添加到本地仓库里的最后一次提交: $ git commit --amend $ git push origin \u0026lt;branch_name\u0026gt; 提交到远程仓库 如果本地仓库与远程仓库不属于同一祖先的话，先git pull \u0026lt;remote_name\u0026gt;  --allow-unrelated-histories 同步分支后在提交  忽略文件 如果有不需要参与提交的文件，可以创建文件.gitignore，以正则表达式的形式，将不需要的文件表达加入进去:\n   表达式 描述     *~ 将vim中间文件，排除git管理   *.class 将以class结尾的文件，排除git管理   *.[ab] 将以a或b结尾的文件，排除git管理   target/ 将第一级的target文件夹，排除git管理   **/log 将所有的log文件夹，排除git管理   !git.class 将git.class文件纳入到git管理    分支 查看分支：$ git branch 创建分支：$ git branch \u0026lt;branch_name\u0026gt; 创建远端分支: $ git checkout -b \u0026lt;branch_name\u0026gt; origin/\u0026lt;branch_name\u0026gt; 或 git fetch origin \u0026lt;branch_name\u0026gt;:\u0026lt;branch_name\u0026gt; 建立远端映射关系: $ git branch -u origin/\u0026lt;branch_name\u0026gt; 切换分支：$ git checkout \u0026lt;branch_name\u0026gt; 创建+切换分支：$ git checkout -b \u0026lt;branch_name\u0026gt; 删除分支：$ git branch -d \u0026lt;branch_name\u0026gt; 删除远端分支: $ git branch -r -d origin/\u0026lt;branch_name\u0026gt;, git push origin :\u0026lt;branch_name\u0026gt;  如果要丢弃一个没有被合并过的分支，可以通过$ git branch -D \u0026lt;branch_name\u0026gt;强行删除。\n贮藏工作现场 Git提供了一个stash功能，可以把当前工作现场“储藏”起来，等以后恢复现场后继续工作：\n$ git stash save [-a \u0026quot;stash_name\u0026quot;]  用$ git stash list命令可以查看所有工作现场。 恢复有两个办法：\n 一是用$ git stash apply恢复，但是恢复后，stash内容并不删除，你需要用$ git stash drop \u0026lt;stash_name\u0026gt;来删除； 另一种方式是用$ git stash pop，恢复的同时把stash内容也删了。 当想要一次性清理全部stash时，可以通过命令$ git stash clear来完成。  标签 标签可以用于给分支打上多个tag，作为版本的标明 从版本tag上新建分支bug分支，用于修复历史版本存在bug。\n 在Git中打标签非常简单，首先，切换到需要打标签的分支上，然后通过命令  $ git tag [tagname]  新建一个标签，默认为HEAD，也可以指定一个tag name。\n 要对历史提交打标签，则需要在后面添加对应的commit id，敲入命令：  $ git tag \u0026lt;tagname\u0026gt; \u0026lt;commit_id\u0026gt;   还可以创建带有说明的标签，用-a指定标签名，-m指定说明文字：  $ git tag -a \u0026lt;tagname\u0026gt; -m \u0026quot;version 0.1 released\u0026quot; 3628164   还可以通过-s用私钥签名一个标签： $ git tag -s  -m \u0026ldquo;signed version 0.2 released\u0026rdquo; fec145a 签名采用PGP签名，因此，必须首先安装gpg（GnuPG），如果没有找到gpg，或者没有gpg密钥对，就会报错  查看所有标签可以用命令: $ git tag\n查看标签信息可以用: $ git show \n命令$ git push origin 可以推送一个本地标签； 命令$ git push origin --tags可以推送全部未推送过的本地标签； 命令$ git tag -d 可以删除一个本地标签； 命令$ git push origin :refs/tags/可以删除一个远程标签。\n合并 在需要合并某分支到当前分支时:\n$ git merge \u0026lt;branch_name\u0026gt;  当Git无法自动合并分支时，就必须首先解决冲突。解决冲突后，再提交，合并完成。 如果想放弃此次合并的话，可以使用命令:\n$ git merge \\-\\-abort  当合并的分支衍生处在一条分支上时，Git会用Fast forward模式。 如果要强制禁用Fast forward模式，Git就会在merge时生成一个新的commit，这样，从分支历史上就可以看出分支信息。\n使用--no-ff参数，可以禁用Fast forward：\n$ git merge \\-\\-no-ff -m \u0026quot;merge with no-ff\u0026quot; \u0026lt;branch_name\u0026gt;  用$ git log --graph命令可以看到分支合并图。 用带参数的git log也可以看到分支的合并情况：\n$ git log \\-\\-graph \\-\\-oneline \\-\\-abbrev-commit  版本操作 查看历史  查看所有分支的历史示意图:  $ git log \\-\\-oneline \\-\\-stat \\-\\-decorate \\-\\-graph \\-\\-all -p   查看工作区与历史提交之间的差异  $ git diff   查看暂存区与历史提交之间的差异  $ git diff \\-\\-cached   查看工作区与历史提交之间的差异  $ git diff \u0026lt;commit_id\u0026gt;   查看暂存区与历史提交之间的差异  $ git diff \\-\\-cached \u0026lt;commit_id\u0026gt;   查看历史提交之间的差异  $ git diff \u0026lt;commit_id\u0026gt; \u0026lt;commit_id\u0026gt;   查看工作区与历史提交的某个文件的单词差异  $ git diff \\-\\-color-words [\\-\\-] \u0026lt;file\u0026gt; $ git diff \\-\\-word-diff [\\-\\-] \u0026lt;file\u0026gt;  撤销操作  恢复暂存区某个文件的某个历史版本  $ git checkout \u0026lt;commit_id\u0026gt; [\\-\\-] \u0026lt;file\u0026gt;   恢复工作区某个文件的某个历史版本  $ git reset \u0026lt;commit_id\u0026gt; [\\-\\-] \u0026lt;file\u0026gt;  --- 清除操作: $ git clean -n 查看准备移除工作区文件 -x 移除忽略文件内的表达式的文件 -X 移除忽略文件内的表达式的文件及工作区文件 -f 执行移除工作区文件\n--- 移除某次提交的内容:\n$ git revert \u0026lt;commit_id\u0026gt;  修改历史 替换最后一次提及 $ git commit --amend\n将当前分支设置为另一分支的衍生分支 $ git rebase \u0026lt;branch_name\u0026gt;\n要重返历史版本，可以用$ git reflog查看历史操作，以便确定要回到哪个版本。 版本回退:\nHEAD指向的版本就是当前版本，Git允许我们在版本的历史之间穿梭， ~和^均可代表向上一个版本 $ git reset \\-\\-hard HEAD~ ## 回到上一个版本； $ git reset \\-\\-hard HEAD^^ ## 回到上两个版本； $ git reset \\-\\-hard \u0026lt;commit_tag\u0026gt; ## 回退到指定版本。  --hard 使用某次提交的内容还原暂存区和工作区 --mixed 只使用某次提交的内容还原暂存区，并把HEAD和分支引用指向指定的commit --soft 只把HEAD和分支引用指向指定的commit\n远程仓库 创建SSH Key 生成ssh密钥\n$ ssh-keygen -t rsa -C \u0026quot;youremail@example.com\u0026quot;  保存ssh密钥\n$ eval \u0026quot;$(ssh-agent -s)\u0026quot; $ ssh-add ~/.ssh/id_rsa  登陆GitHub，打开“Account settings”，“SSH Keys”页面 点“Add SSH Key”，填上任意Title，在Key文本框里粘贴id_rsa.pub文件的内容 验证ssh密钥\n$ ssh -T git@github.com Hi xueyikang! You've successfully authenticated, but GitHub does not provide shell access.  远程协作 从远程库克隆 可以用命令git clone克隆一个本地库： $ git clone \u0026lt;http_url | ssh_url\u0026gt; 或者建立本地仓库与远程仓库的联系 $ git remote add \u0026lt;origin | else_name\u0026gt; \u0026lt;http_url | ssh_url\u0026gt;\n查看所有远程库的配置信息： $ git remote -v\n查看远程库的更详细的信息: $ git remote shop \u0026lt;branch_name\u0026gt;\n重命名远程仓库 $ git remote rename \u0026lt;origin_name\u0026gt; \u0026lt;else_name\u0026gt;\n删除远程仓库 $ git remote rm \u0026lt;origin_name\u0026gt;\n远程库协作 没有关联关系的话需要先要使用命令创建本地分支与远程origin的链接关系： $ git checkout -b \u0026lt;local_branch_name\u0026gt; origin \u0026lt;remote_branch_name\u0026gt;\n把本地库的所有内容推送到远程库上： $ git push [-u] origin \u0026lt;branch_name\u0026gt; 我们第一次推送新分支时，加上了-u参数，Git不但会把本地分支内容推送的远程新分支，还会把本地分支和远程分支关联起来，在以后的推送或者拉取时就可以简化命令。\n获取远程分支的最新代码到本地的远程分支上: $ git fetch [origin [branch_name]\n获取远程分支的最新代码到本地的远程分支上并与本地分支合并: $ git pull [origin [branch_name] 如果提示“no tracking information”，则说明本地分支和远程分支的链接关系没有创建， 用命令建立:$ git branch --set-upstream \u0026lt;local_branch_name\u0026gt; origin \u0026lt;remote_branch_name\u0026gt;。\n如果是是两个不同的项目，则需要先 git pull --allow-unrelated-histories\n删除远程分支\n$ git push \\-\\-delete origin \u0026lt;branch_name\u0026gt; 或者 $ git push origin :\u0026lt;branch_name\u0026gt;  搭建Git服务器   安装git： $ sudo apt-get install git\n  创建一个git用户，用来运行git服务： $ sudo adduser git\n  创建证书登录： 收集所有需要登录的用户的公钥，就是他们自己的id_rsa.pub文件，把所有公钥导入到/home/git/.ssh/authorized_keys文件里，一行一个。\n  初始化Git仓库： 先选定一个目录作为Git仓库，假定是/srv/sample.git，在/srv目录下输入命令： $ sudo git init --bare sample.git Git就会创建一个裸仓库，裸仓库没有工作区，因为服务器上的Git仓库纯粹是为了共享，所以不让用户直接登录到服务器上去改工作区，并且服务器上的Git仓库通常都以.git结尾。然后，把owner改为git： $ sudo chown -R git:git sample.git\n  禁用shell登录： 出于安全考虑，第二步创建的git用户不允许登录shell，这可以通过编辑/etc/passwd文件完成。找到类似下面的一行： git❌1001:1001:,,,:/home/git:/bin/bash 改为： git❌1001:1001:,,,:/home/git:/usr/bin/git-shell 这样，git用户可以正常通过ssh使用git，但无法登录shell，因为我们为git用户指定的git-shell每次一登录就自动退出。\n  克隆远程仓库： 现在，可以通过git clone命令克隆远程仓库了，在各自的电脑上运行： $ git clone git@server:/srv/sample.gitCloning into \u0026lsquo;sample\u0026rsquo;\u0026hellip;warning: You appear to have cloned an empty repository. 剩下的推送就简单了。\n  管理公钥 如果团队很小，把每个人的公钥收集起来放到服务器的/home/git/.ssh/authorized_keys文件里就是可行的。如果团队有几百号人，就没法这么玩了，这时，可以用Gitosis来管理公钥。 这里我们不介绍怎么玩Gitosis了，几百号人的团队基本都在500强了，相信找个高水平的Linux管理员问题不大。 管理权限 有很多不但视源代码如生命，而且视员工为窃贼的公司，会在版本控制系统里设置一套完善的权限控制，每个人是否有读写权限会精确到每个分支甚至每个目录下。因为Git是为Linux源代码托管而开发的，所以Git也继承了开源社区的精神，不支持权限控制。不过，因为Git支持钩子（hook），所以，可以在服务器端编写一系列脚本来控制提交等操作，达到权限控制的目的。Gitolite就是这个工具。 这里我们也不介绍Gitolite了，不要把有限的生命浪费到权限斗争中。\n https://mux.alimama.com/posts/711\n ","date":1488027190,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1488027190,"objectID":"a64b1b7c7f27ecc7e81c833938a437c9","permalink":"https://moyada.github.io/post/git/","publishdate":"2017-02-25T12:53:10Z","relpermalink":"/post/git/","section":"post","summary":"设置基本配置 让Git显示颜色，会让命令输出看起来更醒目： $ git","tags":[],"title":"Git的基本操作","type":"post"},{"authors":[],"categories":[],"content":"博客   计算机书籍控  开源文档  程序猿DD - Spring Boot教程与Spring Cloud教程  老高的技术博客  阿里中间件团队博客  ELK 大数据  猿天地  Java工程师成神之路 http://blog.csdn.net/dengsilinming/article/list/1   分布式 Hystrix  https://my.oschina.net/yangshaokai/blog/674685  Spring Cloud与Dubbo  http://blog.csdn.net/kobejayandy/article/details/52078275  Zabbix  https://www.zhihu.com/question/19973178  微服务  https://www.ibm.com/developerworks/cn/java/j-cn-java-and-microservice-1st/index.html?cm_mmc=dwchina-_-homepage-_-social-_-weibo  redis分布式锁  http://www.cnblogs.com/0201zcr/p/5942748.html  zkclient,curator使用  http://blueyan.iteye.com/blog/2298276  最终一致性  http://blog.csdn.net/xiaoqiangxx/article/details/7566654  日志分析  http://blog.csdn.net/changdazhong/article/details/52536186 http://blog.csdn.net/cnbird2008/article/details/39901087 http://www.cnblogs.com/smartloli/p/4615908.html http://mp.weixin.qq.com/s?__biz=MzIzMzEzODYwOA==\u0026amp;mid=2665283950\u0026amp;idx=1\u0026amp;sn=9005fcaf85f8d4673c62f4067bf3d0ca\u0026amp;scene=0#wechat_redirect http://www.elain.org/2016/02/15/ELK实战一:架构的选择/?hmsr=toutiao.io\u0026amp;utm_medium=toutiao.io\u0026amp;utm_source=toutiao.io http://www.elain.org/2015/12/17/EFK日志收集丢失率测试报告/ http://www.icyfire.me/2014/11/13/logstash-es-kibana.html http://blog.magicmanufactory.com/efk框架搭建/  Kafka  http://mp.weixin.qq.com/s?__biz=MzI4OTU3ODk3NQ==\u0026amp;mid=2247483898\u0026amp;idx=1\u0026amp;sn=e5abc4cd7ae3650efc920498483d479b\u0026amp;chksm=ec2c4b4adb5bc25c774b900d579ea9cf9ea3bc04d5c0df517fe2c775b85b406dd1a2efd82a39\u0026amp;mpshare=1\u0026amp;scene=23\u0026amp;srcid=0217hWKtP4AK21NuFM5DnAvr#rd  Kafka 设计与原理详解  http://blog.csdn.net/suifeng3051/article/details/48053965  分布式系统事务一致性解决方案  http://www.infoq.com/cn/articles/solution-of-distributed-system-transaction-consistency  同程旅游Redis缓存系统  http://geek.csdn.net/news/detail/136648  Spring Cloud  http://blog.didispace.com/springcloud1/  分布式事务  http://blog.csdn.net/bluishglc/article/details/7612811   容器 Docker  http://blog.csdn.net/haiyan_qi/article/details/52777298 http://geek.csdn.net/news/detail/131711   架构   http://mp.weixin.qq.com/s/zsbCnXioxTA1F5cIs_2Ytg\n   Dapper，大规模分布式系统的跟踪系统\n   SOA 设计的 9 大原则\n   荔枝FM异地多活IDC机房架构\n   消息队列设计精要\n   消息队列\n   各种大型网站技术架构\n   支付宝钱包\n   唯品会\n   京东、宅急送\n   金融架构\n   支付系统架构\n   亿级用户下的新浪微博平台架构\n   去哪儿网支付系统\n   MTDDL——美团点评分布式数据访问层中间件\n   ELK 日志分析系统\n   Google 是如何做负载均衡\n   搜索引擎选择： Elasticsearch与Solr\n   Memcache,Redis,MongoDB（数据缓存系统）方案对比与分析\n   消息队列设计精要\n   游戏架构\n   算法 Snowflake  http://www.lanindex.com/twitter-snowflake，64位自增id算法详解/  TF-IDF  http://www.cnblogs.com/ywl925/archive/2013/08/26/3275878.html  MESI－CPU缓存一致性协议  http://blog.csdn.net/realxie/article/details/7317630 http://blog.csdn.net/cqu20093154/article/details/46909903 https://en.wikipedia.org/wiki/MESI_protocol  PageRank  http://blog.csdn.net/hguisu/article/details/7996185 https://segmentfault.com/a/1190000000711128  CRC16 三种算法及c实现  http://www.cnblogs.com/Msisiterc/archive/2011/12/20/2294910.html   大数据 大数据实时处理实战  http://geek.csdn.net/news/detail/163702  Beam  https://zhuanlan.zhihu.com/p/23618169  Mahout  https://www.ibm.com/developerworks/cn/java/j-mahout/index.html http://www.open-open.com/lib/view/open1383390452040.html http://hadoop.readthedocs.io/en/latest/Hadoop-Mahout.html http://blog.csdn.net/zhoubl668/article/details/13297663  Azkaban  https://oschina.net/p/azkaban https://azkaban.github.io/ http://www.cnblogs.com/fbiswt/p/3318876.html   机器学习  http://it.sohu.com/20161221/n476512671.shtml http://blog.csdn.net/BaiHuaXiu123/article/category/6477383  Keras中文文档  http://keras-cn.readthedocs.io/en/latest/#theanotensorflow  TensorFlow  http://tensorfly.cn http://blog.csdn.net/matrix_space/article/details/54286086 http://geek.csdn.net/news/detail/159031 http://mp.weixin.qq.com/s/w7sVasusVUntfNXbUaTltg http://blog.jobbole.com/110558/  Deeplearning4j(DL4J)  https://deeplearning4j.org/cn/ http://www.oschina.net/p/deeplearning4j  自动图像补全  https://mp.weixin.qq.com/s/oWUDqhhi2B4mjqZpe0_oaQ  部署  http://geek.csdn.net/news/detail/134150   Linux VI与VIM区别  http://blog.csdn.net/carolzhang8406/article/details/6117593  epoll  http://blog.163.com/huchengsz@126/blog/static/73483745201181824629285/ http://blog.csdn.net/xiajun07061225/article/details/9250579 https://my.oschina.net/dclink/blog/287198 http://blog.csdn.net/sparkliang/article/details/4770655 http://www.cnblogs.com/venow/archive/2012/11/30/2790031.html http://blog.csdn.net/ljx0305/article/details/4065058 http://www.cnblogs.com/Anker/p/3265058.html  网络IO之阻塞、非阻塞、同步、异步  http://www.cnblogs.com/Anker/p/3254269.html  Linux 4.4 之后 TCP 三路握手的新流程  https://zhuanlan.zhihu.com/p/25313903  Learn  http://roclinux.cn/?page_id=3759 http://www.cnblogs.com/peida/archive/2012/12/05/2803591.html http://codingstandards.iteye.com/blog/786653  iptables  http://www.cnblogs.com/JemBai/archive/2009/03/19/1416364.html   依赖管理 maven  http://blog.csdn.net/sin90lzc/article/details/7543262   MySQL MVCC  http://blog.csdn.net/chen77716/article/details/6742128 http://www.cnblogs.com/chenpingzhao/p/5065316.html  Redo、Undo  http://www.cnblogs.com/liuhao/p/3714012.html http://blog.csdn.net/chenlvzhou/article/details/40537839  Innodb锁机制  http://blog.chinaunix.net/uid-24111901-id-2627857.html   JAVA   IO Tutorials  Java 和微服务  Java 内存分配和回收机制  http://blog.csdn.net/initphp/article/details/30487407  面向GC的Java编程  http://blog.hesey.net/2014/05/gc-oriented-java-programming.html  Jersey开发RESTful服务  http://www.jdon.com/soa/jersey.html  Atomic  http://ifeve.com/java-atomic/  Netty-Mina  http://ifeve.com/netty-mina-in-depth-1/  Disruptor  http://ifeve.com/disruptor/ http://ifeve.com/disruptor-getting-started/  深入浅出MyBatis-Configuration  http://blog.csdn.net/hupanfeng/article/details/9080545  spring监听器  http://blog.csdn.net/blueboz/article/details/49949573 https://my.oschina.net/huangcongcong/blog/527779 http://blog.csdn.net/sd0902/article/details/8394082  BIO | NIO | AIO  https://my.oschina.net/bluesky0leon/blog/132361 http://blog.csdn.net/liuj2511981/article/details/8658440 http://www.programering.com/a/MTO3IzMwATk.html  Im4java  http://www.open-open.com/lib/view/open1378730603412.html http://windows9834.blog.163.com/blog/static/273450042013030115742860/  锁  http://www.infoq.com/cn/articles/java-memory-model-5  Drools  http://blog.csdn.net/quzishen/article/details/6163012/ http://dengkane.iteye.com/blog/2208953  JVM  http://geek.csdn.net/news/detail/131976 http://www.importnew.com/22240.html#comment-541402 http://blog.csdn.net/qq_35101189/article/details/55657798 http://blog.csdn.net/renfufei/article/details/56678064  java8  https://www.ibm.com/developerworks/cn/java/j-lo-jdk8newfeature/index.html  IO  http://it.deepinmind.com/java/2014/02/13/Java8-features-new-new-io.html  Stream  http://blog.csdn.net/youzhouliu/article/details/51820088 http://www.infoq.com/cn/articles/java8-new-features-new-stream-api  HashMap  http://www.cnblogs.com/huaizuo/p/5371099.html https://yq.aliyun.com/articles/36781  Spring Boot参考指南  https://www.gitbook.com/book/qbgbook/spring-boot-reference-guide-zh/details  Spring Boot 入门  http://blog.csdn.net/isea533/article/details/50278205  Spring 4  http://www.infoq.com/cn/articles/spring-4-java-8 https://www.techempower.com/blog/2013/03/26/everything-about-java-8/ http://blog.csdn.net/dm_vincent/article/category/2648241 http://www.oschina.net/translate/everything-about-java-8 http://www.ibm.com/developerworks/cn/java/j-lo-jdk8newfeature/index.html http://winterbe.com/posts/2015/03/25/java8-examples-string-number-math-files/ http://eherrera.net/ocpj8-notes/09-java-file-io-(NIO.2) http://ifeve.com/java-8-features-tutorial/  CAS  http://blog.hesey.net/2011/09/resolve-aba-by-atomicstampedreference.html http://ifeve.com/atomic-operation/ https://www.ibm.com/developerworks/cn/java/j-jtp11234/ https://www.ibm.com/developerworks/cn/java/j-jtp04186/ http://zl198751.iteye.com/blog/1848575   Python   PyCharm vs. Sublime Text  python守护进程demo  https://blog.phpgao.com/pythond.html  Python Tutorial  http://www.pythondoc.com http://www.runoob.com/python3/python3-basic-syntax.html http://www.liaoxuefeng.com/wiki/0014316089557264a6b348958f449949df42a6d3a2e542c000/001431658624177ea4f8fcb06bc4d0e8aab2fd7aa65dd95000  爬虫  https://zhuanlan.zhihu.com/p/21377121 https://xlzd.me/tag/crawler/2/  文本挖掘  http://geek.csdn.net/news/detail/129348  配置编译环境  https://zhuanlan.zhihu.com/p/22704462  pip  http://blog.163.com/yang_jianli/blog/static/161990006201162152724339/  Nginx + Gunicorn + Django  http://www.isaced.com/post-248.html  MySQL  http://www.liaoxuefeng.com/wiki/001374738125095c955c1e6d8bb493182103fac9270762a000/001391435131816c6a377e100ec4d43b3fc9145f3bb8056000  调试  https://www.zhihu.com/question/21572891   HTML WebSocket  https://www.zhihu.com/question/20215561  CSS Selectors Level 4  http://geek.csdn.net/news/detail/127566   其他 DevOps  http://www.infoq.com/cn/articles/devops-not-legend  SRE之道  https://yq.aliyun.com/articles/70525  技术领域 ** http://geek.csdn.net/news/detail/134070\nHTTPS 与 HTTP2 协议分析  http://geek.csdn.net/news/detail/188003  Reactor和Proactor模式  http://blog.csdn.net/caiwenfeng_for_23/article/details/8458299 http://www.blogjava.net/DLevin/archive/2015/09/02/427045.html http://blog.jobbole.com/59676/  管道模型(Pipeline)  http://blog.csdn.net/yanghua_kobe/article/details/7561016  半包、粘包  http://www.cnblogs.com/jiangtong/archive/2012/03/22/2411985.html http://www.itstack.org/?post=12  Sftp和ftp 区别、工作原理等  http://blog.csdn.net/cuker919/article/details/6403925  双向数据绑定  https://segmentfault.com/q/1010000002511449/a-1020000002514653  JSON Web Token  http://blog.leapoahead.com/2015/09/06/understanding-jwt/ https://segmentfault.com/a/1190000005047525?utm_source=tuicool\u0026amp;utm_medium=referral  OAuth 2.0  http://www.ruanyifeng.com/blog/2014/05/oauth_2_0.html  RESTful API 设计  http://www.ruanyifeng.com/blog/2014/05/restful_api.html  微服务的技术架构术语定义  http://mp.weixin.qq.com/s?__biz=MjM5MjEwNTEzOQ==\u0026amp;amp;mid=401500724\u0026amp;amp;idx=1\u0026amp;amp;sn=4e42fa2ffcd5732ae044fe6a387a1cc3  ","date":1487718393,"expirydate":-62135596800,"kind":"page","lang":"zh","lastmod":1487718393,"objectID":"f88d181df470f1ed7cc8038afd7c422d","permalink":"https://moyada.github.io/bak/collection/","publishdate":"2017-02-21T23:06:33Z","relpermalink":"/bak/collection/","section":"bak","summary":"博客 计算机书籍控 开源文档 程序猿DD - Spring Boot教程与Spri","tags":[],"title":"收藏","type":"bak"}]